# FLOPs 指标说明

## 概述

本项目已集成 FLOPs（浮点运算次数）指标计算功能，用于评估模型的计算复杂度。

## 功能特点

1. **自动计算**: 训练开始时自动计算模型的 FLOPs 和参数量
2. **详细记录**: 将 FLOPs 指标记录到训练日志中
3. **友好显示**: 使用易读格式（如 M, G）显示计算结果

## 实现细节

### 计算函数

位置: `utils/common.py`

```python
calculate_flops(model, input_shape=(1, 1, 96, 64), device='cuda')
```

### 集成位置

在 `audio_cross_domain_trainer.py` 的训练器初始化阶段（`__init__` 方法）自动调用。

### 输出格式

训练开始时会显示：

```
============================================================
计算模型复杂度...
============================================================
FLOPs: 863.896M
Parameters: 72.141M
============================================================
```

同时会记录到训练日志文件中：

```
============================================================
MODEL COMPLEXITY
============================================================
FLOPs: 863.896M
Parameters: 72.141M
FLOPs (exact): 863895808
Parameters (exact): 72141442
============================================================
```

## VGGish 模型复杂度

以当前的 VGGish 模型为例：

- **FLOPs**: 863.896M (约 0.864 GFLOPs)
- **参数量**: 72.141M
- **输入尺寸**: (1, 1, 96, 64) - (batch_size, channels, n_mels, time_frames)

## 依赖库

- `thop`: 用于计算 FLOPs
  - 安装命令: `pip install thop`
  - 已在环境中安装

## 注意事项

1. FLOPs 计算会在模型初始化后、训练开始前自动执行
2. 对于动态初始化的层，函数会先执行一次前向传播以确保模型完全初始化
3. 如果 `thop` 库计算失败，会尝试至少统计模型参数量

## 技术说明

FLOPs (Floating Point Operations) 是衡量模型计算复杂度的重要指标：

- **1 FLOP**: 一次浮点运算
- **1 MFLOPs**: 100万次浮点运算
- **1 GFLOPs**: 10亿次浮点运算

对于实时应用，较低的 FLOPs 意味着更快的推理速度和更低的能耗。
