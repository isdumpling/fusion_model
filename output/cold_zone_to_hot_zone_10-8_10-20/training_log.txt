[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:29] MODEL COMPLEXITY
[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:29] FLOPs: 863.897M
[2025-10-08 10:20:29] Parameters: 72.142M
[2025-10-08 10:20:29]   FLOPs (exact): 863896576
[2025-10-08 10:20:29]   Parameters (exact): 72141700
[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:29] ABLATION EXPERIMENT CONFIGURATION
[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:29] WeightedRandomSampler: ENABLED
[2025-10-08 10:20:29] Focal Loss: DISABLED
[2025-10-08 10:20:29] Logit Adjustment: DISABLED
[2025-10-08 10:20:29] Label Smoothing: 0.98
[2025-10-08 10:20:29] Stage 2 Use Source Data: DISABLED
[2025-10-08 10:20:29] Stage 2 Sliding Window Filter: DISABLED
[2025-10-08 10:20:29] ============================================================
[2025-10-08 10:20:35] Stage1 - Epoch: [1 | 100]
[2025-10-08 10:20:35]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-08 10:20:35]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-08 10:20:35]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-08 10:20:35]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-08 10:20:35]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-08 10:20:35]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-08 10:20:35]   [Param]	LR:	0.00010000
[2025-10-08 10:20:38] Stage1 - Epoch: [2 | 100]
[2025-10-08 10:20:38]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-08 10:20:38]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-08 10:20:38]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-08 10:20:38]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-08 10:20:38]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-08 10:20:38]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-08 10:20:38]   [Param]	LR:	0.00009998
[2025-10-08 10:20:41] Stage1 - Epoch: [3 | 100]
[2025-10-08 10:20:41]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-08 10:20:41]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-08 10:20:41]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-08 10:20:41]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-08 10:20:41]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-08 10:20:41]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-08 10:20:41]   [Param]	LR:	0.00009990
[2025-10-08 10:20:45] Stage1 - Epoch: [4 | 100]
[2025-10-08 10:20:45]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-08 10:20:45]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-08 10:20:45]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-08 10:20:45]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-08 10:20:45]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-08 10:20:45]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-08 10:20:45]   [Param]	LR:	0.00009978
[2025-10-08 10:20:48] Stage1 - Epoch: [5 | 100]
[2025-10-08 10:20:48]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-08 10:20:48]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-08 10:20:48]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-08 10:20:48]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-08 10:20:48]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-08 10:20:48]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-08 10:20:48]   [Param]	LR:	0.00009961
[2025-10-08 10:20:51] Stage1 - Epoch: [6 | 100]
[2025-10-08 10:20:51]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-08 10:20:51]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-08 10:20:51]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-08 10:20:51]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-08 10:20:51]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-08 10:20:51]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-08 10:20:51]   [Param]	LR:	0.00009938
[2025-10-08 10:20:54] Stage1 - Epoch: [7 | 100]
[2025-10-08 10:20:54]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-08 10:20:54]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-08 10:20:54]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-08 10:20:54]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-08 10:20:54]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-08 10:20:54]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-08 10:20:54]   [Param]	LR:	0.00009911
[2025-10-08 10:20:57] Stage1 - Epoch: [8 | 100]
[2025-10-08 10:20:57]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-08 10:20:57]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-08 10:20:57]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-08 10:20:57]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-08 10:20:57]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-08 10:20:57]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-08 10:20:57]   [Param]	LR:	0.00009880
[2025-10-08 10:21:00] Stage1 - Epoch: [9 | 100]
[2025-10-08 10:21:00]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-08 10:21:00]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-08 10:21:00]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-08 10:21:00]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-08 10:21:00]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-08 10:21:00]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-08 10:21:00]   [Param]	LR:	0.00009843
[2025-10-08 10:21:04] Stage1 - Epoch: [10 | 100]
[2025-10-08 10:21:04]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-08 10:21:04]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-08 10:21:04]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:21:04]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:21:04]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:21:04]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:04]   [Param]	LR:	0.00009801
[2025-10-08 10:21:07] Stage1 - Epoch: [11 | 100]
[2025-10-08 10:21:07]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-08 10:21:07]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-08 10:21:07]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:21:07]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:21:07]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:21:07]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:21:07]   [Param]	LR:	0.00009755
[2025-10-08 10:21:10] Stage1 - Epoch: [12 | 100]
[2025-10-08 10:21:10]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-08 10:21:10]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-08 10:21:10]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-08 10:21:10]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-08 10:21:10]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-08 10:21:10]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:21:10]   [Param]	LR:	0.00009704
[2025-10-08 10:21:13] Stage1 - Epoch: [13 | 100]
[2025-10-08 10:21:13]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-08 10:21:13]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-08 10:21:13]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:21:13]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:21:13]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:21:13]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:13]   [Param]	LR:	0.00009649
[2025-10-08 10:21:16] Stage1 - Epoch: [14 | 100]
[2025-10-08 10:21:16]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-08 10:21:16]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-08 10:21:16]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:21:16]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:21:16]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:21:16]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:16]   [Param]	LR:	0.00009589
[2025-10-08 10:21:19] Stage1 - Epoch: [15 | 100]
[2025-10-08 10:21:19]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-08 10:21:19]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-08 10:21:19]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:21:19]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:21:19]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:21:19]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:21:19]   [Param]	LR:	0.00009524
[2025-10-08 10:21:23] Stage1 - Epoch: [16 | 100]
[2025-10-08 10:21:23]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-08 10:21:23]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-08 10:21:23]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:21:23]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:21:23]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:21:23]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:21:23]   [Param]	LR:	0.00009455
[2025-10-08 10:21:26] Stage1 - Epoch: [17 | 100]
[2025-10-08 10:21:26]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-08 10:21:26]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-08 10:21:26]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-08 10:21:26]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-08 10:21:26]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-08 10:21:26]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:26]   [Param]	LR:	0.00009382
[2025-10-08 10:21:29] Stage1 - Epoch: [18 | 100]
[2025-10-08 10:21:29]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-08 10:21:29]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-08 10:21:29]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:21:29]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:21:29]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:21:29]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:29]   [Param]	LR:	0.00009304
[2025-10-08 10:21:32] Stage1 - Epoch: [19 | 100]
[2025-10-08 10:21:32]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-08 10:21:32]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-08 10:21:32]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-08 10:21:32]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-08 10:21:32]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-08 10:21:32]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:32]   [Param]	LR:	0.00009222
[2025-10-08 10:21:35] Stage1 - Epoch: [20 | 100]
[2025-10-08 10:21:35]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-08 10:21:35]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-08 10:21:35]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:21:35]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:21:35]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:21:35]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:35]   [Param]	LR:	0.00009135
[2025-10-08 10:21:38] Stage1 - Epoch: [21 | 100]
[2025-10-08 10:21:38]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-08 10:21:38]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-08 10:21:38]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:21:38]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:21:38]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:21:38]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:38]   [Param]	LR:	0.00009045
[2025-10-08 10:21:41] Stage1 - Epoch: [22 | 100]
[2025-10-08 10:21:41]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-08 10:21:41]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-08 10:21:41]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:21:41]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:21:41]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:21:41]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:41]   [Param]	LR:	0.00008951
[2025-10-08 10:21:44] Stage1 - Epoch: [23 | 100]
[2025-10-08 10:21:44]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-08 10:21:44]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-08 10:21:44]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:21:44]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:21:44]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:21:44]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:44]   [Param]	LR:	0.00008853
[2025-10-08 10:21:48] Stage1 - Epoch: [24 | 100]
[2025-10-08 10:21:48]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-08 10:21:48]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-08 10:21:48]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-08 10:21:48]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-08 10:21:48]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-08 10:21:48]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:48]   [Param]	LR:	0.00008751
[2025-10-08 10:21:51] Stage1 - Epoch: [25 | 100]
[2025-10-08 10:21:51]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-08 10:21:51]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-08 10:21:51]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:21:51]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:21:51]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:21:51]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:51]   [Param]	LR:	0.00008645
[2025-10-08 10:21:54] Stage1 - Epoch: [26 | 100]
[2025-10-08 10:21:54]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-08 10:21:54]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-08 10:21:54]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:21:54]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:21:54]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:21:54]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:54]   [Param]	LR:	0.00008536
[2025-10-08 10:21:57] Stage1 - Epoch: [27 | 100]
[2025-10-08 10:21:57]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-08 10:21:57]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-08 10:21:57]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:21:57]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:21:57]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:21:57]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:21:57]   [Param]	LR:	0.00008423
[2025-10-08 10:22:00] Stage1 - Epoch: [28 | 100]
[2025-10-08 10:22:00]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-08 10:22:00]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-08 10:22:00]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:22:00]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:22:00]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:22:00]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:00]   [Param]	LR:	0.00008307
[2025-10-08 10:22:03] Stage1 - Epoch: [29 | 100]
[2025-10-08 10:22:03]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-08 10:22:03]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-08 10:22:03]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:22:03]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:22:03]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:22:03]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:03]   [Param]	LR:	0.00008187
[2025-10-08 10:22:06] Stage1 - Epoch: [30 | 100]
[2025-10-08 10:22:06]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-08 10:22:06]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-08 10:22:06]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:22:06]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:22:06]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:22:06]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:06]   [Param]	LR:	0.00008065
[2025-10-08 10:22:09] Stage1 - Epoch: [31 | 100]
[2025-10-08 10:22:09]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-08 10:22:09]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-08 10:22:09]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:22:09]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:22:09]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:22:09]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:09]   [Param]	LR:	0.00007939
[2025-10-08 10:22:13] Stage1 - Epoch: [32 | 100]
[2025-10-08 10:22:13]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-08 10:22:13]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-08 10:22:13]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:22:13]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:22:13]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:22:13]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:13]   [Param]	LR:	0.00007810
[2025-10-08 10:22:16] Stage1 - Epoch: [33 | 100]
[2025-10-08 10:22:16]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-08 10:22:16]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-08 10:22:16]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:22:16]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:22:16]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:22:16]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:16]   [Param]	LR:	0.00007679
[2025-10-08 10:22:19] Stage1 - Epoch: [34 | 100]
[2025-10-08 10:22:19]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-08 10:22:19]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-08 10:22:19]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:22:19]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:22:19]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:22:19]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:19]   [Param]	LR:	0.00007545
[2025-10-08 10:22:22] Stage1 - Epoch: [35 | 100]
[2025-10-08 10:22:22]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-08 10:22:22]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-08 10:22:22]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:22:22]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:22:22]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:22:22]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:22]   [Param]	LR:	0.00007409
[2025-10-08 10:22:25] Stage1 - Epoch: [36 | 100]
[2025-10-08 10:22:25]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-08 10:22:25]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-08 10:22:25]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:22:25]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:22:25]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:22:25]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:22:25]   [Param]	LR:	0.00007270
[2025-10-08 10:22:25] Early stopping triggered after 36 epochs.
[2025-10-08 10:22:26] Model saved to output/cold_zone_to_hot_zone_10-8_10-20/best_model_stage1_audio.pth
[2025-10-08 10:22:26] Stage 1 Training Time: 00:01:55
[2025-10-08 10:22:26] Stage 1 Best Macro F1: 0.9542
[2025-10-08 10:22:26] Starting pseudo-label precomputation for curriculum learning...
[2025-10-08 10:22:29] Confidence statistics - Min: 0.5086, Max: 0.9995, Mean: 0.9361, Median: 0.9801
[2025-10-08 10:22:29] Precomputed 252 samples with confidence scores
[2025-10-08 10:22:29] Epoch 1/50: Using 179/252 target samples (threshold=0.9500)
[2025-10-08 10:22:39] Stage2 - Epoch: [1 | 50]
[2025-10-08 10:22:39]   [Train]	Total Loss:	0.0223	CE Loss:	0.0171	Distill Loss:	0.0052
[2025-10-08 10:22:39]   [Train]	Acc:	1.0000
[2025-10-08 10:22:39]   [Test ]	Loss:	0.0000	Acc:	81.2500
[2025-10-08 10:22:39]   [Test ]	Micro F1:	0.8125	Macro F1:	0.7681
[2025-10-08 10:22:39]   [Cough   ]	F1:	0.6667	Precision:	0.6000	Recall:	0.7500
[2025-10-08 10:22:39]   [NonCough]	F1:	0.8696	Precision:	0.9091	Recall:	0.8333
[2025-10-08 10:22:39]   [Stats]	Many:	75.0000	Medium:	83.3333	Few:	0.0000
[2025-10-08 10:22:39]   [Param]	LR:	0.00100000
[2025-10-08 10:22:39] Epoch 2/50: Using 181/252 target samples (threshold=0.9469)
[2025-10-08 10:22:48] Stage2 - Epoch: [2 | 50]
[2025-10-08 10:22:48]   [Train]	Total Loss:	0.0153	CE Loss:	0.0078	Distill Loss:	0.0075
[2025-10-08 10:22:48]   [Train]	Acc:	1.0000
[2025-10-08 10:22:48]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:22:48]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:22:48]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:22:48]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:22:48]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:22:48]   [Param]	LR:	0.00099901
[2025-10-08 10:22:48] Epoch 3/50: Using 181/252 target samples (threshold=0.9439)
[2025-10-08 10:22:56] Stage2 - Epoch: [3 | 50]
[2025-10-08 10:22:56]   [Train]	Total Loss:	0.0187	CE Loss:	0.0080	Distill Loss:	0.0107
[2025-10-08 10:22:56]   [Train]	Acc:	1.0000
[2025-10-08 10:22:56]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:22:56]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:22:56]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:22:56]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:22:56]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:22:56]   [Param]	LR:	0.00099606
[2025-10-08 10:22:56] Epoch 4/50: Using 183/252 target samples (threshold=0.9408)
[2025-10-08 10:23:04] Stage2 - Epoch: [4 | 50]
[2025-10-08 10:23:04]   [Train]	Total Loss:	0.0195	CE Loss:	0.0074	Distill Loss:	0.0122
[2025-10-08 10:23:04]   [Train]	Acc:	1.0000
[2025-10-08 10:23:04]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:23:04]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:23:04]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:23:04]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:23:04]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:04]   [Param]	LR:	0.00099114
[2025-10-08 10:23:04] Epoch 5/50: Using 183/252 target samples (threshold=0.9378)
[2025-10-08 10:23:12] Stage2 - Epoch: [5 | 50]
[2025-10-08 10:23:12]   [Train]	Total Loss:	0.0185	CE Loss:	0.0074	Distill Loss:	0.0110
[2025-10-08 10:23:12]   [Train]	Acc:	1.0000
[2025-10-08 10:23:12]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:23:12]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:23:12]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:23:12]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:23:12]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:12]   [Param]	LR:	0.00098429
[2025-10-08 10:23:12] Epoch 6/50: Using 184/252 target samples (threshold=0.9347)
[2025-10-08 10:23:20] Stage2 - Epoch: [6 | 50]
[2025-10-08 10:23:20]   [Train]	Total Loss:	0.0189	CE Loss:	0.0090	Distill Loss:	0.0099
[2025-10-08 10:23:20]   [Train]	Acc:	1.0000
[2025-10-08 10:23:20]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:23:20]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:23:20]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:23:20]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:23:20]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:20]   [Param]	LR:	0.00097553
[2025-10-08 10:23:20] Epoch 7/50: Using 187/252 target samples (threshold=0.9316)
[2025-10-08 10:23:28] Stage2 - Epoch: [7 | 50]
[2025-10-08 10:23:28]   [Train]	Total Loss:	0.0160	CE Loss:	0.0083	Distill Loss:	0.0077
[2025-10-08 10:23:28]   [Train]	Acc:	1.0000
[2025-10-08 10:23:28]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:23:28]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:23:28]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:23:28]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:23:28]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:28]   [Param]	LR:	0.00096489
[2025-10-08 10:23:28] Epoch 8/50: Using 189/252 target samples (threshold=0.9286)
[2025-10-08 10:23:37] Stage2 - Epoch: [8 | 50]
[2025-10-08 10:23:37]   [Train]	Total Loss:	0.0219	CE Loss:	0.0118	Distill Loss:	0.0101
[2025-10-08 10:23:37]   [Train]	Acc:	1.0000
[2025-10-08 10:23:37]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:23:37]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:23:37]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:23:37]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:23:37]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:37]   [Param]	LR:	0.00095241
[2025-10-08 10:23:37] Epoch 9/50: Using 193/252 target samples (threshold=0.9255)
[2025-10-08 10:23:46] Stage2 - Epoch: [9 | 50]
[2025-10-08 10:23:46]   [Train]	Total Loss:	0.0646	CE Loss:	0.0300	Distill Loss:	0.0347
[2025-10-08 10:23:46]   [Train]	Acc:	0.9896
[2025-10-08 10:23:46]   [Test ]	Loss:	0.0000	Acc:	82.8125
[2025-10-08 10:23:46]   [Test ]	Micro F1:	0.8281	Macro F1:	0.7659
[2025-10-08 10:23:46]   [Cough   ]	F1:	0.6452	Precision:	0.6667	Recall:	0.6250
[2025-10-08 10:23:46]   [NonCough]	F1:	0.8866	Precision:	0.8776	Recall:	0.8958
[2025-10-08 10:23:46]   [Stats]	Many:	62.5000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:46]   [Param]	LR:	0.00093815
[2025-10-08 10:23:46] Epoch 10/50: Using 195/252 target samples (threshold=0.9224)
[2025-10-08 10:23:55] Stage2 - Epoch: [10 | 50]
[2025-10-08 10:23:55]   [Train]	Total Loss:	0.0275	CE Loss:	0.0059	Distill Loss:	0.0217
[2025-10-08 10:23:55]   [Train]	Acc:	1.0000
[2025-10-08 10:23:55]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:23:55]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:23:55]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:23:55]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:23:55]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:23:55]   [Param]	LR:	0.00092216
[2025-10-08 10:23:55] Epoch 11/50: Using 198/252 target samples (threshold=0.9194)
[2025-10-08 10:24:03] Stage2 - Epoch: [11 | 50]
[2025-10-08 10:24:03]   [Train]	Total Loss:	0.0234	CE Loss:	0.0059	Distill Loss:	0.0175
[2025-10-08 10:24:03]   [Train]	Acc:	1.0000
[2025-10-08 10:24:03]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:24:03]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:24:03]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:24:03]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:24:03]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:03]   [Param]	LR:	0.00090451
[2025-10-08 10:24:03] Epoch 12/50: Using 198/252 target samples (threshold=0.9163)
[2025-10-08 10:24:11] Stage2 - Epoch: [12 | 50]
[2025-10-08 10:24:11]   [Train]	Total Loss:	0.0208	CE Loss:	0.0103	Distill Loss:	0.0105
[2025-10-08 10:24:11]   [Train]	Acc:	1.0000
[2025-10-08 10:24:11]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:24:11]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:24:11]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:24:11]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:24:11]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:11]   [Param]	LR:	0.00088526
[2025-10-08 10:24:11] Epoch 13/50: Using 200/252 target samples (threshold=0.9133)
[2025-10-08 10:24:20] Stage2 - Epoch: [13 | 50]
[2025-10-08 10:24:20]   [Train]	Total Loss:	0.0228	CE Loss:	0.0123	Distill Loss:	0.0104
[2025-10-08 10:24:20]   [Train]	Acc:	1.0000
[2025-10-08 10:24:20]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:24:20]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:24:20]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:24:20]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:24:20]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:20]   [Param]	LR:	0.00086448
[2025-10-08 10:24:20] Epoch 14/50: Using 201/252 target samples (threshold=0.9102)
[2025-10-08 10:24:28] Stage2 - Epoch: [14 | 50]
[2025-10-08 10:24:28]   [Train]	Total Loss:	0.0218	CE Loss:	0.0119	Distill Loss:	0.0098
[2025-10-08 10:24:28]   [Train]	Acc:	1.0000
[2025-10-08 10:24:28]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:24:28]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:24:28]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:24:28]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:24:28]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:28]   [Param]	LR:	0.00084227
[2025-10-08 10:24:28] Epoch 15/50: Using 201/252 target samples (threshold=0.9071)
[2025-10-08 10:24:37] Stage2 - Epoch: [15 | 50]
[2025-10-08 10:24:37]   [Train]	Total Loss:	0.0218	CE Loss:	0.0109	Distill Loss:	0.0108
[2025-10-08 10:24:37]   [Train]	Acc:	1.0000
[2025-10-08 10:24:37]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:24:37]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:24:37]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:24:37]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:24:37]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:37]   [Param]	LR:	0.00081871
[2025-10-08 10:24:37] Epoch 16/50: Using 201/252 target samples (threshold=0.9041)
[2025-10-08 10:24:46] Stage2 - Epoch: [16 | 50]
[2025-10-08 10:24:46]   [Train]	Total Loss:	0.0205	CE Loss:	0.0097	Distill Loss:	0.0108
[2025-10-08 10:24:46]   [Train]	Acc:	1.0000
[2025-10-08 10:24:46]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:24:46]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:24:46]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:24:46]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:24:46]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:46]   [Param]	LR:	0.00079389
[2025-10-08 10:24:46] Epoch 17/50: Using 204/252 target samples (threshold=0.9010)
[2025-10-08 10:24:54] Stage2 - Epoch: [17 | 50]
[2025-10-08 10:24:54]   [Train]	Total Loss:	0.0230	CE Loss:	0.0113	Distill Loss:	0.0117
[2025-10-08 10:24:54]   [Train]	Acc:	1.0000
[2025-10-08 10:24:54]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:24:54]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:24:54]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:24:54]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:24:54]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:24:54]   [Param]	LR:	0.00076791
[2025-10-08 10:24:54] Epoch 18/50: Using 204/252 target samples (threshold=0.8980)
[2025-10-08 10:25:03] Stage2 - Epoch: [18 | 50]
[2025-10-08 10:25:03]   [Train]	Total Loss:	0.0218	CE Loss:	0.0103	Distill Loss:	0.0116
[2025-10-08 10:25:03]   [Train]	Acc:	1.0000
[2025-10-08 10:25:03]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:25:03]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:25:03]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:25:03]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:25:03]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:03]   [Param]	LR:	0.00074088
[2025-10-08 10:25:03] Epoch 19/50: Using 205/252 target samples (threshold=0.8949)
[2025-10-08 10:25:11] Stage2 - Epoch: [19 | 50]
[2025-10-08 10:25:11]   [Train]	Total Loss:	0.0434	CE Loss:	0.0222	Distill Loss:	0.0211
[2025-10-08 10:25:11]   [Train]	Acc:	0.9948
[2025-10-08 10:25:11]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:25:11]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:25:11]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:25:11]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:25:11]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:11]   [Param]	LR:	0.00071289
[2025-10-08 10:25:11] Epoch 20/50: Using 207/252 target samples (threshold=0.8918)
[2025-10-08 10:25:19] Stage2 - Epoch: [20 | 50]
[2025-10-08 10:25:19]   [Train]	Total Loss:	0.0534	CE Loss:	0.0250	Distill Loss:	0.0284
[2025-10-08 10:25:19]   [Train]	Acc:	0.9948
[2025-10-08 10:25:19]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:25:19]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:25:19]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:25:19]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:25:19]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:19]   [Param]	LR:	0.00068406
[2025-10-08 10:25:19] Epoch 21/50: Using 208/252 target samples (threshold=0.8888)
[2025-10-08 10:25:28] Stage2 - Epoch: [21 | 50]
[2025-10-08 10:25:28]   [Train]	Total Loss:	0.0298	CE Loss:	0.0103	Distill Loss:	0.0195
[2025-10-08 10:25:28]   [Train]	Acc:	1.0000
[2025-10-08 10:25:28]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:25:28]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:25:28]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:25:28]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:25:28]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:28]   [Param]	LR:	0.00065451
[2025-10-08 10:25:28] Epoch 22/50: Using 212/252 target samples (threshold=0.8857)
[2025-10-08 10:25:36] Stage2 - Epoch: [22 | 50]
[2025-10-08 10:25:36]   [Train]	Total Loss:	0.0781	CE Loss:	0.0411	Distill Loss:	0.0370
[2025-10-08 10:25:36]   [Train]	Acc:	0.9952
[2025-10-08 10:25:36]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:25:36]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:25:36]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:25:36]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:25:36]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:36]   [Param]	LR:	0.00062434
[2025-10-08 10:25:36] Epoch 23/50: Using 213/252 target samples (threshold=0.8827)
[2025-10-08 10:25:45] Stage2 - Epoch: [23 | 50]
[2025-10-08 10:25:45]   [Train]	Total Loss:	0.0354	CE Loss:	0.0195	Distill Loss:	0.0159
[2025-10-08 10:25:45]   [Train]	Acc:	0.9952
[2025-10-08 10:25:45]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:25:45]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:25:45]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:25:45]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:25:45]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:45]   [Param]	LR:	0.00059369
[2025-10-08 10:25:45] Epoch 24/50: Using 214/252 target samples (threshold=0.8796)
[2025-10-08 10:25:53] Stage2 - Epoch: [24 | 50]
[2025-10-08 10:25:53]   [Train]	Total Loss:	0.0293	CE Loss:	0.0138	Distill Loss:	0.0155
[2025-10-08 10:25:53]   [Train]	Acc:	1.0000
[2025-10-08 10:25:53]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:25:53]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:25:53]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:25:53]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:25:53]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:25:53]   [Param]	LR:	0.00056267
[2025-10-08 10:25:53] Epoch 25/50: Using 214/252 target samples (threshold=0.8765)
[2025-10-08 10:26:02] Stage2 - Epoch: [25 | 50]
[2025-10-08 10:26:02]   [Train]	Total Loss:	0.0598	CE Loss:	0.0342	Distill Loss:	0.0255
[2025-10-08 10:26:02]   [Train]	Acc:	0.9952
[2025-10-08 10:26:02]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:26:02]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:26:02]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:26:02]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:26:02]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:02]   [Param]	LR:	0.00053140
[2025-10-08 10:26:02] Epoch 26/50: Using 214/252 target samples (threshold=0.8735)
[2025-10-08 10:26:11] Stage2 - Epoch: [26 | 50]
[2025-10-08 10:26:11]   [Train]	Total Loss:	0.0255	CE Loss:	0.0164	Distill Loss:	0.0091
[2025-10-08 10:26:11]   [Train]	Acc:	1.0000
[2025-10-08 10:26:11]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:26:11]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:26:11]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:26:11]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:26:11]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:11]   [Param]	LR:	0.00050000
[2025-10-08 10:26:11] Epoch 27/50: Using 215/252 target samples (threshold=0.8704)
[2025-10-08 10:26:19] Stage2 - Epoch: [27 | 50]
[2025-10-08 10:26:19]   [Train]	Total Loss:	0.0325	CE Loss:	0.0204	Distill Loss:	0.0122
[2025-10-08 10:26:19]   [Train]	Acc:	0.9952
[2025-10-08 10:26:19]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:26:19]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:26:19]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:26:19]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:26:19]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:19]   [Param]	LR:	0.00046860
[2025-10-08 10:26:19] Epoch 28/50: Using 215/252 target samples (threshold=0.8673)
[2025-10-08 10:26:27] Stage2 - Epoch: [28 | 50]
[2025-10-08 10:26:27]   [Train]	Total Loss:	0.0251	CE Loss:	0.0138	Distill Loss:	0.0114
[2025-10-08 10:26:27]   [Train]	Acc:	1.0000
[2025-10-08 10:26:27]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:26:27]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:26:27]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:26:27]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:26:27]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:27]   [Param]	LR:	0.00043733
[2025-10-08 10:26:27] Epoch 29/50: Using 216/252 target samples (threshold=0.8643)
[2025-10-08 10:26:36] Stage2 - Epoch: [29 | 50]
[2025-10-08 10:26:36]   [Train]	Total Loss:	0.0393	CE Loss:	0.0229	Distill Loss:	0.0164
[2025-10-08 10:26:36]   [Train]	Acc:	0.9952
[2025-10-08 10:26:36]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:26:36]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:26:36]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:26:36]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:26:36]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:36]   [Param]	LR:	0.00040631
[2025-10-08 10:26:36] Epoch 30/50: Using 217/252 target samples (threshold=0.8612)
[2025-10-08 10:26:44] Stage2 - Epoch: [30 | 50]
[2025-10-08 10:26:44]   [Train]	Total Loss:	0.0751	CE Loss:	0.0396	Distill Loss:	0.0354
[2025-10-08 10:26:44]   [Train]	Acc:	0.9952
[2025-10-08 10:26:44]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:26:44]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:26:44]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:26:44]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:26:44]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:44]   [Param]	LR:	0.00037566
[2025-10-08 10:26:44] Epoch 31/50: Using 218/252 target samples (threshold=0.8582)
[2025-10-08 10:26:53] Stage2 - Epoch: [31 | 50]
[2025-10-08 10:26:53]   [Train]	Total Loss:	0.0319	CE Loss:	0.0162	Distill Loss:	0.0157
[2025-10-08 10:26:53]   [Train]	Acc:	1.0000
[2025-10-08 10:26:53]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:26:53]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:26:53]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:26:53]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:26:53]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:26:53]   [Param]	LR:	0.00034549
[2025-10-08 10:26:53] Epoch 32/50: Using 219/252 target samples (threshold=0.8551)
[2025-10-08 10:27:01] Stage2 - Epoch: [32 | 50]
[2025-10-08 10:27:01]   [Train]	Total Loss:	0.0368	CE Loss:	0.0210	Distill Loss:	0.0158
[2025-10-08 10:27:01]   [Train]	Acc:	0.9952
[2025-10-08 10:27:01]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:27:01]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:27:01]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:27:01]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:27:01]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:01]   [Param]	LR:	0.00031594
[2025-10-08 10:27:01] Epoch 33/50: Using 219/252 target samples (threshold=0.8520)
[2025-10-08 10:27:10] Stage2 - Epoch: [33 | 50]
[2025-10-08 10:27:10]   [Train]	Total Loss:	0.0318	CE Loss:	0.0165	Distill Loss:	0.0153
[2025-10-08 10:27:10]   [Train]	Acc:	1.0000
[2025-10-08 10:27:10]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:27:10]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:27:10]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:27:10]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:27:10]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:10]   [Param]	LR:	0.00028711
[2025-10-08 10:27:10] Epoch 34/50: Using 220/252 target samples (threshold=0.8490)
[2025-10-08 10:27:18] Stage2 - Epoch: [34 | 50]
[2025-10-08 10:27:18]   [Train]	Total Loss:	0.0312	CE Loss:	0.0179	Distill Loss:	0.0134
[2025-10-08 10:27:18]   [Train]	Acc:	1.0000
[2025-10-08 10:27:18]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:27:18]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:27:18]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:27:18]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:27:18]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:18]   [Param]	LR:	0.00025912
[2025-10-08 10:27:18] Epoch 35/50: Using 220/252 target samples (threshold=0.8459)
[2025-10-08 10:27:27] Stage2 - Epoch: [35 | 50]
[2025-10-08 10:27:27]   [Train]	Total Loss:	0.0334	CE Loss:	0.0155	Distill Loss:	0.0179
[2025-10-08 10:27:27]   [Train]	Acc:	1.0000
[2025-10-08 10:27:27]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:27:27]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:27:27]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:27:27]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:27:27]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:27]   [Param]	LR:	0.00023209
[2025-10-08 10:27:27] Epoch 36/50: Using 220/252 target samples (threshold=0.8429)
[2025-10-08 10:27:35] Stage2 - Epoch: [36 | 50]
[2025-10-08 10:27:35]   [Train]	Total Loss:	0.0306	CE Loss:	0.0148	Distill Loss:	0.0157
[2025-10-08 10:27:35]   [Train]	Acc:	1.0000
[2025-10-08 10:27:35]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:27:35]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:27:35]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:27:35]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:27:35]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:35]   [Param]	LR:	0.00020611
[2025-10-08 10:27:35] Epoch 37/50: Using 221/252 target samples (threshold=0.8398)
[2025-10-08 10:27:44] Stage2 - Epoch: [37 | 50]
[2025-10-08 10:27:44]   [Train]	Total Loss:	0.0606	CE Loss:	0.0365	Distill Loss:	0.0241
[2025-10-08 10:27:44]   [Train]	Acc:	0.9952
[2025-10-08 10:27:44]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:27:44]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:27:44]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:27:44]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:27:44]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:44]   [Param]	LR:	0.00018129
[2025-10-08 10:27:44] Epoch 38/50: Using 222/252 target samples (threshold=0.8367)
[2025-10-08 10:27:53] Stage2 - Epoch: [38 | 50]
[2025-10-08 10:27:53]   [Train]	Total Loss:	0.0316	CE Loss:	0.0184	Distill Loss:	0.0132
[2025-10-08 10:27:53]   [Train]	Acc:	1.0000
[2025-10-08 10:27:53]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:27:53]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:27:53]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:27:53]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:27:53]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:27:53]   [Param]	LR:	0.00015773
[2025-10-08 10:27:53] Epoch 39/50: Using 223/252 target samples (threshold=0.8337)
[2025-10-08 10:28:01] Stage2 - Epoch: [39 | 50]
[2025-10-08 10:28:01]   [Train]	Total Loss:	0.0341	CE Loss:	0.0180	Distill Loss:	0.0161
[2025-10-08 10:28:01]   [Train]	Acc:	1.0000
[2025-10-08 10:28:01]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:28:01]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:28:01]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:28:01]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:28:01]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:01]   [Param]	LR:	0.00013552
[2025-10-08 10:28:01] Epoch 40/50: Using 223/252 target samples (threshold=0.8306)
[2025-10-08 10:28:09] Stage2 - Epoch: [40 | 50]
[2025-10-08 10:28:09]   [Train]	Total Loss:	0.0331	CE Loss:	0.0197	Distill Loss:	0.0134
[2025-10-08 10:28:09]   [Train]	Acc:	1.0000
[2025-10-08 10:28:09]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:28:09]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:28:09]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:28:09]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:28:09]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:09]   [Param]	LR:	0.00011474
[2025-10-08 10:28:09] Epoch 41/50: Using 224/252 target samples (threshold=0.8276)
[2025-10-08 10:28:18] Stage2 - Epoch: [41 | 50]
[2025-10-08 10:28:18]   [Train]	Total Loss:	0.0395	CE Loss:	0.0250	Distill Loss:	0.0146
[2025-10-08 10:28:18]   [Train]	Acc:	1.0000
[2025-10-08 10:28:18]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:28:18]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:28:18]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:28:18]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:28:18]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:18]   [Param]	LR:	0.00009549
[2025-10-08 10:28:18] Epoch 42/50: Using 224/252 target samples (threshold=0.8245)
[2025-10-08 10:28:27] Stage2 - Epoch: [42 | 50]
[2025-10-08 10:28:27]   [Train]	Total Loss:	0.0543	CE Loss:	0.0285	Distill Loss:	0.0258
[2025-10-08 10:28:27]   [Train]	Acc:	0.9955
[2025-10-08 10:28:27]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:28:27]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:28:27]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:28:27]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:28:27]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:27]   [Param]	LR:	0.00007784
[2025-10-08 10:28:27] Epoch 43/50: Using 224/252 target samples (threshold=0.8214)
[2025-10-08 10:28:35] Stage2 - Epoch: [43 | 50]
[2025-10-08 10:28:35]   [Train]	Total Loss:	0.0395	CE Loss:	0.0213	Distill Loss:	0.0182
[2025-10-08 10:28:35]   [Train]	Acc:	1.0000
[2025-10-08 10:28:35]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:28:35]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:28:35]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:28:35]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:28:35]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:35]   [Param]	LR:	0.00006185
[2025-10-08 10:28:35] Epoch 44/50: Using 224/252 target samples (threshold=0.8184)
[2025-10-08 10:28:43] Stage2 - Epoch: [44 | 50]
[2025-10-08 10:28:43]   [Train]	Total Loss:	0.0624	CE Loss:	0.0329	Distill Loss:	0.0296
[2025-10-08 10:28:43]   [Train]	Acc:	0.9955
[2025-10-08 10:28:43]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:28:43]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:28:43]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:28:43]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:28:43]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:43]   [Param]	LR:	0.00004759
[2025-10-08 10:28:43] Epoch 45/50: Using 225/252 target samples (threshold=0.8153)
[2025-10-08 10:28:52] Stage2 - Epoch: [45 | 50]
[2025-10-08 10:28:52]   [Train]	Total Loss:	0.0688	CE Loss:	0.0379	Distill Loss:	0.0309
[2025-10-08 10:28:52]   [Train]	Acc:	0.9955
[2025-10-08 10:28:52]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:28:52]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:28:52]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:28:52]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:28:52]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:28:52]   [Param]	LR:	0.00003511
[2025-10-08 10:28:52] Epoch 46/50: Using 226/252 target samples (threshold=0.8122)
[2025-10-08 10:29:00] Stage2 - Epoch: [46 | 50]
[2025-10-08 10:29:00]   [Train]	Total Loss:	0.0355	CE Loss:	0.0192	Distill Loss:	0.0163
[2025-10-08 10:29:00]   [Train]	Acc:	1.0000
[2025-10-08 10:29:00]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:29:00]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:29:00]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:29:00]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:29:00]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:29:00]   [Param]	LR:	0.00002447
[2025-10-08 10:29:00] Epoch 47/50: Using 228/252 target samples (threshold=0.8092)
[2025-10-08 10:29:09] Stage2 - Epoch: [47 | 50]
[2025-10-08 10:29:09]   [Train]	Total Loss:	0.0475	CE Loss:	0.0253	Distill Loss:	0.0222
[2025-10-08 10:29:09]   [Train]	Acc:	0.9955
[2025-10-08 10:29:09]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:29:09]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:29:09]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:29:09]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:29:09]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:29:09]   [Param]	LR:	0.00001571
[2025-10-08 10:29:09] Epoch 48/50: Using 228/252 target samples (threshold=0.8061)
[2025-10-08 10:29:17] Stage2 - Epoch: [48 | 50]
[2025-10-08 10:29:17]   [Train]	Total Loss:	0.0430	CE Loss:	0.0238	Distill Loss:	0.0191
[2025-10-08 10:29:17]   [Train]	Acc:	0.9955
[2025-10-08 10:29:17]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:29:17]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:29:17]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:29:17]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:29:17]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:29:17]   [Param]	LR:	0.00000886
[2025-10-08 10:29:17] Epoch 49/50: Using 228/252 target samples (threshold=0.8031)
[2025-10-08 10:29:26] Stage2 - Epoch: [49 | 50]
[2025-10-08 10:29:26]   [Train]	Total Loss:	0.0449	CE Loss:	0.0266	Distill Loss:	0.0183
[2025-10-08 10:29:26]   [Train]	Acc:	0.9955
[2025-10-08 10:29:26]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:29:26]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:29:26]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:29:26]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:29:26]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:29:26]   [Param]	LR:	0.00000394
[2025-10-08 10:29:26] Epoch 50/50: Using 229/252 target samples (threshold=0.8000)
[2025-10-08 10:29:34] Stage2 - Epoch: [50 | 50]
[2025-10-08 10:29:34]   [Train]	Total Loss:	0.0371	CE Loss:	0.0194	Distill Loss:	0.0177
[2025-10-08 10:29:34]   [Train]	Acc:	1.0000
[2025-10-08 10:29:34]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:29:34]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:29:34]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:29:34]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:29:34]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:29:34]   [Param]	LR:	0.00000099
[2025-10-08 10:29:36] Model saved to output/cold_zone_to_hot_zone_10-8_10-20/best_model_stage2_audio.pth
[2025-10-08 10:29:36] Stage 2 Training Time: 00:07:05
[2025-10-08 10:29:36] Stage 2 Best Target Macro F1: 0.8163
