[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:34] MODEL COMPLEXITY
[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:34] FLOPs: 863.897M
[2025-10-08 10:43:34] Parameters: 72.142M
[2025-10-08 10:43:34]   FLOPs (exact): 863896576
[2025-10-08 10:43:34]   Parameters (exact): 72141700
[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:34] ABLATION EXPERIMENT CONFIGURATION
[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:34] WeightedRandomSampler: ENABLED
[2025-10-08 10:43:34] Focal Loss: DISABLED
[2025-10-08 10:43:34] Logit Adjustment: DISABLED
[2025-10-08 10:43:34] Label Smoothing: 0.98
[2025-10-08 10:43:34] Stage 2 Use Source Data: DISABLED
[2025-10-08 10:43:34] Stage 2 Sliding Window Filter: DISABLED
[2025-10-08 10:43:34] ============================================================
[2025-10-08 10:43:39] Stage1 - Epoch: [1 | 100]
[2025-10-08 10:43:39]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-08 10:43:39]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-08 10:43:39]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-08 10:43:39]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-08 10:43:39]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-08 10:43:39]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-08 10:43:39]   [Param]	LR:	0.00010000
[2025-10-08 10:43:42] Stage1 - Epoch: [2 | 100]
[2025-10-08 10:43:42]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-08 10:43:42]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-08 10:43:42]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-08 10:43:42]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-08 10:43:42]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-08 10:43:42]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-08 10:43:42]   [Param]	LR:	0.00009998
[2025-10-08 10:43:45] Stage1 - Epoch: [3 | 100]
[2025-10-08 10:43:45]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-08 10:43:45]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-08 10:43:45]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-08 10:43:45]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-08 10:43:45]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-08 10:43:45]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-08 10:43:45]   [Param]	LR:	0.00009990
[2025-10-08 10:43:49] Stage1 - Epoch: [4 | 100]
[2025-10-08 10:43:49]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-08 10:43:49]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-08 10:43:49]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-08 10:43:49]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-08 10:43:49]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-08 10:43:49]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-08 10:43:49]   [Param]	LR:	0.00009978
[2025-10-08 10:43:52] Stage1 - Epoch: [5 | 100]
[2025-10-08 10:43:52]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-08 10:43:52]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-08 10:43:52]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-08 10:43:52]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-08 10:43:52]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-08 10:43:52]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-08 10:43:52]   [Param]	LR:	0.00009961
[2025-10-08 10:43:55] Stage1 - Epoch: [6 | 100]
[2025-10-08 10:43:55]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-08 10:43:55]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-08 10:43:55]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-08 10:43:55]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-08 10:43:55]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-08 10:43:55]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-08 10:43:55]   [Param]	LR:	0.00009938
[2025-10-08 10:43:58] Stage1 - Epoch: [7 | 100]
[2025-10-08 10:43:58]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-08 10:43:58]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-08 10:43:58]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-08 10:43:58]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-08 10:43:58]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-08 10:43:58]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-08 10:43:58]   [Param]	LR:	0.00009911
[2025-10-08 10:44:01] Stage1 - Epoch: [8 | 100]
[2025-10-08 10:44:01]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-08 10:44:01]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-08 10:44:01]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-08 10:44:01]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-08 10:44:01]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-08 10:44:01]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-08 10:44:01]   [Param]	LR:	0.00009880
[2025-10-08 10:44:04] Stage1 - Epoch: [9 | 100]
[2025-10-08 10:44:04]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-08 10:44:04]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-08 10:44:04]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-08 10:44:04]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-08 10:44:04]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-08 10:44:04]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-08 10:44:04]   [Param]	LR:	0.00009843
[2025-10-08 10:44:07] Stage1 - Epoch: [10 | 100]
[2025-10-08 10:44:07]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-08 10:44:07]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-08 10:44:07]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:44:07]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:44:07]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:44:07]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:07]   [Param]	LR:	0.00009801
[2025-10-08 10:44:11] Stage1 - Epoch: [11 | 100]
[2025-10-08 10:44:11]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-08 10:44:11]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-08 10:44:11]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:44:11]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:44:11]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:44:11]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:44:11]   [Param]	LR:	0.00009755
[2025-10-08 10:44:14] Stage1 - Epoch: [12 | 100]
[2025-10-08 10:44:14]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-08 10:44:14]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-08 10:44:14]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-08 10:44:14]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-08 10:44:14]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-08 10:44:14]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:44:14]   [Param]	LR:	0.00009704
[2025-10-08 10:44:17] Stage1 - Epoch: [13 | 100]
[2025-10-08 10:44:17]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-08 10:44:17]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-08 10:44:17]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:44:17]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:44:17]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:44:17]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:17]   [Param]	LR:	0.00009649
[2025-10-08 10:44:20] Stage1 - Epoch: [14 | 100]
[2025-10-08 10:44:20]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-08 10:44:20]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-08 10:44:20]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:44:20]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:44:20]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:44:20]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:20]   [Param]	LR:	0.00009589
[2025-10-08 10:44:23] Stage1 - Epoch: [15 | 100]
[2025-10-08 10:44:23]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-08 10:44:23]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-08 10:44:23]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:44:23]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:44:23]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:44:23]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:44:23]   [Param]	LR:	0.00009524
[2025-10-08 10:44:26] Stage1 - Epoch: [16 | 100]
[2025-10-08 10:44:26]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-08 10:44:26]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-08 10:44:26]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-08 10:44:26]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-08 10:44:26]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-08 10:44:26]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-08 10:44:26]   [Param]	LR:	0.00009455
[2025-10-08 10:44:29] Stage1 - Epoch: [17 | 100]
[2025-10-08 10:44:29]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-08 10:44:29]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-08 10:44:29]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-08 10:44:29]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-08 10:44:29]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-08 10:44:29]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:29]   [Param]	LR:	0.00009382
[2025-10-08 10:44:32] Stage1 - Epoch: [18 | 100]
[2025-10-08 10:44:32]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-08 10:44:32]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-08 10:44:32]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:44:32]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:44:32]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:44:32]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:32]   [Param]	LR:	0.00009304
[2025-10-08 10:44:36] Stage1 - Epoch: [19 | 100]
[2025-10-08 10:44:36]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-08 10:44:36]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-08 10:44:36]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-08 10:44:36]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-08 10:44:36]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-08 10:44:36]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:36]   [Param]	LR:	0.00009222
[2025-10-08 10:44:39] Stage1 - Epoch: [20 | 100]
[2025-10-08 10:44:39]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-08 10:44:39]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-08 10:44:39]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:44:39]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:44:39]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:44:39]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:39]   [Param]	LR:	0.00009135
[2025-10-08 10:44:42] Stage1 - Epoch: [21 | 100]
[2025-10-08 10:44:42]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-08 10:44:42]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-08 10:44:42]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:44:42]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:44:42]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:44:42]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:42]   [Param]	LR:	0.00009045
[2025-10-08 10:44:45] Stage1 - Epoch: [22 | 100]
[2025-10-08 10:44:45]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-08 10:44:45]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-08 10:44:45]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:44:45]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:44:45]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:44:45]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:45]   [Param]	LR:	0.00008951
[2025-10-08 10:44:48] Stage1 - Epoch: [23 | 100]
[2025-10-08 10:44:48]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-08 10:44:48]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-08 10:44:48]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:44:48]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:44:48]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:44:48]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:48]   [Param]	LR:	0.00008853
[2025-10-08 10:44:51] Stage1 - Epoch: [24 | 100]
[2025-10-08 10:44:51]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-08 10:44:51]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-08 10:44:51]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-08 10:44:51]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-08 10:44:51]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-08 10:44:51]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:51]   [Param]	LR:	0.00008751
[2025-10-08 10:44:54] Stage1 - Epoch: [25 | 100]
[2025-10-08 10:44:54]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-08 10:44:54]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-08 10:44:54]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:44:54]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:44:54]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:44:54]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:54]   [Param]	LR:	0.00008645
[2025-10-08 10:44:57] Stage1 - Epoch: [26 | 100]
[2025-10-08 10:44:57]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-08 10:44:57]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-08 10:44:57]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:44:57]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:44:57]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:44:57]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:44:57]   [Param]	LR:	0.00008536
[2025-10-08 10:45:01] Stage1 - Epoch: [27 | 100]
[2025-10-08 10:45:01]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-08 10:45:01]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-08 10:45:01]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:45:01]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:45:01]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:45:01]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:01]   [Param]	LR:	0.00008423
[2025-10-08 10:45:04] Stage1 - Epoch: [28 | 100]
[2025-10-08 10:45:04]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-08 10:45:04]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-08 10:45:04]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:45:04]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:45:04]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:45:04]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:04]   [Param]	LR:	0.00008307
[2025-10-08 10:45:07] Stage1 - Epoch: [29 | 100]
[2025-10-08 10:45:07]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-08 10:45:07]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-08 10:45:07]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:45:07]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:45:07]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:45:07]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:07]   [Param]	LR:	0.00008187
[2025-10-08 10:45:10] Stage1 - Epoch: [30 | 100]
[2025-10-08 10:45:10]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-08 10:45:10]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-08 10:45:10]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-08 10:45:10]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-08 10:45:10]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-08 10:45:10]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:10]   [Param]	LR:	0.00008065
[2025-10-08 10:45:13] Stage1 - Epoch: [31 | 100]
[2025-10-08 10:45:13]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-08 10:45:13]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-08 10:45:13]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:45:13]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:45:13]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:45:13]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:13]   [Param]	LR:	0.00007939
[2025-10-08 10:45:16] Stage1 - Epoch: [32 | 100]
[2025-10-08 10:45:16]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-08 10:45:16]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-08 10:45:16]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:45:16]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:45:16]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:45:16]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:16]   [Param]	LR:	0.00007810
[2025-10-08 10:45:19] Stage1 - Epoch: [33 | 100]
[2025-10-08 10:45:19]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-08 10:45:19]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-08 10:45:19]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:45:19]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:45:19]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:45:19]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:19]   [Param]	LR:	0.00007679
[2025-10-08 10:45:22] Stage1 - Epoch: [34 | 100]
[2025-10-08 10:45:22]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-08 10:45:22]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-08 10:45:22]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:45:22]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:45:22]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:45:22]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:22]   [Param]	LR:	0.00007545
[2025-10-08 10:45:26] Stage1 - Epoch: [35 | 100]
[2025-10-08 10:45:26]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-08 10:45:26]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-08 10:45:26]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-08 10:45:26]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-08 10:45:26]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-08 10:45:26]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:26]   [Param]	LR:	0.00007409
[2025-10-08 10:45:29] Stage1 - Epoch: [36 | 100]
[2025-10-08 10:45:29]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-08 10:45:29]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-08 10:45:29]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-08 10:45:29]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-08 10:45:29]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-08 10:45:29]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-08 10:45:29]   [Param]	LR:	0.00007270
[2025-10-08 10:45:29] Early stopping triggered after 36 epochs.
[2025-10-08 10:45:30] Model saved to output/cold_zone_to_hot_zone_10-8_10-43/best_model_stage1_audio.pth
[2025-10-08 10:45:30] Stage 1 Training Time: 00:01:54
[2025-10-08 10:45:30] Stage 1 Best Macro F1: 0.9542
[2025-10-08 10:45:30] Starting pseudo-label precomputation for curriculum learning...
[2025-10-08 10:45:32] Confidence statistics - Min: 0.5086, Max: 0.9995, Mean: 0.9361, Median: 0.9801
[2025-10-08 10:45:32] Precomputed 252 samples with confidence scores
[2025-10-08 10:45:32] Epoch 1/30: Using 179/252 target samples (threshold=0.9500)
[2025-10-08 10:45:43] Stage2 - Epoch: [1 | 30]
[2025-10-08 10:45:43]   [Train]	Total Loss:	0.0223	CE Loss:	0.0171	Distill Loss:	0.0052
[2025-10-08 10:45:43]   [Train]	Acc:	1.0000
[2025-10-08 10:45:43]   [Test ]	Loss:	0.0000	Acc:	81.2500
[2025-10-08 10:45:43]   [Test ]	Micro F1:	0.8125	Macro F1:	0.7681
[2025-10-08 10:45:43]   [Cough   ]	F1:	0.6667	Precision:	0.6000	Recall:	0.7500
[2025-10-08 10:45:43]   [NonCough]	F1:	0.8696	Precision:	0.9091	Recall:	0.8333
[2025-10-08 10:45:43]   [Stats]	Many:	75.0000	Medium:	83.3333	Few:	0.0000
[2025-10-08 10:45:43]   [Param]	LR:	0.00100000
[2025-10-08 10:45:43] Epoch 2/30: Using 181/252 target samples (threshold=0.9448)
[2025-10-08 10:45:52] Stage2 - Epoch: [2 | 30]
[2025-10-08 10:45:52]   [Train]	Total Loss:	0.0153	CE Loss:	0.0078	Distill Loss:	0.0075
[2025-10-08 10:45:52]   [Train]	Acc:	1.0000
[2025-10-08 10:45:52]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:45:52]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:45:52]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:45:52]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:45:52]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:45:52]   [Param]	LR:	0.00099726
[2025-10-08 10:45:52] Epoch 3/30: Using 183/252 target samples (threshold=0.9397)
[2025-10-08 10:46:00] Stage2 - Epoch: [3 | 30]
[2025-10-08 10:46:00]   [Train]	Total Loss:	0.0163	CE Loss:	0.0067	Distill Loss:	0.0096
[2025-10-08 10:46:00]   [Train]	Acc:	1.0000
[2025-10-08 10:46:00]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:46:00]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:46:00]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:46:00]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:46:00]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:00]   [Param]	LR:	0.00098907
[2025-10-08 10:46:00] Epoch 4/30: Using 184/252 target samples (threshold=0.9345)
[2025-10-08 10:46:08] Stage2 - Epoch: [4 | 30]
[2025-10-08 10:46:08]   [Train]	Total Loss:	0.0561	CE Loss:	0.0282	Distill Loss:	0.0279
[2025-10-08 10:46:08]   [Train]	Acc:	0.9943
[2025-10-08 10:46:08]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:46:08]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:46:08]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:46:08]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:46:08]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:08]   [Param]	LR:	0.00097553
[2025-10-08 10:46:08] Epoch 5/30: Using 188/252 target samples (threshold=0.9293)
[2025-10-08 10:46:17] Stage2 - Epoch: [5 | 30]
[2025-10-08 10:46:17]   [Train]	Total Loss:	0.0230	CE Loss:	0.0066	Distill Loss:	0.0163
[2025-10-08 10:46:17]   [Train]	Acc:	1.0000
[2025-10-08 10:46:17]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:46:17]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:46:17]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:46:17]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:46:17]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:17]   [Param]	LR:	0.00095677
[2025-10-08 10:46:17] Epoch 6/30: Using 195/252 target samples (threshold=0.9241)
[2025-10-08 10:46:25] Stage2 - Epoch: [6 | 30]
[2025-10-08 10:46:25]   [Train]	Total Loss:	0.0246	CE Loss:	0.0061	Distill Loss:	0.0185
[2025-10-08 10:46:25]   [Train]	Acc:	1.0000
[2025-10-08 10:46:25]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:46:25]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:46:25]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:46:25]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:46:25]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:25]   [Param]	LR:	0.00093301
[2025-10-08 10:46:25] Epoch 7/30: Using 198/252 target samples (threshold=0.9190)
[2025-10-08 10:46:34] Stage2 - Epoch: [7 | 30]
[2025-10-08 10:46:34]   [Train]	Total Loss:	0.0261	CE Loss:	0.0098	Distill Loss:	0.0163
[2025-10-08 10:46:34]   [Train]	Acc:	1.0000
[2025-10-08 10:46:34]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:46:34]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:46:34]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:46:34]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:46:34]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:34]   [Param]	LR:	0.00090451
[2025-10-08 10:46:34] Epoch 8/30: Using 200/252 target samples (threshold=0.9138)
[2025-10-08 10:46:42] Stage2 - Epoch: [8 | 30]
[2025-10-08 10:46:42]   [Train]	Total Loss:	0.0230	CE Loss:	0.0097	Distill Loss:	0.0133
[2025-10-08 10:46:42]   [Train]	Acc:	1.0000
[2025-10-08 10:46:42]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:46:42]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:46:42]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:46:42]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:46:42]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:42]   [Param]	LR:	0.00087157
[2025-10-08 10:46:42] Epoch 9/30: Using 201/252 target samples (threshold=0.9086)
[2025-10-08 10:46:50] Stage2 - Epoch: [9 | 30]
[2025-10-08 10:46:50]   [Train]	Total Loss:	0.0214	CE Loss:	0.0111	Distill Loss:	0.0103
[2025-10-08 10:46:50]   [Train]	Acc:	1.0000
[2025-10-08 10:46:50]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:46:50]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:46:50]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:46:50]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:46:50]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:50]   [Param]	LR:	0.00083457
[2025-10-08 10:46:50] Epoch 10/30: Using 201/252 target samples (threshold=0.9034)
[2025-10-08 10:46:58] Stage2 - Epoch: [10 | 30]
[2025-10-08 10:46:58]   [Train]	Total Loss:	0.0220	CE Loss:	0.0118	Distill Loss:	0.0103
[2025-10-08 10:46:58]   [Train]	Acc:	1.0000
[2025-10-08 10:46:58]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:46:58]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:46:58]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:46:58]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:46:58]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:46:58]   [Param]	LR:	0.00079389
[2025-10-08 10:46:58] Epoch 11/30: Using 204/252 target samples (threshold=0.8983)
[2025-10-08 10:47:07] Stage2 - Epoch: [11 | 30]
[2025-10-08 10:47:07]   [Train]	Total Loss:	0.0229	CE Loss:	0.0126	Distill Loss:	0.0104
[2025-10-08 10:47:07]   [Train]	Acc:	1.0000
[2025-10-08 10:47:07]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:47:07]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:47:07]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:47:07]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:47:07]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:07]   [Param]	LR:	0.00075000
[2025-10-08 10:47:07] Epoch 12/30: Using 206/252 target samples (threshold=0.8931)
[2025-10-08 10:47:15] Stage2 - Epoch: [12 | 30]
[2025-10-08 10:47:15]   [Train]	Total Loss:	0.0277	CE Loss:	0.0137	Distill Loss:	0.0141
[2025-10-08 10:47:15]   [Train]	Acc:	1.0000
[2025-10-08 10:47:15]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:47:15]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:47:15]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:47:15]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:47:15]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:15]   [Param]	LR:	0.00070337
[2025-10-08 10:47:15] Epoch 13/30: Using 209/252 target samples (threshold=0.8879)
[2025-10-08 10:47:24] Stage2 - Epoch: [13 | 30]
[2025-10-08 10:47:24]   [Train]	Total Loss:	0.0280	CE Loss:	0.0102	Distill Loss:	0.0178
[2025-10-08 10:47:24]   [Train]	Acc:	1.0000
[2025-10-08 10:47:24]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:47:24]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:47:24]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:47:24]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:47:24]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:24]   [Param]	LR:	0.00065451
[2025-10-08 10:47:24] Epoch 14/30: Using 213/252 target samples (threshold=0.8828)
[2025-10-08 10:47:32] Stage2 - Epoch: [14 | 30]
[2025-10-08 10:47:32]   [Train]	Total Loss:	0.0262	CE Loss:	0.0151	Distill Loss:	0.0111
[2025-10-08 10:47:32]   [Train]	Acc:	1.0000
[2025-10-08 10:47:32]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:47:32]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:47:32]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:47:32]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:47:32]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:32]   [Param]	LR:	0.00060396
[2025-10-08 10:47:32] Epoch 15/30: Using 214/252 target samples (threshold=0.8776)
[2025-10-08 10:47:39] Stage2 - Epoch: [15 | 30]
[2025-10-08 10:47:39]   [Train]	Total Loss:	0.0279	CE Loss:	0.0170	Distill Loss:	0.0109
[2025-10-08 10:47:39]   [Train]	Acc:	1.0000
[2025-10-08 10:47:39]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:47:39]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:47:39]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:47:39]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:47:39]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:39]   [Param]	LR:	0.00055226
[2025-10-08 10:47:39] Epoch 16/30: Using 214/252 target samples (threshold=0.8724)
[2025-10-08 10:47:48] Stage2 - Epoch: [16 | 30]
[2025-10-08 10:47:48]   [Train]	Total Loss:	0.0297	CE Loss:	0.0185	Distill Loss:	0.0112
[2025-10-08 10:47:48]   [Train]	Acc:	1.0000
[2025-10-08 10:47:48]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:47:48]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:47:48]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:47:48]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:47:48]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:48]   [Param]	LR:	0.00050000
[2025-10-08 10:47:48] Epoch 17/30: Using 215/252 target samples (threshold=0.8672)
[2025-10-08 10:47:56] Stage2 - Epoch: [17 | 30]
[2025-10-08 10:47:56]   [Train]	Total Loss:	0.0510	CE Loss:	0.0281	Distill Loss:	0.0229
[2025-10-08 10:47:56]   [Train]	Acc:	0.9952
[2025-10-08 10:47:56]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:47:56]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:47:56]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:47:56]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:47:56]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:47:56]   [Param]	LR:	0.00044774
[2025-10-08 10:47:56] Epoch 18/30: Using 217/252 target samples (threshold=0.8621)
[2025-10-08 10:48:05] Stage2 - Epoch: [18 | 30]
[2025-10-08 10:48:05]   [Train]	Total Loss:	0.0319	CE Loss:	0.0145	Distill Loss:	0.0175
[2025-10-08 10:48:05]   [Train]	Acc:	1.0000
[2025-10-08 10:48:05]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:05]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:05]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:05]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:05]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:05]   [Param]	LR:	0.00039604
[2025-10-08 10:48:05] Epoch 19/30: Using 218/252 target samples (threshold=0.8569)
[2025-10-08 10:48:14] Stage2 - Epoch: [19 | 30]
[2025-10-08 10:48:14]   [Train]	Total Loss:	0.0431	CE Loss:	0.0191	Distill Loss:	0.0240
[2025-10-08 10:48:14]   [Train]	Acc:	0.9952
[2025-10-08 10:48:14]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:14]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:14]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:14]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:14]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:14]   [Param]	LR:	0.00034549
[2025-10-08 10:48:14] Epoch 20/30: Using 220/252 target samples (threshold=0.8517)
[2025-10-08 10:48:22] Stage2 - Epoch: [20 | 30]
[2025-10-08 10:48:22]   [Train]	Total Loss:	0.1050	CE Loss:	0.0560	Distill Loss:	0.0490
[2025-10-08 10:48:22]   [Train]	Acc:	0.9904
[2025-10-08 10:48:22]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:22]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:22]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:22]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:22]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:22]   [Param]	LR:	0.00029663
[2025-10-08 10:48:22] Epoch 21/30: Using 220/252 target samples (threshold=0.8466)
[2025-10-08 10:48:31] Stage2 - Epoch: [21 | 30]
[2025-10-08 10:48:31]   [Train]	Total Loss:	0.0912	CE Loss:	0.0452	Distill Loss:	0.0460
[2025-10-08 10:48:31]   [Train]	Acc:	0.9904
[2025-10-08 10:48:31]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:31]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:31]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:31]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:31]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:31]   [Param]	LR:	0.00025000
[2025-10-08 10:48:31] Epoch 22/30: Using 220/252 target samples (threshold=0.8414)
[2025-10-08 10:48:40] Stage2 - Epoch: [22 | 30]
[2025-10-08 10:48:40]   [Train]	Total Loss:	0.0318	CE Loss:	0.0140	Distill Loss:	0.0178
[2025-10-08 10:48:40]   [Train]	Acc:	1.0000
[2025-10-08 10:48:40]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:40]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:40]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:40]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:40]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:40]   [Param]	LR:	0.00020611
[2025-10-08 10:48:40] Epoch 23/30: Using 222/252 target samples (threshold=0.8362)
[2025-10-08 10:48:48] Stage2 - Epoch: [23 | 30]
[2025-10-08 10:48:48]   [Train]	Total Loss:	0.0385	CE Loss:	0.0206	Distill Loss:	0.0179
[2025-10-08 10:48:48]   [Train]	Acc:	0.9952
[2025-10-08 10:48:48]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:48:48]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:48:48]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:48:48]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:48:48]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:48]   [Param]	LR:	0.00016543
[2025-10-08 10:48:48] Epoch 24/30: Using 223/252 target samples (threshold=0.8310)
[2025-10-08 10:48:56] Stage2 - Epoch: [24 | 30]
[2025-10-08 10:48:56]   [Train]	Total Loss:	0.0857	CE Loss:	0.0470	Distill Loss:	0.0387
[2025-10-08 10:48:56]   [Train]	Acc:	0.9952
[2025-10-08 10:48:56]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:48:56]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:48:56]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:48:56]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:48:56]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:48:56]   [Param]	LR:	0.00012843
[2025-10-08 10:48:56] Epoch 25/30: Using 224/252 target samples (threshold=0.8259)
[2025-10-08 10:49:05] Stage2 - Epoch: [25 | 30]
[2025-10-08 10:49:05]   [Train]	Total Loss:	0.0598	CE Loss:	0.0325	Distill Loss:	0.0273
[2025-10-08 10:49:05]   [Train]	Acc:	0.9955
[2025-10-08 10:49:05]   [Test ]	Loss:	0.0000	Acc:	85.9375
[2025-10-08 10:49:05]   [Test ]	Micro F1:	0.8594	Macro F1:	0.8163
[2025-10-08 10:49:05]   [Cough   ]	F1:	0.7273	Precision:	0.7059	Recall:	0.7500
[2025-10-08 10:49:05]   [NonCough]	F1:	0.9053	Precision:	0.9149	Recall:	0.8958
[2025-10-08 10:49:05]   [Stats]	Many:	75.0000	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:05]   [Param]	LR:	0.00009549
[2025-10-08 10:49:05] Epoch 26/30: Using 224/252 target samples (threshold=0.8207)
[2025-10-08 10:49:14] Stage2 - Epoch: [26 | 30]
[2025-10-08 10:49:14]   [Train]	Total Loss:	0.0439	CE Loss:	0.0259	Distill Loss:	0.0180
[2025-10-08 10:49:14]   [Train]	Acc:	0.9955
[2025-10-08 10:49:14]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:49:14]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:49:14]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:49:14]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:49:14]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:14]   [Param]	LR:	0.00006699
[2025-10-08 10:49:14] Epoch 27/30: Using 224/252 target samples (threshold=0.8155)
[2025-10-08 10:49:22] Stage2 - Epoch: [27 | 30]
[2025-10-08 10:49:22]   [Train]	Total Loss:	0.0361	CE Loss:	0.0191	Distill Loss:	0.0171
[2025-10-08 10:49:22]   [Train]	Acc:	1.0000
[2025-10-08 10:49:22]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:49:22]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:49:22]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:49:22]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:49:22]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:22]   [Param]	LR:	0.00004323
[2025-10-08 10:49:22] Epoch 28/30: Using 226/252 target samples (threshold=0.8103)
[2025-10-08 10:49:32] Stage2 - Epoch: [28 | 30]
[2025-10-08 10:49:32]   [Train]	Total Loss:	0.0558	CE Loss:	0.0259	Distill Loss:	0.0299
[2025-10-08 10:49:32]   [Train]	Acc:	0.9955
[2025-10-08 10:49:32]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:49:32]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:49:32]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:49:32]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:49:32]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:32]   [Param]	LR:	0.00002447
[2025-10-08 10:49:32] Epoch 29/30: Using 228/252 target samples (threshold=0.8052)
[2025-10-08 10:49:40] Stage2 - Epoch: [29 | 30]
[2025-10-08 10:49:40]   [Train]	Total Loss:	0.0398	CE Loss:	0.0201	Distill Loss:	0.0198
[2025-10-08 10:49:40]   [Train]	Acc:	1.0000
[2025-10-08 10:49:40]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:49:40]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:49:40]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:49:40]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:49:40]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:40]   [Param]	LR:	0.00001093
[2025-10-08 10:49:40] Epoch 30/30: Using 229/252 target samples (threshold=0.8000)
[2025-10-08 10:49:48] Stage2 - Epoch: [30 | 30]
[2025-10-08 10:49:48]   [Train]	Total Loss:	0.0501	CE Loss:	0.0294	Distill Loss:	0.0206
[2025-10-08 10:49:48]   [Train]	Acc:	0.9955
[2025-10-08 10:49:48]   [Test ]	Loss:	0.0000	Acc:	84.3750
[2025-10-08 10:49:48]   [Test ]	Micro F1:	0.8438	Macro F1:	0.7917
[2025-10-08 10:49:48]   [Cough   ]	F1:	0.6875	Precision:	0.6875	Recall:	0.6875
[2025-10-08 10:49:48]   [NonCough]	F1:	0.8958	Precision:	0.8958	Recall:	0.8958
[2025-10-08 10:49:48]   [Stats]	Many:	68.7500	Medium:	89.5833	Few:	0.0000
[2025-10-08 10:49:48]   [Param]	LR:	0.00000274
[2025-10-08 10:49:51] Model saved to output/cold_zone_to_hot_zone_10-8_10-43/best_model_stage2_audio.pth
[2025-10-08 10:49:51] Stage 2 Training Time: 00:04:16
[2025-10-08 10:49:51] Stage 2 Best Target Macro F1: 0.8163
