[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:03] MODEL COMPLEXITY
[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:03] FLOPs: 863.897M
[2025-10-29 10:47:03] Parameters: 72.142M
[2025-10-29 10:47:03]   FLOPs (exact): 863896576
[2025-10-29 10:47:03]   Parameters (exact): 72141700
[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:03] ABLATION EXPERIMENT CONFIGURATION
[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:03] WeightedRandomSampler: ENABLED
[2025-10-29 10:47:03] Focal Loss: DISABLED
[2025-10-29 10:47:03] Logit Adjustment: DISABLED
[2025-10-29 10:47:03] Label Smoothing: 0.98
[2025-10-29 10:47:03] Stage 2 Use Source Data: DISABLED
[2025-10-29 10:47:03] Stage 2 Sliding Window Filter: DISABLED
[2025-10-29 10:47:03] ============================================================
[2025-10-29 10:47:08] Stage1 - Epoch: [1 | 100]
[2025-10-29 10:47:08]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-29 10:47:08]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-29 10:47:08]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-29 10:47:08]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-29 10:47:08]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-29 10:47:08]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-29 10:47:08]   [Param]	LR:	0.00010000
[2025-10-29 10:47:12] Stage1 - Epoch: [2 | 100]
[2025-10-29 10:47:12]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-29 10:47:12]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-29 10:47:12]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-29 10:47:12]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-29 10:47:12]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-29 10:47:12]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-29 10:47:12]   [Param]	LR:	0.00009998
[2025-10-29 10:47:16] Stage1 - Epoch: [3 | 100]
[2025-10-29 10:47:16]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-29 10:47:16]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-29 10:47:16]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-29 10:47:16]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-29 10:47:16]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-29 10:47:16]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-29 10:47:16]   [Param]	LR:	0.00009990
[2025-10-29 10:47:20] Stage1 - Epoch: [4 | 100]
[2025-10-29 10:47:20]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-29 10:47:20]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-29 10:47:20]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-29 10:47:20]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-29 10:47:20]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-29 10:47:20]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-29 10:47:20]   [Param]	LR:	0.00009978
[2025-10-29 10:47:24] Stage1 - Epoch: [5 | 100]
[2025-10-29 10:47:24]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-29 10:47:24]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-29 10:47:24]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-29 10:47:24]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-29 10:47:24]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-29 10:47:24]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-29 10:47:24]   [Param]	LR:	0.00009961
[2025-10-29 10:47:28] Stage1 - Epoch: [6 | 100]
[2025-10-29 10:47:28]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-29 10:47:28]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-29 10:47:28]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-29 10:47:28]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-29 10:47:28]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-29 10:47:28]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-29 10:47:28]   [Param]	LR:	0.00009938
[2025-10-29 10:47:32] Stage1 - Epoch: [7 | 100]
[2025-10-29 10:47:32]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-29 10:47:32]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-29 10:47:32]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-29 10:47:32]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-29 10:47:32]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-29 10:47:32]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-29 10:47:32]   [Param]	LR:	0.00009911
[2025-10-29 10:47:36] Stage1 - Epoch: [8 | 100]
[2025-10-29 10:47:36]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-29 10:47:36]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-29 10:47:36]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-29 10:47:36]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-29 10:47:36]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-29 10:47:36]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-29 10:47:36]   [Param]	LR:	0.00009880
[2025-10-29 10:47:40] Stage1 - Epoch: [9 | 100]
[2025-10-29 10:47:40]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-29 10:47:40]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-29 10:47:40]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-29 10:47:40]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-29 10:47:40]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-29 10:47:40]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-29 10:47:40]   [Param]	LR:	0.00009843
[2025-10-29 10:47:44] Stage1 - Epoch: [10 | 100]
[2025-10-29 10:47:44]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-29 10:47:44]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-29 10:47:44]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:47:44]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:47:44]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:47:44]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:47:44]   [Param]	LR:	0.00009801
[2025-10-29 10:47:49] Stage1 - Epoch: [11 | 100]
[2025-10-29 10:47:49]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-29 10:47:49]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-29 10:47:49]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:47:49]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:47:49]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:47:49]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:47:49]   [Param]	LR:	0.00009755
[2025-10-29 10:47:53] Stage1 - Epoch: [12 | 100]
[2025-10-29 10:47:53]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-29 10:47:53]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-29 10:47:53]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-29 10:47:53]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-29 10:47:53]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-29 10:47:53]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:47:53]   [Param]	LR:	0.00009704
[2025-10-29 10:47:57] Stage1 - Epoch: [13 | 100]
[2025-10-29 10:47:57]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-29 10:47:57]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-29 10:47:57]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:47:57]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:47:57]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:47:57]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:47:57]   [Param]	LR:	0.00009649
[2025-10-29 10:48:01] Stage1 - Epoch: [14 | 100]
[2025-10-29 10:48:01]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-29 10:48:01]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-29 10:48:01]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:48:01]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:48:01]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:48:01]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:01]   [Param]	LR:	0.00009589
[2025-10-29 10:48:05] Stage1 - Epoch: [15 | 100]
[2025-10-29 10:48:05]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-29 10:48:05]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-29 10:48:05]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:48:05]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:48:05]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:48:05]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:48:05]   [Param]	LR:	0.00009524
[2025-10-29 10:48:09] Stage1 - Epoch: [16 | 100]
[2025-10-29 10:48:09]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-29 10:48:09]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-29 10:48:09]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:48:09]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:48:09]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:48:09]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:48:09]   [Param]	LR:	0.00009455
[2025-10-29 10:48:13] Stage1 - Epoch: [17 | 100]
[2025-10-29 10:48:13]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-29 10:48:13]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-29 10:48:13]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 10:48:13]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 10:48:13]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 10:48:13]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:13]   [Param]	LR:	0.00009382
[2025-10-29 10:48:18] Stage1 - Epoch: [18 | 100]
[2025-10-29 10:48:18]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-29 10:48:18]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 10:48:18]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:48:18]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:48:18]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:48:18]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:18]   [Param]	LR:	0.00009304
[2025-10-29 10:48:22] Stage1 - Epoch: [19 | 100]
[2025-10-29 10:48:22]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-29 10:48:22]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-29 10:48:22]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 10:48:22]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 10:48:22]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 10:48:22]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:22]   [Param]	LR:	0.00009222
[2025-10-29 10:48:26] Stage1 - Epoch: [20 | 100]
[2025-10-29 10:48:26]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-29 10:48:26]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-29 10:48:26]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:48:26]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:48:26]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:48:26]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:26]   [Param]	LR:	0.00009135
[2025-10-29 10:48:30] Stage1 - Epoch: [21 | 100]
[2025-10-29 10:48:30]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-29 10:48:30]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-29 10:48:30]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:48:30]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:48:30]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:48:30]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:30]   [Param]	LR:	0.00009045
[2025-10-29 10:48:34] Stage1 - Epoch: [22 | 100]
[2025-10-29 10:48:34]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-29 10:48:34]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-29 10:48:34]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:48:34]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:48:34]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:48:34]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:34]   [Param]	LR:	0.00008951
[2025-10-29 10:48:38] Stage1 - Epoch: [23 | 100]
[2025-10-29 10:48:38]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-29 10:48:38]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-29 10:48:38]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:48:38]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:48:38]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:48:38]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:38]   [Param]	LR:	0.00008853
[2025-10-29 10:48:43] Stage1 - Epoch: [24 | 100]
[2025-10-29 10:48:43]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-29 10:48:43]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-29 10:48:43]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-29 10:48:43]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-29 10:48:43]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-29 10:48:43]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:43]   [Param]	LR:	0.00008751
[2025-10-29 10:48:47] Stage1 - Epoch: [25 | 100]
[2025-10-29 10:48:47]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-29 10:48:47]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 10:48:47]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:48:47]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:48:47]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:48:47]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:47]   [Param]	LR:	0.00008645
[2025-10-29 10:48:51] Stage1 - Epoch: [26 | 100]
[2025-10-29 10:48:51]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-29 10:48:51]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-29 10:48:51]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:48:51]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:48:51]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:48:51]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:51]   [Param]	LR:	0.00008536
[2025-10-29 10:48:55] Stage1 - Epoch: [27 | 100]
[2025-10-29 10:48:55]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-29 10:48:55]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-29 10:48:55]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:48:55]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:48:55]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:48:55]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:55]   [Param]	LR:	0.00008423
[2025-10-29 10:48:59] Stage1 - Epoch: [28 | 100]
[2025-10-29 10:48:59]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-29 10:48:59]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-29 10:48:59]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:48:59]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:48:59]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:48:59]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:48:59]   [Param]	LR:	0.00008307
[2025-10-29 10:49:04] Stage1 - Epoch: [29 | 100]
[2025-10-29 10:49:04]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-29 10:49:04]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-29 10:49:04]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:49:04]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:49:04]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:49:04]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:04]   [Param]	LR:	0.00008187
[2025-10-29 10:49:08] Stage1 - Epoch: [30 | 100]
[2025-10-29 10:49:08]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-29 10:49:08]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-29 10:49:08]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:49:08]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:49:08]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:49:08]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:08]   [Param]	LR:	0.00008065
[2025-10-29 10:49:12] Stage1 - Epoch: [31 | 100]
[2025-10-29 10:49:12]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-29 10:49:12]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-29 10:49:12]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:49:12]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:49:12]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:49:12]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:12]   [Param]	LR:	0.00007939
[2025-10-29 10:49:16] Stage1 - Epoch: [32 | 100]
[2025-10-29 10:49:16]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-29 10:49:16]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-29 10:49:16]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:49:16]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:49:16]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:49:16]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:16]   [Param]	LR:	0.00007810
[2025-10-29 10:49:20] Stage1 - Epoch: [33 | 100]
[2025-10-29 10:49:20]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-29 10:49:20]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-29 10:49:20]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:49:20]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:49:20]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:49:20]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:20]   [Param]	LR:	0.00007679
[2025-10-29 10:49:24] Stage1 - Epoch: [34 | 100]
[2025-10-29 10:49:24]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-29 10:49:24]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-29 10:49:24]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:49:24]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:49:24]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:49:24]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:24]   [Param]	LR:	0.00007545
[2025-10-29 10:49:29] Stage1 - Epoch: [35 | 100]
[2025-10-29 10:49:29]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-29 10:49:29]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-29 10:49:29]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:49:29]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:49:29]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:49:29]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:29]   [Param]	LR:	0.00007409
[2025-10-29 10:49:33] Stage1 - Epoch: [36 | 100]
[2025-10-29 10:49:33]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-29 10:49:33]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-29 10:49:33]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:49:33]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:49:33]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:49:33]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:49:33]   [Param]	LR:	0.00007270
[2025-10-29 10:49:33] Early stopping triggered after 36 epochs.
[2025-10-29 10:49:34] Model saved to output/cold_zone_to_hot_zone_fine_10-29_10-47/best_model_stage1_audio.pth
[2025-10-29 10:49:34] F1 score plot for stage1 saved to output/cold_zone_to_hot_zone_fine_10-29_10-47/stage1_macro_f1.png
[2025-10-29 10:49:34] Stage 1 Training Time: 00:02:29
[2025-10-29 10:49:34] Stage 1 Best Macro F1: 0.9542
[2025-10-29 10:49:34] Starting pseudo-label precomputation for curriculum learning...
[2025-10-29 10:49:35] Confidence statistics - Min: 0.5020, Max: 0.9998, Mean: 0.8990, Median: 0.9663
[2025-10-29 10:49:35] Precomputed 649 samples with confidence scores
[2025-10-29 10:49:35] Epoch 1/30: Using 495/649 target samples (threshold=0.8500)
[2025-10-29 10:49:40] Stage2 - Epoch: [1 | 30]
[2025-10-29 10:49:40]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:40]   [Train]	Acc:	0.2958
[2025-10-29 10:49:40]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:40]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:40]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:40]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:40]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:40]   [Param]	LR:	0.00100000
[2025-10-29 10:49:40] Epoch 2/30: Using 499/649 target samples (threshold=0.8448)
[2025-10-29 10:49:44] Stage2 - Epoch: [2 | 30]
[2025-10-29 10:49:44]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:44]   [Train]	Acc:	0.0786
[2025-10-29 10:49:44]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:44]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:44]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:44]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:44]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:44]   [Param]	LR:	0.00099726
[2025-10-29 10:49:44] Epoch 3/30: Using 504/649 target samples (threshold=0.8397)
[2025-10-29 10:49:47] Stage2 - Epoch: [3 | 30]
[2025-10-29 10:49:47]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:47]   [Train]	Acc:	0.0847
[2025-10-29 10:49:47]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:47]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:47]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:47]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:47]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:47]   [Param]	LR:	0.00098907
[2025-10-29 10:49:47] Epoch 4/30: Using 506/649 target samples (threshold=0.8345)
[2025-10-29 10:49:51] Stage2 - Epoch: [4 | 30]
[2025-10-29 10:49:51]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:51]   [Train]	Acc:	0.0847
[2025-10-29 10:49:51]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:51]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:51]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:51]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:51]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:51]   [Param]	LR:	0.00097553
[2025-10-29 10:49:51] Epoch 5/30: Using 509/649 target samples (threshold=0.8293)
[2025-10-29 10:49:54] Stage2 - Epoch: [5 | 30]
[2025-10-29 10:49:54]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:54]   [Train]	Acc:	0.0887
[2025-10-29 10:49:54]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:54]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:54]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:54]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:54]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:54]   [Param]	LR:	0.00095677
[2025-10-29 10:49:54] Epoch 6/30: Using 511/649 target samples (threshold=0.8241)
[2025-10-29 10:49:57] Stage2 - Epoch: [6 | 30]
[2025-10-29 10:49:57]   [Train]	Total Loss:	nan	CE Loss:	nan	Distill Loss:	nan
[2025-10-29 10:49:57]   [Train]	Acc:	0.0927
[2025-10-29 10:49:57]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:49:57]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:49:57]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:49:57]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:49:57]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:49:57]   [Param]	LR:	0.00093301
[2025-10-29 10:49:57] Epoch 7/30: Using 512/649 target samples (threshold=0.8190)
[2025-10-29 10:50:01] Stage2 - Epoch: [7 | 30]
[2025-10-29 10:50:01]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:01]   [Train]	Acc:	1.0000
[2025-10-29 10:50:01]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:01]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:01]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:01]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:01]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:01]   [Param]	LR:	0.00090451
[2025-10-29 10:50:01] Epoch 8/30: Using 518/649 target samples (threshold=0.8138)
[2025-10-29 10:50:04] Stage2 - Epoch: [8 | 30]
[2025-10-29 10:50:04]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:04]   [Train]	Acc:	1.0000
[2025-10-29 10:50:04]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:04]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:04]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:04]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:04]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:04]   [Param]	LR:	0.00087157
[2025-10-29 10:50:04] Epoch 9/30: Using 520/649 target samples (threshold=0.8086)
[2025-10-29 10:50:08] Stage2 - Epoch: [9 | 30]
[2025-10-29 10:50:08]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:08]   [Train]	Acc:	1.0000
[2025-10-29 10:50:08]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:08]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:08]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:08]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:08]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:08]   [Param]	LR:	0.00083457
[2025-10-29 10:50:08] Epoch 10/30: Using 523/649 target samples (threshold=0.8034)
[2025-10-29 10:50:11] Stage2 - Epoch: [10 | 30]
[2025-10-29 10:50:11]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:11]   [Train]	Acc:	1.0000
[2025-10-29 10:50:11]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:11]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:11]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:11]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:11]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:11]   [Param]	LR:	0.00079389
[2025-10-29 10:50:11] Epoch 11/30: Using 524/649 target samples (threshold=0.7983)
[2025-10-29 10:50:15] Stage2 - Epoch: [11 | 30]
[2025-10-29 10:50:15]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:15]   [Train]	Acc:	1.0000
[2025-10-29 10:50:15]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:15]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:15]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:15]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:15]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:15]   [Param]	LR:	0.00075000
[2025-10-29 10:50:15] Epoch 12/30: Using 525/649 target samples (threshold=0.7931)
[2025-10-29 10:50:18] Stage2 - Epoch: [12 | 30]
[2025-10-29 10:50:18]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:18]   [Train]	Acc:	1.0000
[2025-10-29 10:50:18]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:18]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:18]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:18]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:18]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:18]   [Param]	LR:	0.00070337
[2025-10-29 10:50:18] Epoch 13/30: Using 527/649 target samples (threshold=0.7879)
[2025-10-29 10:50:21] Stage2 - Epoch: [13 | 30]
[2025-10-29 10:50:21]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:21]   [Train]	Acc:	1.0000
[2025-10-29 10:50:21]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:21]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:21]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:21]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:21]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:21]   [Param]	LR:	0.00065451
[2025-10-29 10:50:21] Epoch 14/30: Using 531/649 target samples (threshold=0.7828)
[2025-10-29 10:50:25] Stage2 - Epoch: [14 | 30]
[2025-10-29 10:50:25]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:25]   [Train]	Acc:	1.0000
[2025-10-29 10:50:25]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:25]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:25]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:25]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:25]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:25]   [Param]	LR:	0.00060396
[2025-10-29 10:50:25] Epoch 15/30: Using 532/649 target samples (threshold=0.7776)
[2025-10-29 10:50:29] Stage2 - Epoch: [15 | 30]
[2025-10-29 10:50:29]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:29]   [Train]	Acc:	1.0000
[2025-10-29 10:50:29]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:29]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:29]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:29]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:29]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:29]   [Param]	LR:	0.00055226
[2025-10-29 10:50:29] Epoch 16/30: Using 533/649 target samples (threshold=0.7724)
[2025-10-29 10:50:32] Stage2 - Epoch: [16 | 30]
[2025-10-29 10:50:32]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:32]   [Train]	Acc:	1.0000
[2025-10-29 10:50:32]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:32]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:32]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:32]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:32]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:32]   [Param]	LR:	0.00050000
[2025-10-29 10:50:32] Epoch 17/30: Using 534/649 target samples (threshold=0.7672)
[2025-10-29 10:50:35] Stage2 - Epoch: [17 | 30]
[2025-10-29 10:50:35]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:35]   [Train]	Acc:	1.0000
[2025-10-29 10:50:35]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:35]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:35]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:35]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:35]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:35]   [Param]	LR:	0.00044774
[2025-10-29 10:50:35] Epoch 18/30: Using 535/649 target samples (threshold=0.7621)
[2025-10-29 10:50:39] Stage2 - Epoch: [18 | 30]
[2025-10-29 10:50:39]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:39]   [Train]	Acc:	1.0000
[2025-10-29 10:50:39]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:39]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:39]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:39]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:39]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:39]   [Param]	LR:	0.00039604
[2025-10-29 10:50:39] Epoch 19/30: Using 536/649 target samples (threshold=0.7569)
[2025-10-29 10:50:43] Stage2 - Epoch: [19 | 30]
[2025-10-29 10:50:43]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:43]   [Train]	Acc:	1.0000
[2025-10-29 10:50:43]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:43]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:43]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:43]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:43]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:43]   [Param]	LR:	0.00034549
[2025-10-29 10:50:43] Epoch 20/30: Using 536/649 target samples (threshold=0.7517)
[2025-10-29 10:50:46] Stage2 - Epoch: [20 | 30]
[2025-10-29 10:50:46]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:46]   [Train]	Acc:	1.0000
[2025-10-29 10:50:46]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:46]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:46]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:46]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:46]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:46]   [Param]	LR:	0.00029663
[2025-10-29 10:50:46] Epoch 21/30: Using 539/649 target samples (threshold=0.7466)
[2025-10-29 10:50:50] Stage2 - Epoch: [21 | 30]
[2025-10-29 10:50:50]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:50]   [Train]	Acc:	1.0000
[2025-10-29 10:50:50]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:50]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:50]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:50]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:50]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:50]   [Param]	LR:	0.00025000
[2025-10-29 10:50:50] Epoch 22/30: Using 544/649 target samples (threshold=0.7414)
[2025-10-29 10:50:53] Stage2 - Epoch: [22 | 30]
[2025-10-29 10:50:53]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:53]   [Train]	Acc:	1.0000
[2025-10-29 10:50:53]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:53]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:53]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:53]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:53]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:53]   [Param]	LR:	0.00020611
[2025-10-29 10:50:53] Epoch 23/30: Using 546/649 target samples (threshold=0.7362)
[2025-10-29 10:50:57] Stage2 - Epoch: [23 | 30]
[2025-10-29 10:50:57]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:50:57]   [Train]	Acc:	1.0000
[2025-10-29 10:50:57]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:50:57]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:50:57]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:50:57]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:50:57]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:50:57]   [Param]	LR:	0.00016543
[2025-10-29 10:50:57] Epoch 24/30: Using 548/649 target samples (threshold=0.7310)
[2025-10-29 10:51:01] Stage2 - Epoch: [24 | 30]
[2025-10-29 10:51:01]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:01]   [Train]	Acc:	1.0000
[2025-10-29 10:51:01]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:01]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:01]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:01]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:01]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:01]   [Param]	LR:	0.00012843
[2025-10-29 10:51:01] Epoch 25/30: Using 552/649 target samples (threshold=0.7259)
[2025-10-29 10:51:04] Stage2 - Epoch: [25 | 30]
[2025-10-29 10:51:04]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:04]   [Train]	Acc:	1.0000
[2025-10-29 10:51:04]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:04]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:04]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:04]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:04]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:04]   [Param]	LR:	0.00009549
[2025-10-29 10:51:04] Epoch 26/30: Using 554/649 target samples (threshold=0.7207)
[2025-10-29 10:51:08] Stage2 - Epoch: [26 | 30]
[2025-10-29 10:51:08]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:08]   [Train]	Acc:	1.0000
[2025-10-29 10:51:08]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:08]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:08]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:08]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:08]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:08]   [Param]	LR:	0.00006699
[2025-10-29 10:51:08] Epoch 27/30: Using 557/649 target samples (threshold=0.7155)
[2025-10-29 10:51:11] Stage2 - Epoch: [27 | 30]
[2025-10-29 10:51:11]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:11]   [Train]	Acc:	1.0000
[2025-10-29 10:51:11]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:11]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:11]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:11]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:11]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:11]   [Param]	LR:	0.00004323
[2025-10-29 10:51:11] Epoch 28/30: Using 558/649 target samples (threshold=0.7103)
[2025-10-29 10:51:15] Stage2 - Epoch: [28 | 30]
[2025-10-29 10:51:15]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:15]   [Train]	Acc:	1.0000
[2025-10-29 10:51:15]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:15]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:15]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:15]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:15]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:15]   [Param]	LR:	0.00002447
[2025-10-29 10:51:15] Epoch 29/30: Using 562/649 target samples (threshold=0.7052)
[2025-10-29 10:51:18] Stage2 - Epoch: [29 | 30]
[2025-10-29 10:51:18]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:18]   [Train]	Acc:	1.0000
[2025-10-29 10:51:18]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:18]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:18]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:18]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:18]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:18]   [Param]	LR:	0.00001093
[2025-10-29 10:51:18] Epoch 30/30: Using 564/649 target samples (threshold=0.7000)
[2025-10-29 10:51:22] Stage2 - Epoch: [30 | 30]
[2025-10-29 10:51:22]   [Train]	Total Loss:	nan	CE Loss:	0.0000	Distill Loss:	nan
[2025-10-29 10:51:22]   [Train]	Acc:	1.0000
[2025-10-29 10:51:22]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-29 10:51:22]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-29 10:51:22]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-29 10:51:22]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:51:22]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-29 10:51:22]   [Param]	LR:	0.00000274
[2025-10-29 10:51:23] Model saved to output/cold_zone_to_hot_zone_fine_10-29_10-47/best_model_stage2_audio.pth
[2025-10-29 10:51:24] F1 score plot for stage2 saved to output/cold_zone_to_hot_zone_fine_10-29_10-47/stage2_macro_f1.png
[2025-10-29 10:51:24] Stage 2 Training Time: 00:01:46
[2025-10-29 10:51:24] Stage 2 Best Target Macro F1: 0.3292
