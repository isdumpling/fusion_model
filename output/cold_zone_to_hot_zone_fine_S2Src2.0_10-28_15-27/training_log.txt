[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:31] MODEL COMPLEXITY
[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:31] FLOPs: 863.897M
[2025-10-28 15:27:31] Parameters: 72.142M
[2025-10-28 15:27:31]   FLOPs (exact): 863896576
[2025-10-28 15:27:31]   Parameters (exact): 72141700
[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:31] ABLATION EXPERIMENT CONFIGURATION
[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:31] WeightedRandomSampler: ENABLED
[2025-10-28 15:27:31] Focal Loss: DISABLED
[2025-10-28 15:27:31] Logit Adjustment: DISABLED
[2025-10-28 15:27:31] Label Smoothing: 0.98
[2025-10-28 15:27:31] Stage 2 Use Source Data: ENABLED
[2025-10-28 15:27:31]     - Source/Target Ratio: 2.0
[2025-10-28 15:27:31] Stage 2 Sliding Window Filter: ENABLED
[2025-10-28 15:27:31]     - Confidence Threshold: 0.65
[2025-10-28 15:27:31] ============================================================
[2025-10-28 15:27:37] Stage1 - Epoch: [1 | 100]
[2025-10-28 15:27:37]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-28 15:27:37]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-28 15:27:37]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-28 15:27:37]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-28 15:27:37]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-28 15:27:37]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-28 15:27:37]   [Param]	LR:	0.00010000
[2025-10-28 15:27:40] Stage1 - Epoch: [2 | 100]
[2025-10-28 15:27:40]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-28 15:27:40]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-28 15:27:40]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-28 15:27:40]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-28 15:27:40]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-28 15:27:40]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-28 15:27:40]   [Param]	LR:	0.00009998
[2025-10-28 15:27:44] Stage1 - Epoch: [3 | 100]
[2025-10-28 15:27:44]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-28 15:27:44]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-28 15:27:44]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-28 15:27:44]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-28 15:27:44]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-28 15:27:44]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-28 15:27:44]   [Param]	LR:	0.00009990
[2025-10-28 15:27:48] Stage1 - Epoch: [4 | 100]
[2025-10-28 15:27:48]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-28 15:27:48]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-28 15:27:48]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-28 15:27:48]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-28 15:27:48]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-28 15:27:48]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-28 15:27:48]   [Param]	LR:	0.00009978
[2025-10-28 15:27:53] Stage1 - Epoch: [5 | 100]
[2025-10-28 15:27:53]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-28 15:27:53]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-28 15:27:53]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-28 15:27:53]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-28 15:27:53]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-28 15:27:53]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-28 15:27:53]   [Param]	LR:	0.00009961
[2025-10-28 15:27:57] Stage1 - Epoch: [6 | 100]
[2025-10-28 15:27:57]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-28 15:27:57]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-28 15:27:57]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-28 15:27:57]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-28 15:27:57]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-28 15:27:57]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-28 15:27:57]   [Param]	LR:	0.00009938
[2025-10-28 15:28:02] Stage1 - Epoch: [7 | 100]
[2025-10-28 15:28:02]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-28 15:28:02]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-28 15:28:02]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-28 15:28:02]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-28 15:28:02]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-28 15:28:02]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-28 15:28:02]   [Param]	LR:	0.00009911
[2025-10-28 15:28:07] Stage1 - Epoch: [8 | 100]
[2025-10-28 15:28:07]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-28 15:28:07]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-28 15:28:07]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-28 15:28:07]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-28 15:28:07]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-28 15:28:07]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-28 15:28:07]   [Param]	LR:	0.00009880
[2025-10-28 15:28:10] Stage1 - Epoch: [9 | 100]
[2025-10-28 15:28:10]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-28 15:28:10]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-28 15:28:10]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-28 15:28:10]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-28 15:28:10]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-28 15:28:10]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-28 15:28:10]   [Param]	LR:	0.00009843
[2025-10-28 15:28:15] Stage1 - Epoch: [10 | 100]
[2025-10-28 15:28:15]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-28 15:28:15]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-28 15:28:15]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:28:15]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:28:15]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:28:15]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:15]   [Param]	LR:	0.00009801
[2025-10-28 15:28:19] Stage1 - Epoch: [11 | 100]
[2025-10-28 15:28:19]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-28 15:28:19]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-28 15:28:19]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:28:19]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:28:19]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:28:19]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:28:19]   [Param]	LR:	0.00009755
[2025-10-28 15:28:25] Stage1 - Epoch: [12 | 100]
[2025-10-28 15:28:25]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-28 15:28:25]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-28 15:28:25]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-28 15:28:25]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-28 15:28:25]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-28 15:28:25]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:28:25]   [Param]	LR:	0.00009704
[2025-10-28 15:28:29] Stage1 - Epoch: [13 | 100]
[2025-10-28 15:28:29]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-28 15:28:29]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-28 15:28:29]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:28:29]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:28:29]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:28:29]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:29]   [Param]	LR:	0.00009649
[2025-10-28 15:28:34] Stage1 - Epoch: [14 | 100]
[2025-10-28 15:28:34]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-28 15:28:34]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-28 15:28:34]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:28:34]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:28:34]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:28:34]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:34]   [Param]	LR:	0.00009589
[2025-10-28 15:28:39] Stage1 - Epoch: [15 | 100]
[2025-10-28 15:28:39]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-28 15:28:39]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-28 15:28:39]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:28:39]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:28:39]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:28:39]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:28:39]   [Param]	LR:	0.00009524
[2025-10-28 15:28:42] Stage1 - Epoch: [16 | 100]
[2025-10-28 15:28:42]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-28 15:28:42]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-28 15:28:42]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:28:42]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:28:42]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:28:42]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:28:42]   [Param]	LR:	0.00009455
[2025-10-28 15:28:47] Stage1 - Epoch: [17 | 100]
[2025-10-28 15:28:47]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-28 15:28:47]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-28 15:28:47]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-28 15:28:47]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-28 15:28:47]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-28 15:28:47]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:47]   [Param]	LR:	0.00009382
[2025-10-28 15:28:51] Stage1 - Epoch: [18 | 100]
[2025-10-28 15:28:51]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-28 15:28:51]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-28 15:28:51]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:28:51]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:28:51]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:28:51]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:51]   [Param]	LR:	0.00009304
[2025-10-28 15:28:56] Stage1 - Epoch: [19 | 100]
[2025-10-28 15:28:56]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-28 15:28:56]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-28 15:28:56]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-28 15:28:56]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-28 15:28:56]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-28 15:28:56]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:28:56]   [Param]	LR:	0.00009222
[2025-10-28 15:29:00] Stage1 - Epoch: [20 | 100]
[2025-10-28 15:29:00]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-28 15:29:00]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-28 15:29:00]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:00]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:00]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:00]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:00]   [Param]	LR:	0.00009135
[2025-10-28 15:29:05] Stage1 - Epoch: [21 | 100]
[2025-10-28 15:29:05]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-28 15:29:05]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-28 15:29:05]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:05]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:05]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:05]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:05]   [Param]	LR:	0.00009045
[2025-10-28 15:29:09] Stage1 - Epoch: [22 | 100]
[2025-10-28 15:29:09]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-28 15:29:09]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-28 15:29:09]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:29:09]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:29:09]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:29:09]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:09]   [Param]	LR:	0.00008951
[2025-10-28 15:29:13] Stage1 - Epoch: [23 | 100]
[2025-10-28 15:29:13]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-28 15:29:13]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-28 15:29:13]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:29:13]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:29:13]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:29:13]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:13]   [Param]	LR:	0.00008853
[2025-10-28 15:29:17] Stage1 - Epoch: [24 | 100]
[2025-10-28 15:29:17]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-28 15:29:17]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-28 15:29:17]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-28 15:29:17]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-28 15:29:17]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-28 15:29:17]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:17]   [Param]	LR:	0.00008751
[2025-10-28 15:29:22] Stage1 - Epoch: [25 | 100]
[2025-10-28 15:29:22]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-28 15:29:22]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-28 15:29:22]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:29:22]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:29:22]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:29:22]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:22]   [Param]	LR:	0.00008645
[2025-10-28 15:29:26] Stage1 - Epoch: [26 | 100]
[2025-10-28 15:29:26]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-28 15:29:26]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-28 15:29:26]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:29:26]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:29:26]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:29:26]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:26]   [Param]	LR:	0.00008536
[2025-10-28 15:29:31] Stage1 - Epoch: [27 | 100]
[2025-10-28 15:29:31]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-28 15:29:31]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-28 15:29:31]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:31]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:31]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:31]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:31]   [Param]	LR:	0.00008423
[2025-10-28 15:29:36] Stage1 - Epoch: [28 | 100]
[2025-10-28 15:29:36]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-28 15:29:36]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-28 15:29:36]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:29:36]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:29:36]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:29:36]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:36]   [Param]	LR:	0.00008307
[2025-10-28 15:29:41] Stage1 - Epoch: [29 | 100]
[2025-10-28 15:29:41]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-28 15:29:41]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-28 15:29:41]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:29:41]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:29:41]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:29:41]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:41]   [Param]	LR:	0.00008187
[2025-10-28 15:29:45] Stage1 - Epoch: [30 | 100]
[2025-10-28 15:29:45]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-28 15:29:45]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-28 15:29:45]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:29:45]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:29:45]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:29:45]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:45]   [Param]	LR:	0.00008065
[2025-10-28 15:29:49] Stage1 - Epoch: [31 | 100]
[2025-10-28 15:29:49]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-28 15:29:49]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-28 15:29:49]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:49]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:49]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:49]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:49]   [Param]	LR:	0.00007939
[2025-10-28 15:29:54] Stage1 - Epoch: [32 | 100]
[2025-10-28 15:29:54]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-28 15:29:54]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-28 15:29:54]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:54]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:54]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:54]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:54]   [Param]	LR:	0.00007810
[2025-10-28 15:29:58] Stage1 - Epoch: [33 | 100]
[2025-10-28 15:29:58]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-28 15:29:58]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-28 15:29:58]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:29:58]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:29:58]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:29:58]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:29:58]   [Param]	LR:	0.00007679
[2025-10-28 15:30:03] Stage1 - Epoch: [34 | 100]
[2025-10-28 15:30:03]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-28 15:30:03]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-28 15:30:03]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:30:03]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:30:03]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:30:03]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:03]   [Param]	LR:	0.00007545
[2025-10-28 15:30:08] Stage1 - Epoch: [35 | 100]
[2025-10-28 15:30:08]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-28 15:30:08]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-28 15:30:08]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:30:08]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:30:08]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:30:08]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:08]   [Param]	LR:	0.00007409
[2025-10-28 15:30:13] Stage1 - Epoch: [36 | 100]
[2025-10-28 15:30:13]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-28 15:30:13]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-28 15:30:13]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:30:13]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:30:13]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:30:13]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:13]   [Param]	LR:	0.00007270
[2025-10-28 15:30:13] Early stopping triggered after 36 epochs.
[2025-10-28 15:30:14] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-27/best_model_stage1_audio.pth
[2025-10-28 15:30:14] F1 score plot for stage1 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-27/stage1_macro_f1.png
[2025-10-28 15:30:14] ============================================================
[2025-10-28 15:30:14] STAGE 1 TRAINING COMPLETED
[2025-10-28 15:30:14] ============================================================
[2025-10-28 15:30:14] Stage 1 Training Time: 00:02:41
[2025-10-28 15:30:14] Stage 1 Best Macro F1: 0.9542
[2025-10-28 15:30:14] ============================================================
[2025-10-28 15:30:14] Evaluating Stage 1 model on target domain before Stage 2 training...
[2025-10-28 15:30:15] ============================================================
[2025-10-28 15:30:15] STAGE 1 MODEL - TARGET DOMAIN TEST RESULTS
[2025-10-28 15:30:15] ============================================================
[2025-10-28 15:30:15] [Test ]	Loss:	0.0000	Acc:	72.3926
[2025-10-28 15:30:15] [Test ]	Micro F1:	0.7239	Macro F1:	0.7022
[2025-10-28 15:30:15] [Cough   ]	F1:	0.6218	Precision:	0.9487	Recall:	0.4625
[2025-10-28 15:30:15] [NonCough]	F1:	0.7826	Precision:	0.6532	Recall:	0.9759
[2025-10-28 15:30:15] [Stats]	Many:	46.2500	Medium:	97.5904	Few:	0.0000
[2025-10-28 15:30:15] ============================================================
[2025-10-28 15:30:15] Confidence threshold: 0.65
[2025-10-28 15:30:21] Total samples: 649
[2025-10-28 15:30:21] Total windows checked: 1127
[2025-10-28 15:30:21] Cough windows found: 168
[2025-10-28 15:30:21] High-confidence negative windows found: 799
[2025-10-28 15:30:21] Total kept windows: 967
[2025-10-28 15:30:21] Selection rate: 85.80%
[2025-10-28 15:30:21] Using filtered dataset with 967 cough segments
[2025-10-28 15:30:21] Starting pseudo-label precomputation for curriculum learning...
[2025-10-28 15:30:23] Confidence statistics - Min: 0.6515, Max: 0.9996, Mean: 0.9183, Median: 0.9558
[2025-10-28 15:30:23] Precomputed 967 samples with confidence scores
[2025-10-28 15:30:23] Epoch 1/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:30:33] Stage2 - Epoch: [1 | 30]
[2025-10-28 15:30:33]   [Train]	Total Loss:	17.3043	CE Loss:	4.7284	Distill Loss:	9.2886	Source Loss:	6.0740
[2025-10-28 15:30:33]   [Train]	Acc:	0.7682
[2025-10-28 15:30:33]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:30:33]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:30:33]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:30:33]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:30:33]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:33]   [Param]	LR:	0.00100000
[2025-10-28 15:30:33] Epoch 2/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:30:41] Stage2 - Epoch: [2 | 30]
[2025-10-28 15:30:41]   [Train]	Total Loss:	1.7900	CE Loss:	0.4853	Distill Loss:	0.8062	Source Loss:	0.7402
[2025-10-28 15:30:41]   [Train]	Acc:	0.9049
[2025-10-28 15:30:41]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:30:41]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:30:41]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:30:41]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:30:41]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:41]   [Param]	LR:	0.00099726
[2025-10-28 15:30:41] Epoch 3/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:30:48] Stage2 - Epoch: [3 | 30]
[2025-10-28 15:30:48]   [Train]	Total Loss:	1.7085	CE Loss:	0.4200	Distill Loss:	0.6890	Source Loss:	0.8062
[2025-10-28 15:30:48]   [Train]	Acc:	0.9076
[2025-10-28 15:30:48]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:30:48]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:30:48]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:30:48]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:30:48]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:48]   [Param]	LR:	0.00098907
[2025-10-28 15:30:48] Epoch 4/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:30:56] Stage2 - Epoch: [4 | 30]
[2025-10-28 15:30:56]   [Train]	Total Loss:	1.6853	CE Loss:	0.3938	Distill Loss:	0.6362	Source Loss:	0.8461
[2025-10-28 15:30:56]   [Train]	Acc:	0.9076
[2025-10-28 15:30:56]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:30:56]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:30:56]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:30:56]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:30:56]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:30:56]   [Param]	LR:	0.00097553
[2025-10-28 15:30:56] Epoch 5/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:05] Stage2 - Epoch: [5 | 30]
[2025-10-28 15:31:05]   [Train]	Total Loss:	1.6767	CE Loss:	0.3840	Distill Loss:	0.6110	Source Loss:	0.8651
[2025-10-28 15:31:05]   [Train]	Acc:	0.9062
[2025-10-28 15:31:05]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:05]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:05]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:05]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:05]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:05]   [Param]	LR:	0.00095677
[2025-10-28 15:31:05] Epoch 6/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:13] Stage2 - Epoch: [6 | 30]
[2025-10-28 15:31:13]   [Train]	Total Loss:	1.4512	CE Loss:	0.3812	Distill Loss:	0.6072	Source Loss:	0.8878
[2025-10-28 15:31:13]   [Train]	Acc:	0.9076
[2025-10-28 15:31:13]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:13]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:13]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:13]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:13]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:13]   [Param]	LR:	0.00093301
[2025-10-28 15:31:13] Epoch 7/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:20] Stage2 - Epoch: [7 | 30]
[2025-10-28 15:31:20]   [Train]	Total Loss:	1.3309	CE Loss:	0.3879	Distill Loss:	0.4415	Source Loss:	0.8105
[2025-10-28 15:31:20]   [Train]	Acc:	0.9089
[2025-10-28 15:31:20]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:20]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:20]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:20]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:20]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:20]   [Param]	LR:	0.00090451
[2025-10-28 15:31:20] Epoch 8/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:29] Stage2 - Epoch: [8 | 30]
[2025-10-28 15:31:29]   [Train]	Total Loss:	1.5016	CE Loss:	0.5361	Distill Loss:	0.4174	Source Loss:	0.8403
[2025-10-28 15:31:29]   [Train]	Acc:	0.7396
[2025-10-28 15:31:29]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:29]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:29]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:29]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:29]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:29]   [Param]	LR:	0.00087157
[2025-10-28 15:31:29] Epoch 9/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:37] Stage2 - Epoch: [9 | 30]
[2025-10-28 15:31:37]   [Train]	Total Loss:	1.7015	CE Loss:	0.7842	Distill Loss:	0.4819	Source Loss:	0.7727
[2025-10-28 15:31:37]   [Train]	Acc:	0.4896
[2025-10-28 15:31:37]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:37]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:37]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:37]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:37]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:37]   [Param]	LR:	0.00083457
[2025-10-28 15:31:37] Epoch 10/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:46] Stage2 - Epoch: [10 | 30]
[2025-10-28 15:31:46]   [Train]	Total Loss:	1.7004	CE Loss:	0.8088	Distill Loss:	0.5514	Source Loss:	0.7262
[2025-10-28 15:31:46]   [Train]	Acc:	0.3125
[2025-10-28 15:31:46]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:31:46]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:31:46]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:46]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:31:46]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:31:46]   [Param]	LR:	0.00079389
[2025-10-28 15:31:46] Epoch 11/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:31:53] Stage2 - Epoch: [11 | 30]
[2025-10-28 15:31:53]   [Train]	Total Loss:	1.5863	CE Loss:	0.7155	Distill Loss:	0.5843	Source Loss:	0.6955
[2025-10-28 15:31:53]   [Train]	Acc:	0.4036
[2025-10-28 15:31:53]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:31:53]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:31:53]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:31:53]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:31:53]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:31:53]   [Param]	LR:	0.00075000
[2025-10-28 15:31:53] Epoch 12/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:02] Stage2 - Epoch: [12 | 30]
[2025-10-28 15:32:02]   [Train]	Total Loss:	1.4811	CE Loss:	0.6057	Distill Loss:	0.5789	Source Loss:	0.7018
[2025-10-28 15:32:02]   [Train]	Acc:	0.8750
[2025-10-28 15:32:02]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:02]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:02]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:02]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:02]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:02]   [Param]	LR:	0.00070337
[2025-10-28 15:32:02] Epoch 13/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:10] Stage2 - Epoch: [13 | 30]
[2025-10-28 15:32:10]   [Train]	Total Loss:	1.4052	CE Loss:	0.5218	Distill Loss:	0.5545	Source Loss:	0.7170
[2025-10-28 15:32:10]   [Train]	Acc:	0.8997
[2025-10-28 15:32:10]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:10]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:10]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:10]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:10]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:10]   [Param]	LR:	0.00065451
[2025-10-28 15:32:10] Epoch 14/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:17] Stage2 - Epoch: [14 | 30]
[2025-10-28 15:32:17]   [Train]	Total Loss:	1.3521	CE Loss:	0.4597	Distill Loss:	0.5233	Source Loss:	0.7354
[2025-10-28 15:32:17]   [Train]	Acc:	0.9219
[2025-10-28 15:32:17]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:17]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:17]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:17]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:17]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:17]   [Param]	LR:	0.00060396
[2025-10-28 15:32:17] Epoch 15/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:26] Stage2 - Epoch: [15 | 30]
[2025-10-28 15:32:26]   [Train]	Total Loss:	1.3346	CE Loss:	0.4099	Distill Loss:	0.4877	Source Loss:	0.7784
[2025-10-28 15:32:26]   [Train]	Acc:	0.9440
[2025-10-28 15:32:26]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:26]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:26]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:26]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:26]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:26]   [Param]	LR:	0.00055226
[2025-10-28 15:32:26] Epoch 16/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:34] Stage2 - Epoch: [16 | 30]
[2025-10-28 15:32:34]   [Train]	Total Loss:	1.2854	CE Loss:	0.3741	Distill Loss:	0.4518	Source Loss:	0.7757
[2025-10-28 15:32:34]   [Train]	Acc:	0.9544
[2025-10-28 15:32:34]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:34]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:34]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:34]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:34]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:34]   [Param]	LR:	0.00050000
[2025-10-28 15:32:34] Epoch 17/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:42] Stage2 - Epoch: [17 | 30]
[2025-10-28 15:32:42]   [Train]	Total Loss:	1.2672	CE Loss:	0.3503	Distill Loss:	0.4121	Source Loss:	0.7932
[2025-10-28 15:32:42]   [Train]	Acc:	0.9635
[2025-10-28 15:32:42]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:42]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:42]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:42]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:42]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:42]   [Param]	LR:	0.00044774
[2025-10-28 15:32:42] Epoch 18/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:49] Stage2 - Epoch: [18 | 30]
[2025-10-28 15:32:49]   [Train]	Total Loss:	1.2594	CE Loss:	0.3311	Distill Loss:	0.3758	Source Loss:	0.8155
[2025-10-28 15:32:49]   [Train]	Acc:	0.9766
[2025-10-28 15:32:49]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:49]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:49]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:49]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:49]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:49]   [Param]	LR:	0.00039604
[2025-10-28 15:32:49] Epoch 19/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:32:57] Stage2 - Epoch: [19 | 30]
[2025-10-28 15:32:57]   [Train]	Total Loss:	1.2277	CE Loss:	0.3173	Distill Loss:	0.3450	Source Loss:	0.8069
[2025-10-28 15:32:57]   [Train]	Acc:	0.9818
[2025-10-28 15:32:57]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:32:57]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:32:57]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:32:57]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:32:57]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:32:57]   [Param]	LR:	0.00034549
[2025-10-28 15:32:57] Epoch 20/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:05] Stage2 - Epoch: [20 | 30]
[2025-10-28 15:33:05]   [Train]	Total Loss:	1.2414	CE Loss:	0.3066	Distill Loss:	0.3143	Source Loss:	0.8405
[2025-10-28 15:33:05]   [Train]	Acc:	0.9844
[2025-10-28 15:33:05]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:05]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:05]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:05]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:05]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:05]   [Param]	LR:	0.00029663
[2025-10-28 15:33:05] Epoch 21/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:14] Stage2 - Epoch: [21 | 30]
[2025-10-28 15:33:14]   [Train]	Total Loss:	1.2213	CE Loss:	0.3004	Distill Loss:	0.2881	Source Loss:	0.8345
[2025-10-28 15:33:14]   [Train]	Acc:	0.9896
[2025-10-28 15:33:14]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:14]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:14]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:14]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:14]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:14]   [Param]	LR:	0.00025000
[2025-10-28 15:33:14] Epoch 22/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:22] Stage2 - Epoch: [22 | 30]
[2025-10-28 15:33:22]   [Train]	Total Loss:	1.2165	CE Loss:	0.2962	Distill Loss:	0.2619	Source Loss:	0.8417
[2025-10-28 15:33:22]   [Train]	Acc:	0.9935
[2025-10-28 15:33:22]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:22]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:22]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:22]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:22]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:22]   [Param]	LR:	0.00020611
[2025-10-28 15:33:22] Epoch 23/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:30] Stage2 - Epoch: [23 | 30]
[2025-10-28 15:33:30]   [Train]	Total Loss:	1.2169	CE Loss:	0.2936	Distill Loss:	0.2366	Source Loss:	0.8523
[2025-10-28 15:33:30]   [Train]	Acc:	0.9948
[2025-10-28 15:33:30]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:30]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:30]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:30]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:30]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:30]   [Param]	LR:	0.00016543
[2025-10-28 15:33:30] Epoch 24/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:39] Stage2 - Epoch: [24 | 30]
[2025-10-28 15:33:39]   [Train]	Total Loss:	1.1960	CE Loss:	0.2919	Distill Loss:	0.2140	Source Loss:	0.8399
[2025-10-28 15:33:39]   [Train]	Acc:	0.9961
[2025-10-28 15:33:39]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:39]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:39]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:39]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:39]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:39]   [Param]	LR:	0.00012843
[2025-10-28 15:33:39] Epoch 25/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:47] Stage2 - Epoch: [25 | 30]
[2025-10-28 15:33:47]   [Train]	Total Loss:	1.2244	CE Loss:	0.2909	Distill Loss:	0.1931	Source Loss:	0.8756
[2025-10-28 15:33:47]   [Train]	Acc:	0.9987
[2025-10-28 15:33:47]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:47]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:47]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:47]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:47]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:47]   [Param]	LR:	0.00009549
[2025-10-28 15:33:47] Epoch 26/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:33:54] Stage2 - Epoch: [26 | 30]
[2025-10-28 15:33:54]   [Train]	Total Loss:	1.1887	CE Loss:	0.2903	Distill Loss:	0.1723	Source Loss:	0.8467
[2025-10-28 15:33:54]   [Train]	Acc:	1.0000
[2025-10-28 15:33:54]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:33:54]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:33:54]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:33:54]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:33:54]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:33:54]   [Param]	LR:	0.00006699
[2025-10-28 15:33:54] Epoch 27/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:34:03] Stage2 - Epoch: [27 | 30]
[2025-10-28 15:34:03]   [Train]	Total Loss:	1.2003	CE Loss:	0.2899	Distill Loss:	0.1507	Source Loss:	0.8653
[2025-10-28 15:34:03]   [Train]	Acc:	1.0000
[2025-10-28 15:34:03]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:34:03]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:34:03]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:34:03]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:34:03]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:34:03]   [Param]	LR:	0.00004323
[2025-10-28 15:34:03] Epoch 28/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:34:12] Stage2 - Epoch: [28 | 30]
[2025-10-28 15:34:12]   [Train]	Total Loss:	1.1641	CE Loss:	0.2897	Distill Loss:	0.1313	Source Loss:	0.8350
[2025-10-28 15:34:12]   [Train]	Acc:	1.0000
[2025-10-28 15:34:12]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:34:12]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:34:12]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:34:12]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:34:12]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:34:12]   [Param]	LR:	0.00002447
[2025-10-28 15:34:12] Epoch 29/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:34:21] Stage2 - Epoch: [29 | 30]
[2025-10-28 15:34:21]   [Train]	Total Loss:	1.1569	CE Loss:	0.2895	Distill Loss:	0.1146	Source Loss:	0.8330
[2025-10-28 15:34:21]   [Train]	Acc:	1.0000
[2025-10-28 15:34:21]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:34:21]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:34:21]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:34:21]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:34:21]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:34:21]   [Param]	LR:	0.00001093
[2025-10-28 15:34:21] Epoch 30/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:34:28] Stage2 - Epoch: [30 | 30]
[2025-10-28 15:34:28]   [Train]	Total Loss:	1.1755	CE Loss:	0.2895	Distill Loss:	0.0993	Source Loss:	0.8563
[2025-10-28 15:34:28]   [Train]	Acc:	1.0000
[2025-10-28 15:34:28]   [Test ]	Loss:	0.0000	Acc:	49.0798
[2025-10-28 15:34:28]   [Test ]	Micro F1:	0.4908	Macro F1:	0.3292
[2025-10-28 15:34:28]   [Cough   ]	F1:	0.6584	Precision:	0.4908	Recall:	1.0000
[2025-10-28 15:34:28]   [NonCough]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:34:28]   [Stats]	Many:	100.0000	Medium:	0.0000	Few:	0.0000
[2025-10-28 15:34:28]   [Param]	LR:	0.00000274
[2025-10-28 15:34:29] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-27/best_model_stage2_audio.pth
[2025-10-28 15:34:29] F1 score plot for stage2 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-27/stage2_macro_f1.png
[2025-10-28 15:34:29] ============================================================
[2025-10-28 15:34:29] STAGE 2 TRAINING COMPLETED
[2025-10-28 15:34:29] ============================================================
[2025-10-28 15:34:29] Stage 2 Training Time: 00:04:04
[2025-10-28 15:34:29] Stage 2 Best Target Macro F1: 0.3374
[2025-10-28 15:34:29] ============================================================
[2025-10-28 15:34:29] ============================================================
[2025-10-28 15:34:29] TRAINING COMPLETED SUMMARY
[2025-10-28 15:34:29] ============================================================
[2025-10-28 15:34:29] Stage 1 Training Time: 00:02:42
[2025-10-28 15:34:29] Stage 2 Training Time: 00:04:15
[2025-10-28 15:34:29] Total Training Time: 00:06:58
[2025-10-28 15:34:29] Best Target Domain Macro F1: 0.3374
[2025-10-28 15:34:29] ============================================================
