[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:55] MODEL COMPLEXITY
[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:55] FLOPs: 863.897M
[2025-10-28 15:51:55] Parameters: 72.142M
[2025-10-28 15:51:55]   FLOPs (exact): 863896576
[2025-10-28 15:51:55]   Parameters (exact): 72141700
[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:55] ABLATION EXPERIMENT CONFIGURATION
[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:55] WeightedRandomSampler: ENABLED
[2025-10-28 15:51:55] Focal Loss: DISABLED
[2025-10-28 15:51:55] Logit Adjustment: DISABLED
[2025-10-28 15:51:55] Label Smoothing: 0.98
[2025-10-28 15:51:55] Stage 2 Use Source Data: ENABLED
[2025-10-28 15:51:55]     - Source/Target Ratio: 2.0
[2025-10-28 15:51:55] Stage 2 Sliding Window Filter: ENABLED
[2025-10-28 15:51:55]     - Confidence Threshold: 0.65
[2025-10-28 15:51:55] ============================================================
[2025-10-28 15:51:59] Stage1 - Epoch: [1 | 100]
[2025-10-28 15:51:59]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-28 15:51:59]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-28 15:51:59]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-28 15:51:59]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-28 15:51:59]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-28 15:51:59]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-28 15:51:59]   [Param]	LR:	0.00010000
[2025-10-28 15:52:04] Stage1 - Epoch: [2 | 100]
[2025-10-28 15:52:04]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-28 15:52:04]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-28 15:52:04]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-28 15:52:04]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-28 15:52:04]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-28 15:52:04]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-28 15:52:04]   [Param]	LR:	0.00009998
[2025-10-28 15:52:09] Stage1 - Epoch: [3 | 100]
[2025-10-28 15:52:09]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-28 15:52:09]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-28 15:52:09]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-28 15:52:09]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-28 15:52:09]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-28 15:52:09]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-28 15:52:09]   [Param]	LR:	0.00009990
[2025-10-28 15:52:13] Stage1 - Epoch: [4 | 100]
[2025-10-28 15:52:13]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-28 15:52:13]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-28 15:52:13]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-28 15:52:13]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-28 15:52:13]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-28 15:52:13]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-28 15:52:13]   [Param]	LR:	0.00009978
[2025-10-28 15:52:18] Stage1 - Epoch: [5 | 100]
[2025-10-28 15:52:18]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-28 15:52:18]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-28 15:52:18]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-28 15:52:18]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-28 15:52:18]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-28 15:52:18]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-28 15:52:18]   [Param]	LR:	0.00009961
[2025-10-28 15:52:22] Stage1 - Epoch: [6 | 100]
[2025-10-28 15:52:22]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-28 15:52:22]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-28 15:52:22]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-28 15:52:22]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-28 15:52:22]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-28 15:52:22]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-28 15:52:22]   [Param]	LR:	0.00009938
[2025-10-28 15:52:27] Stage1 - Epoch: [7 | 100]
[2025-10-28 15:52:27]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-28 15:52:27]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-28 15:52:27]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-28 15:52:27]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-28 15:52:27]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-28 15:52:27]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-28 15:52:27]   [Param]	LR:	0.00009911
[2025-10-28 15:52:30] Stage1 - Epoch: [8 | 100]
[2025-10-28 15:52:30]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-28 15:52:30]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-28 15:52:30]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-28 15:52:30]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-28 15:52:30]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-28 15:52:30]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-28 15:52:30]   [Param]	LR:	0.00009880
[2025-10-28 15:52:34] Stage1 - Epoch: [9 | 100]
[2025-10-28 15:52:34]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-28 15:52:34]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-28 15:52:34]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-28 15:52:34]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-28 15:52:34]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-28 15:52:34]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-28 15:52:34]   [Param]	LR:	0.00009843
[2025-10-28 15:52:39] Stage1 - Epoch: [10 | 100]
[2025-10-28 15:52:39]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-28 15:52:39]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-28 15:52:39]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:52:39]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:52:39]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:52:39]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:52:39]   [Param]	LR:	0.00009801
[2025-10-28 15:52:43] Stage1 - Epoch: [11 | 100]
[2025-10-28 15:52:43]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-28 15:52:43]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-28 15:52:43]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:52:43]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:52:43]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:52:43]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:52:43]   [Param]	LR:	0.00009755
[2025-10-28 15:52:48] Stage1 - Epoch: [12 | 100]
[2025-10-28 15:52:48]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-28 15:52:48]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-28 15:52:48]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-28 15:52:48]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-28 15:52:48]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-28 15:52:48]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:52:48]   [Param]	LR:	0.00009704
[2025-10-28 15:52:52] Stage1 - Epoch: [13 | 100]
[2025-10-28 15:52:52]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-28 15:52:52]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-28 15:52:52]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:52:52]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:52:52]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:52:52]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:52:52]   [Param]	LR:	0.00009649
[2025-10-28 15:52:56] Stage1 - Epoch: [14 | 100]
[2025-10-28 15:52:56]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-28 15:52:56]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-28 15:52:56]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:52:56]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:52:56]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:52:56]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:52:56]   [Param]	LR:	0.00009589
[2025-10-28 15:52:59] Stage1 - Epoch: [15 | 100]
[2025-10-28 15:52:59]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-28 15:52:59]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-28 15:52:59]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:52:59]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:52:59]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:52:59]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:52:59]   [Param]	LR:	0.00009524
[2025-10-28 15:53:03] Stage1 - Epoch: [16 | 100]
[2025-10-28 15:53:03]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-28 15:53:03]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-28 15:53:03]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-28 15:53:03]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-28 15:53:03]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-28 15:53:03]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-28 15:53:03]   [Param]	LR:	0.00009455
[2025-10-28 15:53:08] Stage1 - Epoch: [17 | 100]
[2025-10-28 15:53:08]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-28 15:53:08]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-28 15:53:08]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-28 15:53:08]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-28 15:53:08]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-28 15:53:08]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:08]   [Param]	LR:	0.00009382
[2025-10-28 15:53:12] Stage1 - Epoch: [18 | 100]
[2025-10-28 15:53:12]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-28 15:53:12]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-28 15:53:12]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:53:12]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:53:12]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:53:12]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:12]   [Param]	LR:	0.00009304
[2025-10-28 15:53:17] Stage1 - Epoch: [19 | 100]
[2025-10-28 15:53:17]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-28 15:53:17]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-28 15:53:17]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-28 15:53:17]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-28 15:53:17]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-28 15:53:17]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:17]   [Param]	LR:	0.00009222
[2025-10-28 15:53:21] Stage1 - Epoch: [20 | 100]
[2025-10-28 15:53:21]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-28 15:53:21]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-28 15:53:21]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:53:21]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:53:21]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:53:21]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:21]   [Param]	LR:	0.00009135
[2025-10-28 15:53:25] Stage1 - Epoch: [21 | 100]
[2025-10-28 15:53:25]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-28 15:53:25]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-28 15:53:25]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:53:25]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:53:25]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:53:25]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:25]   [Param]	LR:	0.00009045
[2025-10-28 15:53:30] Stage1 - Epoch: [22 | 100]
[2025-10-28 15:53:30]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-28 15:53:30]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-28 15:53:30]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:53:30]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:53:30]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:53:30]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:30]   [Param]	LR:	0.00008951
[2025-10-28 15:53:33] Stage1 - Epoch: [23 | 100]
[2025-10-28 15:53:33]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-28 15:53:33]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-28 15:53:33]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:53:33]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:53:33]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:53:33]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:33]   [Param]	LR:	0.00008853
[2025-10-28 15:53:37] Stage1 - Epoch: [24 | 100]
[2025-10-28 15:53:37]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-28 15:53:37]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-28 15:53:37]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-28 15:53:37]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-28 15:53:37]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-28 15:53:37]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:37]   [Param]	LR:	0.00008751
[2025-10-28 15:53:42] Stage1 - Epoch: [25 | 100]
[2025-10-28 15:53:42]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-28 15:53:42]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-28 15:53:42]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:53:42]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:53:42]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:53:42]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:42]   [Param]	LR:	0.00008645
[2025-10-28 15:53:46] Stage1 - Epoch: [26 | 100]
[2025-10-28 15:53:46]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-28 15:53:46]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-28 15:53:46]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:53:46]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:53:46]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:53:46]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:46]   [Param]	LR:	0.00008536
[2025-10-28 15:53:51] Stage1 - Epoch: [27 | 100]
[2025-10-28 15:53:51]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-28 15:53:51]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-28 15:53:51]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:53:51]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:53:51]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:53:51]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:51]   [Param]	LR:	0.00008423
[2025-10-28 15:53:55] Stage1 - Epoch: [28 | 100]
[2025-10-28 15:53:55]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-28 15:53:55]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-28 15:53:55]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:53:55]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:53:55]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:53:55]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:53:55]   [Param]	LR:	0.00008307
[2025-10-28 15:54:00] Stage1 - Epoch: [29 | 100]
[2025-10-28 15:54:00]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-28 15:54:00]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-28 15:54:00]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:54:00]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:54:00]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:54:00]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:00]   [Param]	LR:	0.00008187
[2025-10-28 15:54:02] Stage1 - Epoch: [30 | 100]
[2025-10-28 15:54:02]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-28 15:54:02]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-28 15:54:02]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-28 15:54:02]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-28 15:54:02]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-28 15:54:02]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:02]   [Param]	LR:	0.00008065
[2025-10-28 15:54:07] Stage1 - Epoch: [31 | 100]
[2025-10-28 15:54:07]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-28 15:54:07]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-28 15:54:07]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:54:07]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:54:07]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:54:07]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:07]   [Param]	LR:	0.00007939
[2025-10-28 15:54:11] Stage1 - Epoch: [32 | 100]
[2025-10-28 15:54:11]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-28 15:54:11]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-28 15:54:11]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:54:11]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:54:11]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:54:11]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:11]   [Param]	LR:	0.00007810
[2025-10-28 15:54:16] Stage1 - Epoch: [33 | 100]
[2025-10-28 15:54:16]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-28 15:54:16]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-28 15:54:16]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:54:16]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:54:16]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:54:16]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:16]   [Param]	LR:	0.00007679
[2025-10-28 15:54:20] Stage1 - Epoch: [34 | 100]
[2025-10-28 15:54:20]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-28 15:54:20]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-28 15:54:20]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:54:20]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:54:20]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:54:20]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:20]   [Param]	LR:	0.00007545
[2025-10-28 15:54:25] Stage1 - Epoch: [35 | 100]
[2025-10-28 15:54:25]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-28 15:54:25]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-28 15:54:25]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-28 15:54:25]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-28 15:54:25]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-28 15:54:25]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:25]   [Param]	LR:	0.00007409
[2025-10-28 15:54:29] Stage1 - Epoch: [36 | 100]
[2025-10-28 15:54:29]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-28 15:54:29]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-28 15:54:29]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-28 15:54:29]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-28 15:54:29]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-28 15:54:29]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:29]   [Param]	LR:	0.00007270
[2025-10-28 15:54:29] Early stopping triggered after 36 epochs.
[2025-10-28 15:54:30] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-51/best_model_stage1_audio.pth
[2025-10-28 15:54:30] F1 score plot for stage1 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-51/stage1_macro_f1.png
[2025-10-28 15:54:30] Stage 1 Training Time: 00:02:33
[2025-10-28 15:54:30] Stage 1 Best Macro F1: 0.9542
[2025-10-28 15:54:30] Confidence threshold: 0.65
[2025-10-28 15:54:35] Total samples: 649
[2025-10-28 15:54:35] Total windows checked: 1127
[2025-10-28 15:54:35] Cough windows found: 168
[2025-10-28 15:54:35] High-confidence negative windows found: 799
[2025-10-28 15:54:35] Total kept windows: 967
[2025-10-28 15:54:35] Selection rate: 85.80%
[2025-10-28 15:54:35] Using filtered dataset with 967 cough segments
[2025-10-28 15:54:35] Starting pseudo-label precomputation for curriculum learning...
[2025-10-28 15:54:38] Confidence statistics - Min: 0.6515, Max: 0.9996, Mean: 0.9183, Median: 0.9558
[2025-10-28 15:54:38] Precomputed 967 samples with confidence scores
[2025-10-28 15:54:38] Epoch 1/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:54:47] Stage2 - Epoch: [1 | 30]
[2025-10-28 15:54:47]   [Train]	Total Loss:	33.8926	CE Loss:	7.5080	Distill Loss:	16.2163	Source Loss:	15.0332
[2025-10-28 15:54:47]   [Train]	Acc:	0.7552
[2025-10-28 15:54:47]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:54:47]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:54:47]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:54:47]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:54:47]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:47]   [Param]	LR:	0.00100000
[2025-10-28 15:54:47] Epoch 2/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:54:55] Stage2 - Epoch: [2 | 30]
[2025-10-28 15:54:55]   [Train]	Total Loss:	1.2375	CE Loss:	0.2793	Distill Loss:	0.4104	Source Loss:	0.6709
[2025-10-28 15:54:55]   [Train]	Acc:	0.9076
[2025-10-28 15:54:55]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:54:55]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-28 15:54:55]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-28 15:54:55]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-28 15:54:55]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:54:55]   [Param]	LR:	0.00099726
[2025-10-28 15:54:55] Epoch 3/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:03] Stage2 - Epoch: [3 | 30]
[2025-10-28 15:55:03]   [Train]	Total Loss:	0.8380	CE Loss:	0.1963	Distill Loss:	0.2178	Source Loss:	0.4893
[2025-10-28 15:55:03]   [Train]	Acc:	0.9115
[2025-10-28 15:55:03]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-28 15:55:03]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6348
[2025-10-28 15:55:03]   [Cough   ]	F1:	0.5138	Precision:	0.9655	Recall:	0.3500
[2025-10-28 15:55:03]   [NonCough]	F1:	0.7558	Precision:	0.6119	Recall:	0.9880
[2025-10-28 15:55:03]   [Stats]	Many:	35.0000	Medium:	98.7952	Few:	0.0000
[2025-10-28 15:55:03]   [Param]	LR:	0.00098907
[2025-10-28 15:55:03] Epoch 4/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:10] Stage2 - Epoch: [4 | 30]
[2025-10-28 15:55:10]   [Train]	Total Loss:	0.6981	CE Loss:	0.1692	Distill Loss:	0.1727	Source Loss:	0.4080
[2025-10-28 15:55:10]   [Train]	Acc:	0.9648
[2025-10-28 15:55:10]   [Test ]	Loss:	0.0000	Acc:	53.3742
[2025-10-28 15:55:10]   [Test ]	Micro F1:	0.5337	Macro F1:	0.3906
[2025-10-28 15:55:10]   [Cough   ]	F1:	0.0952	Precision:	1.0000	Recall:	0.0500
[2025-10-28 15:55:10]   [NonCough]	F1:	0.6860	Precision:	0.5220	Recall:	1.0000
[2025-10-28 15:55:10]   [Stats]	Many:	5.0000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:55:10]   [Param]	LR:	0.00097553
[2025-10-28 15:55:10] Epoch 5/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:18] Stage2 - Epoch: [5 | 30]
[2025-10-28 15:55:18]   [Train]	Total Loss:	0.6482	CE Loss:	0.1735	Distill Loss:	0.1897	Source Loss:	0.3419
[2025-10-28 15:55:18]   [Train]	Acc:	0.9635
[2025-10-28 15:55:18]   [Test ]	Loss:	0.0000	Acc:	54.6012
[2025-10-28 15:55:18]   [Test ]	Micro F1:	0.5460	Macro F1:	0.4156
[2025-10-28 15:55:18]   [Cough   ]	F1:	0.1395	Precision:	1.0000	Recall:	0.0750
[2025-10-28 15:55:18]   [NonCough]	F1:	0.6917	Precision:	0.5287	Recall:	1.0000
[2025-10-28 15:55:18]   [Stats]	Many:	7.5000	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:55:18]   [Param]	LR:	0.00095677
[2025-10-28 15:55:18] Epoch 6/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:27] Stage2 - Epoch: [6 | 30]
[2025-10-28 15:55:27]   [Train]	Total Loss:	0.5228	CE Loss:	0.1634	Distill Loss:	0.1799	Source Loss:	0.3054
[2025-10-28 15:55:27]   [Train]	Acc:	0.9688
[2025-10-28 15:55:27]   [Test ]	Loss:	0.0000	Acc:	55.2147
[2025-10-28 15:55:27]   [Test ]	Micro F1:	0.5521	Macro F1:	0.4277
[2025-10-28 15:55:27]   [Cough   ]	F1:	0.1609	Precision:	1.0000	Recall:	0.0875
[2025-10-28 15:55:27]   [NonCough]	F1:	0.6946	Precision:	0.5321	Recall:	1.0000
[2025-10-28 15:55:27]   [Stats]	Many:	8.7500	Medium:	100.0000	Few:	0.0000
[2025-10-28 15:55:27]   [Param]	LR:	0.00093301
[2025-10-28 15:55:27] Epoch 7/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:35] Stage2 - Epoch: [7 | 30]
[2025-10-28 15:55:35]   [Train]	Total Loss:	0.5403	CE Loss:	0.1758	Distill Loss:	0.2996	Source Loss:	0.2746
[2025-10-28 15:55:35]   [Train]	Acc:	0.9479
[2025-10-28 15:55:35]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-28 15:55:35]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6517
[2025-10-28 15:55:35]   [Cough   ]	F1:	0.5405	Precision:	0.9677	Recall:	0.3750
[2025-10-28 15:55:35]   [NonCough]	F1:	0.7628	Precision:	0.6212	Recall:	0.9880
[2025-10-28 15:55:35]   [Stats]	Many:	37.5000	Medium:	98.7952	Few:	0.0000
[2025-10-28 15:55:35]   [Param]	LR:	0.00090451
[2025-10-28 15:55:35] Epoch 8/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:45] Stage2 - Epoch: [8 | 30]
[2025-10-28 15:55:45]   [Train]	Total Loss:	0.5368	CE Loss:	0.1921	Distill Loss:	0.2979	Source Loss:	0.2554
[2025-10-28 15:55:45]   [Train]	Acc:	0.9232
[2025-10-28 15:55:45]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-28 15:55:45]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6348
[2025-10-28 15:55:45]   [Cough   ]	F1:	0.5138	Precision:	0.9655	Recall:	0.3500
[2025-10-28 15:55:45]   [NonCough]	F1:	0.7558	Precision:	0.6119	Recall:	0.9880
[2025-10-28 15:55:45]   [Stats]	Many:	35.0000	Medium:	98.7952	Few:	0.0000
[2025-10-28 15:55:45]   [Param]	LR:	0.00087157
[2025-10-28 15:55:45] Epoch 9/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:55:53] Stage2 - Epoch: [9 | 30]
[2025-10-28 15:55:53]   [Train]	Total Loss:	0.8114	CE Loss:	0.4418	Distill Loss:	0.3066	Source Loss:	0.2776
[2025-10-28 15:55:53]   [Train]	Acc:	0.7695
[2025-10-28 15:55:53]   [Test ]	Loss:	0.0000	Acc:	83.4356
[2025-10-28 15:55:53]   [Test ]	Micro F1:	0.8344	Macro F1:	0.8307
[2025-10-28 15:55:53]   [Cough   ]	F1:	0.8058	Precision:	0.9492	Recall:	0.7000
[2025-10-28 15:55:53]   [NonCough]	F1:	0.8556	Precision:	0.7692	Recall:	0.9639
[2025-10-28 15:55:53]   [Stats]	Many:	70.0000	Medium:	96.3855	Few:	0.0000
[2025-10-28 15:55:53]   [Param]	LR:	0.00083457
[2025-10-28 15:55:53] Epoch 10/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:01] Stage2 - Epoch: [10 | 30]
[2025-10-28 15:56:01]   [Train]	Total Loss:	0.8913	CE Loss:	0.5221	Distill Loss:	0.2847	Source Loss:	0.2838
[2025-10-28 15:56:01]   [Train]	Acc:	0.7240
[2025-10-28 15:56:01]   [Test ]	Loss:	0.0000	Acc:	76.0736
[2025-10-28 15:56:01]   [Test ]	Micro F1:	0.7607	Macro F1:	0.7598
[2025-10-28 15:56:01]   [Cough   ]	F1:	0.7746	Precision:	0.7204	Recall:	0.8375
[2025-10-28 15:56:01]   [NonCough]	F1:	0.7451	Precision:	0.8143	Recall:	0.6867
[2025-10-28 15:56:01]   [Stats]	Many:	83.7500	Medium:	68.6747	Few:	0.0000
[2025-10-28 15:56:01]   [Param]	LR:	0.00079389
[2025-10-28 15:56:01] Epoch 11/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:08] Stage2 - Epoch: [11 | 30]
[2025-10-28 15:56:08]   [Train]	Total Loss:	0.8387	CE Loss:	0.4859	Distill Loss:	0.2877	Source Loss:	0.2665
[2025-10-28 15:56:08]   [Train]	Acc:	0.7708
[2025-10-28 15:56:08]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-28 15:56:08]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6789
[2025-10-28 15:56:08]   [Cough   ]	F1:	0.7302	Precision:	0.6330	Recall:	0.8625
[2025-10-28 15:56:08]   [NonCough]	F1:	0.6277	Precision:	0.7963	Recall:	0.5181
[2025-10-28 15:56:08]   [Stats]	Many:	86.2500	Medium:	51.8072	Few:	0.0000
[2025-10-28 15:56:08]   [Param]	LR:	0.00075000
[2025-10-28 15:56:08] Epoch 12/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:17] Stage2 - Epoch: [12 | 30]
[2025-10-28 15:56:17]   [Train]	Total Loss:	0.7625	CE Loss:	0.4057	Distill Loss:	0.2717	Source Loss:	0.2752
[2025-10-28 15:56:17]   [Train]	Acc:	0.8268
[2025-10-28 15:56:17]   [Test ]	Loss:	0.0000	Acc:	58.8957
[2025-10-28 15:56:17]   [Test ]	Micro F1:	0.5890	Macro F1:	0.5245
[2025-10-28 15:56:17]   [Cough   ]	F1:	0.6996	Precision:	0.5455	Recall:	0.9750
[2025-10-28 15:56:17]   [NonCough]	F1:	0.3495	Precision:	0.9000	Recall:	0.2169
[2025-10-28 15:56:17]   [Stats]	Many:	97.5000	Medium:	21.6867	Few:	0.0000
[2025-10-28 15:56:17]   [Param]	LR:	0.00070337
[2025-10-28 15:56:17] Epoch 13/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:26] Stage2 - Epoch: [13 | 30]
[2025-10-28 15:56:26]   [Train]	Total Loss:	0.7294	CE Loss:	0.3677	Distill Loss:	0.2828	Source Loss:	0.2768
[2025-10-28 15:56:26]   [Train]	Acc:	0.8620
[2025-10-28 15:56:26]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-28 15:56:26]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6720
[2025-10-28 15:56:26]   [Cough   ]	F1:	0.7263	Precision:	0.6273	Recall:	0.8625
[2025-10-28 15:56:26]   [NonCough]	F1:	0.6176	Precision:	0.7925	Recall:	0.5060
[2025-10-28 15:56:26]   [Stats]	Many:	86.2500	Medium:	50.6024	Few:	0.0000
[2025-10-28 15:56:26]   [Param]	LR:	0.00065451
[2025-10-28 15:56:26] Epoch 14/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:35] Stage2 - Epoch: [14 | 30]
[2025-10-28 15:56:35]   [Train]	Total Loss:	0.7216	CE Loss:	0.3467	Distill Loss:	0.3169	Source Loss:	0.2798
[2025-10-28 15:56:35]   [Train]	Acc:	0.8763
[2025-10-28 15:56:35]   [Test ]	Loss:	0.0000	Acc:	58.2822
[2025-10-28 15:56:35]   [Test ]	Micro F1:	0.5828	Macro F1:	0.5335
[2025-10-28 15:56:35]   [Cough   ]	F1:	0.6852	Precision:	0.5441	Recall:	0.9250
[2025-10-28 15:56:35]   [NonCough]	F1:	0.3818	Precision:	0.7778	Recall:	0.2530
[2025-10-28 15:56:35]   [Stats]	Many:	92.5000	Medium:	25.3012	Few:	0.0000
[2025-10-28 15:56:35]   [Param]	LR:	0.00060396
[2025-10-28 15:56:35] Epoch 15/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:43] Stage2 - Epoch: [15 | 30]
[2025-10-28 15:56:43]   [Train]	Total Loss:	0.5720	CE Loss:	0.2740	Distill Loss:	0.2978	Source Loss:	0.2086
[2025-10-28 15:56:43]   [Train]	Acc:	0.9102
[2025-10-28 15:56:43]   [Test ]	Loss:	0.0000	Acc:	54.6012
[2025-10-28 15:56:43]   [Test ]	Micro F1:	0.5460	Macro F1:	0.4776
[2025-10-28 15:56:43]   [Cough   ]	F1:	0.6667	Precision:	0.5211	Recall:	0.9250
[2025-10-28 15:56:43]   [NonCough]	F1:	0.2885	Precision:	0.7143	Recall:	0.1807
[2025-10-28 15:56:43]   [Stats]	Many:	92.5000	Medium:	18.0723	Few:	0.0000
[2025-10-28 15:56:43]   [Param]	LR:	0.00055226
[2025-10-28 15:56:43] Epoch 16/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:56:52] Stage2 - Epoch: [16 | 30]
[2025-10-28 15:56:52]   [Train]	Total Loss:	0.5177	CE Loss:	0.2379	Distill Loss:	0.2910	Source Loss:	0.1925
[2025-10-28 15:56:52]   [Train]	Acc:	0.9479
[2025-10-28 15:56:52]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:56:52]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3682
[2025-10-28 15:56:52]   [Cough   ]	F1:	0.6667	Precision:	0.5000	Recall:	1.0000
[2025-10-28 15:56:52]   [NonCough]	F1:	0.0698	Precision:	1.0000	Recall:	0.0361
[2025-10-28 15:56:52]   [Stats]	Many:	100.0000	Medium:	3.6145	Few:	0.0000
[2025-10-28 15:56:52]   [Param]	LR:	0.00050000
[2025-10-28 15:56:52] Epoch 17/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:01] Stage2 - Epoch: [17 | 30]
[2025-10-28 15:57:01]   [Train]	Total Loss:	0.4865	CE Loss:	0.2042	Distill Loss:	0.2921	Source Loss:	0.1946
[2025-10-28 15:57:01]   [Train]	Acc:	0.9688
[2025-10-28 15:57:01]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-28 15:57:01]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4170
[2025-10-28 15:57:01]   [Cough   ]	F1:	0.6638	Precision:	0.5066	Recall:	0.9625
[2025-10-28 15:57:01]   [NonCough]	F1:	0.1702	Precision:	0.7273	Recall:	0.0964
[2025-10-28 15:57:01]   [Stats]	Many:	96.2500	Medium:	9.6386	Few:	0.0000
[2025-10-28 15:57:01]   [Param]	LR:	0.00044774
[2025-10-28 15:57:01] Epoch 18/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:18] Stage2 - Epoch: [18 | 30]
[2025-10-28 15:57:18]   [Train]	Total Loss:	0.4704	CE Loss:	0.1949	Distill Loss:	0.2903	Source Loss:	0.1884
[2025-10-28 15:57:18]   [Train]	Acc:	0.9609
[2025-10-28 15:57:18]   [Test ]	Loss:	0.0000	Acc:	53.3742
[2025-10-28 15:57:18]   [Test ]	Micro F1:	0.5337	Macro F1:	0.4519
[2025-10-28 15:57:18]   [Cough   ]	F1:	0.6637	Precision:	0.5137	Recall:	0.9375
[2025-10-28 15:57:18]   [NonCough]	F1:	0.2400	Precision:	0.7059	Recall:	0.1446
[2025-10-28 15:57:18]   [Stats]	Many:	93.7500	Medium:	14.4578	Few:	0.0000
[2025-10-28 15:57:18]   [Param]	LR:	0.00039604
[2025-10-28 15:57:18] Epoch 19/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:27] Stage2 - Epoch: [19 | 30]
[2025-10-28 15:57:27]   [Train]	Total Loss:	0.4598	CE Loss:	0.1856	Distill Loss:	0.3015	Source Loss:	0.1838
[2025-10-28 15:57:27]   [Train]	Acc:	0.9701
[2025-10-28 15:57:27]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-28 15:57:27]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4310
[2025-10-28 15:57:27]   [Cough   ]	F1:	0.6579	Precision:	0.5068	Recall:	0.9375
[2025-10-28 15:57:27]   [NonCough]	F1:	0.2041	Precision:	0.6667	Recall:	0.1205
[2025-10-28 15:57:27]   [Stats]	Many:	93.7500	Medium:	12.0482	Few:	0.0000
[2025-10-28 15:57:27]   [Param]	LR:	0.00034549
[2025-10-28 15:57:27] Epoch 20/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:36] Stage2 - Epoch: [20 | 30]
[2025-10-28 15:57:36]   [Train]	Total Loss:	0.4218	CE Loss:	0.1669	Distill Loss:	0.2901	Source Loss:	0.1678
[2025-10-28 15:57:36]   [Train]	Acc:	0.9805
[2025-10-28 15:57:36]   [Test ]	Loss:	0.0000	Acc:	49.6933
[2025-10-28 15:57:36]   [Test ]	Micro F1:	0.4969	Macro F1:	0.3524
[2025-10-28 15:57:36]   [Cough   ]	F1:	0.6583	Precision:	0.4938	Recall:	0.9875
[2025-10-28 15:57:36]   [NonCough]	F1:	0.0465	Precision:	0.6667	Recall:	0.0241
[2025-10-28 15:57:36]   [Stats]	Many:	98.7500	Medium:	2.4096	Few:	0.0000
[2025-10-28 15:57:36]   [Param]	LR:	0.00029663
[2025-10-28 15:57:36] Epoch 21/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:44] Stage2 - Epoch: [21 | 30]
[2025-10-28 15:57:44]   [Train]	Total Loss:	0.3854	CE Loss:	0.1509	Distill Loss:	0.2758	Source Loss:	0.1518
[2025-10-28 15:57:44]   [Train]	Acc:	0.9883
[2025-10-28 15:57:44]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-28 15:57:44]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-28 15:57:44]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-28 15:57:44]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-28 15:57:44]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-28 15:57:44]   [Param]	LR:	0.00025000
[2025-10-28 15:57:44] Epoch 22/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:57:53] Stage2 - Epoch: [22 | 30]
[2025-10-28 15:57:53]   [Train]	Total Loss:	0.4178	CE Loss:	0.1650	Distill Loss:	0.2984	Source Loss:	0.1633
[2025-10-28 15:57:53]   [Train]	Acc:	0.9844
[2025-10-28 15:57:53]   [Test ]	Loss:	0.0000	Acc:	50.3067
[2025-10-28 15:57:53]   [Test ]	Micro F1:	0.5031	Macro F1:	0.3650
[2025-10-28 15:57:53]   [Cough   ]	F1:	0.6611	Precision:	0.4969	Recall:	0.9875
[2025-10-28 15:57:53]   [NonCough]	F1:	0.0690	Precision:	0.7500	Recall:	0.0361
[2025-10-28 15:57:53]   [Stats]	Many:	98.7500	Medium:	3.6145	Few:	0.0000
[2025-10-28 15:57:53]   [Param]	LR:	0.00020611
[2025-10-28 15:57:53] Epoch 23/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:02] Stage2 - Epoch: [23 | 30]
[2025-10-28 15:58:02]   [Train]	Total Loss:	0.3861	CE Loss:	0.1533	Distill Loss:	0.2798	Source Loss:	0.1488
[2025-10-28 15:58:02]   [Train]	Acc:	0.9857
[2025-10-28 15:58:02]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-28 15:58:02]   [Test ]	Micro F1:	0.5153	Macro F1:	0.4057
[2025-10-28 15:58:02]   [Cough   ]	F1:	0.6609	Precision:	0.5033	Recall:	0.9625
[2025-10-28 15:58:02]   [NonCough]	F1:	0.1505	Precision:	0.7000	Recall:	0.0843
[2025-10-28 15:58:02]   [Stats]	Many:	96.2500	Medium:	8.4337	Few:	0.0000
[2025-10-28 15:58:02]   [Param]	LR:	0.00016543
[2025-10-28 15:58:02] Epoch 24/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:10] Stage2 - Epoch: [24 | 30]
[2025-10-28 15:58:10]   [Train]	Total Loss:	0.3682	CE Loss:	0.1497	Distill Loss:	0.2752	Source Loss:	0.1360
[2025-10-28 15:58:10]   [Train]	Acc:	0.9883
[2025-10-28 15:58:10]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-28 15:58:10]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4014
[2025-10-28 15:58:10]   [Cough   ]	F1:	0.6695	Precision:	0.5064	Recall:	0.9875
[2025-10-28 15:58:10]   [NonCough]	F1:	0.1333	Precision:	0.8571	Recall:	0.0723
[2025-10-28 15:58:10]   [Stats]	Many:	98.7500	Medium:	7.2289	Few:	0.0000
[2025-10-28 15:58:10]   [Param]	LR:	0.00012843
[2025-10-28 15:58:10] Epoch 25/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:19] Stage2 - Epoch: [25 | 30]
[2025-10-28 15:58:19]   [Train]	Total Loss:	0.3792	CE Loss:	0.1475	Distill Loss:	0.2715	Source Loss:	0.1502
[2025-10-28 15:58:19]   [Train]	Acc:	0.9857
[2025-10-28 15:58:19]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:58:19]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3774
[2025-10-28 15:58:19]   [Cough   ]	F1:	0.6639	Precision:	0.5000	Recall:	0.9875
[2025-10-28 15:58:19]   [NonCough]	F1:	0.0909	Precision:	0.8000	Recall:	0.0482
[2025-10-28 15:58:19]   [Stats]	Many:	98.7500	Medium:	4.8193	Few:	0.0000
[2025-10-28 15:58:19]   [Param]	LR:	0.00009549
[2025-10-28 15:58:19] Epoch 26/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:28] Stage2 - Epoch: [26 | 30]
[2025-10-28 15:58:28]   [Train]	Total Loss:	0.3514	CE Loss:	0.1399	Distill Loss:	0.2515	Source Loss:	0.1361
[2025-10-28 15:58:28]   [Train]	Acc:	0.9922
[2025-10-28 15:58:28]   [Test ]	Loss:	0.0000	Acc:	52.7607
[2025-10-28 15:58:28]   [Test ]	Micro F1:	0.5276	Macro F1:	0.4131
[2025-10-28 15:58:28]   [Cough   ]	F1:	0.6723	Precision:	0.5097	Recall:	0.9875
[2025-10-28 15:58:28]   [NonCough]	F1:	0.1538	Precision:	0.8750	Recall:	0.0843
[2025-10-28 15:58:28]   [Stats]	Many:	98.7500	Medium:	8.4337	Few:	0.0000
[2025-10-28 15:58:28]   [Param]	LR:	0.00006699
[2025-10-28 15:58:28] Epoch 27/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:38] Stage2 - Epoch: [27 | 30]
[2025-10-28 15:58:38]   [Train]	Total Loss:	0.3583	CE Loss:	0.1483	Distill Loss:	0.2553	Source Loss:	0.1334
[2025-10-28 15:58:38]   [Train]	Acc:	0.9844
[2025-10-28 15:58:38]   [Test ]	Loss:	0.0000	Acc:	50.3067
[2025-10-28 15:58:38]   [Test ]	Micro F1:	0.5031	Macro F1:	0.3650
[2025-10-28 15:58:38]   [Cough   ]	F1:	0.6611	Precision:	0.4969	Recall:	0.9875
[2025-10-28 15:58:38]   [NonCough]	F1:	0.0690	Precision:	0.7500	Recall:	0.0361
[2025-10-28 15:58:38]   [Stats]	Many:	98.7500	Medium:	3.6145	Few:	0.0000
[2025-10-28 15:58:38]   [Param]	LR:	0.00004323
[2025-10-28 15:58:38] Epoch 28/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:44] Stage2 - Epoch: [28 | 30]
[2025-10-28 15:58:44]   [Train]	Total Loss:	0.3564	CE Loss:	0.1385	Distill Loss:	0.2324	Source Loss:	0.1481
[2025-10-28 15:58:44]   [Train]	Acc:	0.9922
[2025-10-28 15:58:44]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-28 15:58:44]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-28 15:58:44]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-28 15:58:44]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-28 15:58:44]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-28 15:58:44]   [Param]	LR:	0.00002447
[2025-10-28 15:58:44] Epoch 29/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:58:53] Stage2 - Epoch: [29 | 30]
[2025-10-28 15:58:53]   [Train]	Total Loss:	0.3395	CE Loss:	0.1370	Distill Loss:	0.2189	Source Loss:	0.1368
[2025-10-28 15:58:53]   [Train]	Acc:	0.9909
[2025-10-28 15:58:53]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-28 15:58:53]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3774
[2025-10-28 15:58:53]   [Cough   ]	F1:	0.6639	Precision:	0.5000	Recall:	0.9875
[2025-10-28 15:58:53]   [NonCough]	F1:	0.0909	Precision:	0.8000	Recall:	0.0482
[2025-10-28 15:58:53]   [Stats]	Many:	98.7500	Medium:	4.8193	Few:	0.0000
[2025-10-28 15:58:53]   [Param]	LR:	0.00001093
[2025-10-28 15:58:53] Epoch 30/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-28 15:59:01] Stage2 - Epoch: [30 | 30]
[2025-10-28 15:59:01]   [Train]	Total Loss:	0.3407	CE Loss:	0.1442	Distill Loss:	0.2188	Source Loss:	0.1308
[2025-10-28 15:59:01]   [Train]	Acc:	0.9870
[2025-10-28 15:59:01]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-28 15:59:01]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-28 15:59:01]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-28 15:59:01]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-28 15:59:01]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-28 15:59:01]   [Param]	LR:	0.00000274
[2025-10-28 15:59:03] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-51/best_model_stage2_audio.pth
[2025-10-28 15:59:03] F1 score plot for stage2 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-28_15-51/stage2_macro_f1.png
[2025-10-28 15:59:03] Stage 2 Training Time: 00:04:23
[2025-10-28 15:59:03] Stage 2 Best Target Macro F1: 0.8307
