[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:29:59] MODEL COMPLEXITY
[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:29:59] FLOPs: 863.897M
[2025-10-29 10:29:59] Parameters: 72.142M
[2025-10-29 10:29:59]   FLOPs (exact): 863896576
[2025-10-29 10:29:59]   Parameters (exact): 72141700
[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:29:59] ABLATION EXPERIMENT CONFIGURATION
[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:29:59] WeightedRandomSampler: ENABLED
[2025-10-29 10:29:59] Focal Loss: DISABLED
[2025-10-29 10:29:59] Logit Adjustment: DISABLED
[2025-10-29 10:29:59] Label Smoothing: 0.98
[2025-10-29 10:29:59] Stage 2 Use Source Data: ENABLED
[2025-10-29 10:29:59]     - Source/Target Ratio: 2.0
[2025-10-29 10:29:59] Stage 2 Sliding Window Filter: ENABLED
[2025-10-29 10:29:59]     - Confidence Threshold: 0.65
[2025-10-29 10:29:59] ============================================================
[2025-10-29 10:30:05] Stage1 - Epoch: [1 | 100]
[2025-10-29 10:30:05]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-29 10:30:05]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-29 10:30:05]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-29 10:30:05]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-29 10:30:05]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-29 10:30:05]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-29 10:30:05]   [Param]	LR:	0.00010000
[2025-10-29 10:30:11] Stage1 - Epoch: [2 | 100]
[2025-10-29 10:30:11]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-29 10:30:11]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-29 10:30:11]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-29 10:30:11]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-29 10:30:11]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-29 10:30:11]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-29 10:30:11]   [Param]	LR:	0.00009998
[2025-10-29 10:30:16] Stage1 - Epoch: [3 | 100]
[2025-10-29 10:30:16]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-29 10:30:16]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-29 10:30:16]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-29 10:30:16]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-29 10:30:16]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-29 10:30:16]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-29 10:30:16]   [Param]	LR:	0.00009990
[2025-10-29 10:30:22] Stage1 - Epoch: [4 | 100]
[2025-10-29 10:30:22]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-29 10:30:22]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-29 10:30:22]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-29 10:30:22]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-29 10:30:22]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-29 10:30:22]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-29 10:30:22]   [Param]	LR:	0.00009978
[2025-10-29 10:30:28] Stage1 - Epoch: [5 | 100]
[2025-10-29 10:30:28]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-29 10:30:28]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-29 10:30:28]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-29 10:30:28]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-29 10:30:28]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-29 10:30:28]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-29 10:30:28]   [Param]	LR:	0.00009961
[2025-10-29 10:30:34] Stage1 - Epoch: [6 | 100]
[2025-10-29 10:30:34]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-29 10:30:34]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-29 10:30:34]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-29 10:30:34]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-29 10:30:34]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-29 10:30:34]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-29 10:30:34]   [Param]	LR:	0.00009938
[2025-10-29 10:30:39] Stage1 - Epoch: [7 | 100]
[2025-10-29 10:30:39]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-29 10:30:39]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-29 10:30:39]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-29 10:30:39]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-29 10:30:39]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-29 10:30:39]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-29 10:30:39]   [Param]	LR:	0.00009911
[2025-10-29 10:30:45] Stage1 - Epoch: [8 | 100]
[2025-10-29 10:30:45]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-29 10:30:45]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-29 10:30:45]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-29 10:30:45]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-29 10:30:45]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-29 10:30:45]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-29 10:30:45]   [Param]	LR:	0.00009880
[2025-10-29 10:30:51] Stage1 - Epoch: [9 | 100]
[2025-10-29 10:30:51]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-29 10:30:51]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-29 10:30:51]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-29 10:30:51]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-29 10:30:51]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-29 10:30:51]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-29 10:30:51]   [Param]	LR:	0.00009843
[2025-10-29 10:30:57] Stage1 - Epoch: [10 | 100]
[2025-10-29 10:30:57]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-29 10:30:57]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-29 10:30:57]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:30:57]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:30:57]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:30:57]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:30:57]   [Param]	LR:	0.00009801
[2025-10-29 10:31:03] Stage1 - Epoch: [11 | 100]
[2025-10-29 10:31:03]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-29 10:31:03]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-29 10:31:03]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:31:03]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:31:03]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:31:03]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:31:03]   [Param]	LR:	0.00009755
[2025-10-29 10:31:09] Stage1 - Epoch: [12 | 100]
[2025-10-29 10:31:09]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-29 10:31:09]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-29 10:31:09]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-29 10:31:09]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-29 10:31:09]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-29 10:31:09]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:31:09]   [Param]	LR:	0.00009704
[2025-10-29 10:31:15] Stage1 - Epoch: [13 | 100]
[2025-10-29 10:31:15]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-29 10:31:15]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-29 10:31:15]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:31:15]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:31:15]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:31:15]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:15]   [Param]	LR:	0.00009649
[2025-10-29 10:31:21] Stage1 - Epoch: [14 | 100]
[2025-10-29 10:31:21]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-29 10:31:21]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-29 10:31:21]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:31:21]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:31:21]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:31:21]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:21]   [Param]	LR:	0.00009589
[2025-10-29 10:31:27] Stage1 - Epoch: [15 | 100]
[2025-10-29 10:31:27]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-29 10:31:27]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-29 10:31:27]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:31:27]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:31:27]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:31:27]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:31:27]   [Param]	LR:	0.00009524
[2025-10-29 10:31:33] Stage1 - Epoch: [16 | 100]
[2025-10-29 10:31:33]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-29 10:31:33]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-29 10:31:33]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 10:31:33]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 10:31:33]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 10:31:33]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 10:31:33]   [Param]	LR:	0.00009455
[2025-10-29 10:31:39] Stage1 - Epoch: [17 | 100]
[2025-10-29 10:31:39]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-29 10:31:39]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-29 10:31:39]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 10:31:39]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 10:31:39]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 10:31:39]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:39]   [Param]	LR:	0.00009382
[2025-10-29 10:31:45] Stage1 - Epoch: [18 | 100]
[2025-10-29 10:31:45]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-29 10:31:45]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 10:31:45]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:31:45]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:31:45]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:31:45]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:45]   [Param]	LR:	0.00009304
[2025-10-29 10:31:51] Stage1 - Epoch: [19 | 100]
[2025-10-29 10:31:51]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-29 10:31:51]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-29 10:31:51]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 10:31:51]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 10:31:51]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 10:31:51]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:51]   [Param]	LR:	0.00009222
[2025-10-29 10:31:57] Stage1 - Epoch: [20 | 100]
[2025-10-29 10:31:57]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-29 10:31:57]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-29 10:31:57]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:31:57]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:31:57]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:31:57]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:31:57]   [Param]	LR:	0.00009135
[2025-10-29 10:32:03] Stage1 - Epoch: [21 | 100]
[2025-10-29 10:32:03]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-29 10:32:03]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-29 10:32:03]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:32:03]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:32:03]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:32:03]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:03]   [Param]	LR:	0.00009045
[2025-10-29 10:32:09] Stage1 - Epoch: [22 | 100]
[2025-10-29 10:32:09]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-29 10:32:09]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-29 10:32:09]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:32:09]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:32:09]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:32:09]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:09]   [Param]	LR:	0.00008951
[2025-10-29 10:32:15] Stage1 - Epoch: [23 | 100]
[2025-10-29 10:32:15]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-29 10:32:15]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-29 10:32:15]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:32:15]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:32:15]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:32:15]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:15]   [Param]	LR:	0.00008853
[2025-10-29 10:32:21] Stage1 - Epoch: [24 | 100]
[2025-10-29 10:32:21]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-29 10:32:21]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-29 10:32:21]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-29 10:32:21]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-29 10:32:21]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-29 10:32:21]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:21]   [Param]	LR:	0.00008751
[2025-10-29 10:32:26] Stage1 - Epoch: [25 | 100]
[2025-10-29 10:32:26]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-29 10:32:26]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 10:32:26]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:32:26]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:32:26]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:32:26]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:26]   [Param]	LR:	0.00008645
[2025-10-29 10:32:32] Stage1 - Epoch: [26 | 100]
[2025-10-29 10:32:32]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-29 10:32:32]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-29 10:32:32]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:32:32]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:32:32]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:32:32]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:32]   [Param]	LR:	0.00008536
[2025-10-29 10:32:37] Stage1 - Epoch: [27 | 100]
[2025-10-29 10:32:37]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-29 10:32:37]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-29 10:32:37]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:32:37]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:32:37]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:32:37]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:37]   [Param]	LR:	0.00008423
[2025-10-29 10:32:43] Stage1 - Epoch: [28 | 100]
[2025-10-29 10:32:43]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-29 10:32:43]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-29 10:32:43]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:32:43]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:32:43]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:32:43]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:43]   [Param]	LR:	0.00008307
[2025-10-29 10:32:49] Stage1 - Epoch: [29 | 100]
[2025-10-29 10:32:49]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-29 10:32:49]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-29 10:32:49]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:32:49]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:32:49]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:32:49]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:49]   [Param]	LR:	0.00008187
[2025-10-29 10:32:55] Stage1 - Epoch: [30 | 100]
[2025-10-29 10:32:55]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-29 10:32:55]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-29 10:32:55]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 10:32:55]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 10:32:55]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 10:32:55]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:32:55]   [Param]	LR:	0.00008065
[2025-10-29 10:33:01] Stage1 - Epoch: [31 | 100]
[2025-10-29 10:33:01]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-29 10:33:01]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-29 10:33:01]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:33:01]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:33:01]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:33:01]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:01]   [Param]	LR:	0.00007939
[2025-10-29 10:33:07] Stage1 - Epoch: [32 | 100]
[2025-10-29 10:33:07]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-29 10:33:07]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-29 10:33:07]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:33:07]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:33:07]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:33:07]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:07]   [Param]	LR:	0.00007810
[2025-10-29 10:33:13] Stage1 - Epoch: [33 | 100]
[2025-10-29 10:33:13]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-29 10:33:13]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-29 10:33:13]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:33:13]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:33:13]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:33:13]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:13]   [Param]	LR:	0.00007679
[2025-10-29 10:33:19] Stage1 - Epoch: [34 | 100]
[2025-10-29 10:33:19]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-29 10:33:19]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-29 10:33:19]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:33:19]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:33:19]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:33:19]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:19]   [Param]	LR:	0.00007545
[2025-10-29 10:33:25] Stage1 - Epoch: [35 | 100]
[2025-10-29 10:33:25]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-29 10:33:25]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-29 10:33:25]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 10:33:25]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 10:33:25]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 10:33:25]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:25]   [Param]	LR:	0.00007409
[2025-10-29 10:33:31] Stage1 - Epoch: [36 | 100]
[2025-10-29 10:33:31]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-29 10:33:31]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-29 10:33:31]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 10:33:31]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 10:33:31]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 10:33:31]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:31]   [Param]	LR:	0.00007270
[2025-10-29 10:33:31] Early stopping triggered after 36 epochs.
[2025-10-29 10:33:32] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_10-29/best_model_stage1_audio.pth
[2025-10-29 10:33:32] F1 score plot for stage1 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_10-29/stage1_macro_f1.png
[2025-10-29 10:33:32] Stage 1 Training Time: 00:03:32
[2025-10-29 10:33:32] Stage 1 Best Macro F1: 0.9542
[2025-10-29 10:33:32] Confidence threshold: 0.65
[2025-10-29 10:33:41] Total samples: 649
[2025-10-29 10:33:41] Total windows checked: 1127
[2025-10-29 10:33:41] Cough windows found: 168
[2025-10-29 10:33:41] High-confidence negative windows found: 799
[2025-10-29 10:33:41] Total kept windows: 967
[2025-10-29 10:33:41] Selection rate: 85.80%
[2025-10-29 10:33:41] Using filtered dataset with 967 cough segments
[2025-10-29 10:33:41] Starting pseudo-label precomputation for curriculum learning...
[2025-10-29 10:33:45] Confidence statistics - Min: 0.6515, Max: 0.9996, Mean: 0.9183, Median: 0.9558
[2025-10-29 10:33:45] Precomputed 967 samples with confidence scores
[2025-10-29 10:33:45] Epoch 1/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:33:56] Stage2 - Epoch: [1 | 30]
[2025-10-29 10:33:56]   [Train]	Total Loss:	33.8926	CE Loss:	7.5080	Distill Loss:	16.2163	Source Loss:	15.0332
[2025-10-29 10:33:56]   [Train]	Acc:	0.7552
[2025-10-29 10:33:56]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-29 10:33:56]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-29 10:33:56]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:33:56]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-29 10:33:56]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:33:56]   [Param]	LR:	0.00100000
[2025-10-29 10:33:56] Epoch 2/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:34:08] Stage2 - Epoch: [2 | 30]
[2025-10-29 10:34:08]   [Train]	Total Loss:	1.2375	CE Loss:	0.2793	Distill Loss:	0.4104	Source Loss:	0.6709
[2025-10-29 10:34:08]   [Train]	Acc:	0.9076
[2025-10-29 10:34:08]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-29 10:34:08]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3374
[2025-10-29 10:34:08]   [Cough   ]	F1:	0.0000	Precision:	0.0000	Recall:	0.0000
[2025-10-29 10:34:08]   [NonCough]	F1:	0.6748	Precision:	0.5092	Recall:	1.0000
[2025-10-29 10:34:08]   [Stats]	Many:	0.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:34:08]   [Param]	LR:	0.00099726
[2025-10-29 10:34:08] Epoch 3/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:34:20] Stage2 - Epoch: [3 | 30]
[2025-10-29 10:34:20]   [Train]	Total Loss:	0.8380	CE Loss:	0.1963	Distill Loss:	0.2178	Source Loss:	0.4893
[2025-10-29 10:34:20]   [Train]	Acc:	0.9115
[2025-10-29 10:34:20]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-29 10:34:20]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6348
[2025-10-29 10:34:20]   [Cough   ]	F1:	0.5138	Precision:	0.9655	Recall:	0.3500
[2025-10-29 10:34:20]   [NonCough]	F1:	0.7558	Precision:	0.6119	Recall:	0.9880
[2025-10-29 10:34:20]   [Stats]	Many:	35.0000	Medium:	98.7952	Few:	0.0000
[2025-10-29 10:34:20]   [Param]	LR:	0.00098907
[2025-10-29 10:34:20] Epoch 4/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:34:31] Stage2 - Epoch: [4 | 30]
[2025-10-29 10:34:31]   [Train]	Total Loss:	0.6981	CE Loss:	0.1692	Distill Loss:	0.1727	Source Loss:	0.4080
[2025-10-29 10:34:31]   [Train]	Acc:	0.9648
[2025-10-29 10:34:31]   [Test ]	Loss:	0.0000	Acc:	53.3742
[2025-10-29 10:34:31]   [Test ]	Micro F1:	0.5337	Macro F1:	0.3906
[2025-10-29 10:34:31]   [Cough   ]	F1:	0.0952	Precision:	1.0000	Recall:	0.0500
[2025-10-29 10:34:31]   [NonCough]	F1:	0.6860	Precision:	0.5220	Recall:	1.0000
[2025-10-29 10:34:31]   [Stats]	Many:	5.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:34:31]   [Param]	LR:	0.00097553
[2025-10-29 10:34:31] Epoch 5/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:34:43] Stage2 - Epoch: [5 | 30]
[2025-10-29 10:34:43]   [Train]	Total Loss:	0.6482	CE Loss:	0.1735	Distill Loss:	0.1897	Source Loss:	0.3419
[2025-10-29 10:34:43]   [Train]	Acc:	0.9635
[2025-10-29 10:34:43]   [Test ]	Loss:	0.0000	Acc:	54.6012
[2025-10-29 10:34:43]   [Test ]	Micro F1:	0.5460	Macro F1:	0.4156
[2025-10-29 10:34:43]   [Cough   ]	F1:	0.1395	Precision:	1.0000	Recall:	0.0750
[2025-10-29 10:34:43]   [NonCough]	F1:	0.6917	Precision:	0.5287	Recall:	1.0000
[2025-10-29 10:34:43]   [Stats]	Many:	7.5000	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:34:43]   [Param]	LR:	0.00095677
[2025-10-29 10:34:43] Epoch 6/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:34:54] Stage2 - Epoch: [6 | 30]
[2025-10-29 10:34:54]   [Train]	Total Loss:	0.5228	CE Loss:	0.1634	Distill Loss:	0.1799	Source Loss:	0.3054
[2025-10-29 10:34:54]   [Train]	Acc:	0.9688
[2025-10-29 10:34:54]   [Test ]	Loss:	0.0000	Acc:	55.2147
[2025-10-29 10:34:54]   [Test ]	Micro F1:	0.5521	Macro F1:	0.4277
[2025-10-29 10:34:54]   [Cough   ]	F1:	0.1609	Precision:	1.0000	Recall:	0.0875
[2025-10-29 10:34:54]   [NonCough]	F1:	0.6946	Precision:	0.5321	Recall:	1.0000
[2025-10-29 10:34:54]   [Stats]	Many:	8.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 10:34:54]   [Param]	LR:	0.00093301
[2025-10-29 10:34:54] Epoch 7/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:06] Stage2 - Epoch: [7 | 30]
[2025-10-29 10:35:06]   [Train]	Total Loss:	0.5403	CE Loss:	0.1758	Distill Loss:	0.2996	Source Loss:	0.2746
[2025-10-29 10:35:06]   [Train]	Acc:	0.9479
[2025-10-29 10:35:06]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-29 10:35:06]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6517
[2025-10-29 10:35:06]   [Cough   ]	F1:	0.5405	Precision:	0.9677	Recall:	0.3750
[2025-10-29 10:35:06]   [NonCough]	F1:	0.7628	Precision:	0.6212	Recall:	0.9880
[2025-10-29 10:35:06]   [Stats]	Many:	37.5000	Medium:	98.7952	Few:	0.0000
[2025-10-29 10:35:06]   [Param]	LR:	0.00090451
[2025-10-29 10:35:06] Epoch 8/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:18] Stage2 - Epoch: [8 | 30]
[2025-10-29 10:35:18]   [Train]	Total Loss:	0.5368	CE Loss:	0.1921	Distill Loss:	0.2979	Source Loss:	0.2554
[2025-10-29 10:35:18]   [Train]	Acc:	0.9232
[2025-10-29 10:35:18]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-29 10:35:18]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6348
[2025-10-29 10:35:18]   [Cough   ]	F1:	0.5138	Precision:	0.9655	Recall:	0.3500
[2025-10-29 10:35:18]   [NonCough]	F1:	0.7558	Precision:	0.6119	Recall:	0.9880
[2025-10-29 10:35:18]   [Stats]	Many:	35.0000	Medium:	98.7952	Few:	0.0000
[2025-10-29 10:35:18]   [Param]	LR:	0.00087157
[2025-10-29 10:35:18] Epoch 9/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:27] Stage2 - Epoch: [9 | 30]
[2025-10-29 10:35:27]   [Train]	Total Loss:	0.8114	CE Loss:	0.4418	Distill Loss:	0.3066	Source Loss:	0.2776
[2025-10-29 10:35:27]   [Train]	Acc:	0.7695
[2025-10-29 10:35:27]   [Test ]	Loss:	0.0000	Acc:	83.4356
[2025-10-29 10:35:27]   [Test ]	Micro F1:	0.8344	Macro F1:	0.8307
[2025-10-29 10:35:27]   [Cough   ]	F1:	0.8058	Precision:	0.9492	Recall:	0.7000
[2025-10-29 10:35:27]   [NonCough]	F1:	0.8556	Precision:	0.7692	Recall:	0.9639
[2025-10-29 10:35:27]   [Stats]	Many:	70.0000	Medium:	96.3855	Few:	0.0000
[2025-10-29 10:35:27]   [Param]	LR:	0.00083457
[2025-10-29 10:35:27] Epoch 10/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:35] Stage2 - Epoch: [10 | 30]
[2025-10-29 10:35:35]   [Train]	Total Loss:	0.8913	CE Loss:	0.5221	Distill Loss:	0.2847	Source Loss:	0.2838
[2025-10-29 10:35:35]   [Train]	Acc:	0.7240
[2025-10-29 10:35:35]   [Test ]	Loss:	0.0000	Acc:	76.0736
[2025-10-29 10:35:35]   [Test ]	Micro F1:	0.7607	Macro F1:	0.7598
[2025-10-29 10:35:35]   [Cough   ]	F1:	0.7746	Precision:	0.7204	Recall:	0.8375
[2025-10-29 10:35:35]   [NonCough]	F1:	0.7451	Precision:	0.8143	Recall:	0.6867
[2025-10-29 10:35:35]   [Stats]	Many:	83.7500	Medium:	68.6747	Few:	0.0000
[2025-10-29 10:35:35]   [Param]	LR:	0.00079389
[2025-10-29 10:35:35] Epoch 11/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:43] Stage2 - Epoch: [11 | 30]
[2025-10-29 10:35:43]   [Train]	Total Loss:	0.8387	CE Loss:	0.4859	Distill Loss:	0.2877	Source Loss:	0.2665
[2025-10-29 10:35:43]   [Train]	Acc:	0.7708
[2025-10-29 10:35:43]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-29 10:35:43]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6789
[2025-10-29 10:35:43]   [Cough   ]	F1:	0.7302	Precision:	0.6330	Recall:	0.8625
[2025-10-29 10:35:43]   [NonCough]	F1:	0.6277	Precision:	0.7963	Recall:	0.5181
[2025-10-29 10:35:43]   [Stats]	Many:	86.2500	Medium:	51.8072	Few:	0.0000
[2025-10-29 10:35:43]   [Param]	LR:	0.00075000
[2025-10-29 10:35:43] Epoch 12/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:50] Stage2 - Epoch: [12 | 30]
[2025-10-29 10:35:50]   [Train]	Total Loss:	0.7625	CE Loss:	0.4057	Distill Loss:	0.2717	Source Loss:	0.2752
[2025-10-29 10:35:50]   [Train]	Acc:	0.8268
[2025-10-29 10:35:50]   [Test ]	Loss:	0.0000	Acc:	58.8957
[2025-10-29 10:35:50]   [Test ]	Micro F1:	0.5890	Macro F1:	0.5245
[2025-10-29 10:35:50]   [Cough   ]	F1:	0.6996	Precision:	0.5455	Recall:	0.9750
[2025-10-29 10:35:50]   [NonCough]	F1:	0.3495	Precision:	0.9000	Recall:	0.2169
[2025-10-29 10:35:50]   [Stats]	Many:	97.5000	Medium:	21.6867	Few:	0.0000
[2025-10-29 10:35:50]   [Param]	LR:	0.00070337
[2025-10-29 10:35:50] Epoch 13/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:35:58] Stage2 - Epoch: [13 | 30]
[2025-10-29 10:35:58]   [Train]	Total Loss:	0.7294	CE Loss:	0.3677	Distill Loss:	0.2828	Source Loss:	0.2768
[2025-10-29 10:35:58]   [Train]	Acc:	0.8620
[2025-10-29 10:35:58]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 10:35:58]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6720
[2025-10-29 10:35:58]   [Cough   ]	F1:	0.7263	Precision:	0.6273	Recall:	0.8625
[2025-10-29 10:35:58]   [NonCough]	F1:	0.6176	Precision:	0.7925	Recall:	0.5060
[2025-10-29 10:35:58]   [Stats]	Many:	86.2500	Medium:	50.6024	Few:	0.0000
[2025-10-29 10:35:58]   [Param]	LR:	0.00065451
[2025-10-29 10:35:58] Epoch 14/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:05] Stage2 - Epoch: [14 | 30]
[2025-10-29 10:36:05]   [Train]	Total Loss:	0.7216	CE Loss:	0.3467	Distill Loss:	0.3169	Source Loss:	0.2798
[2025-10-29 10:36:05]   [Train]	Acc:	0.8763
[2025-10-29 10:36:05]   [Test ]	Loss:	0.0000	Acc:	58.2822
[2025-10-29 10:36:05]   [Test ]	Micro F1:	0.5828	Macro F1:	0.5335
[2025-10-29 10:36:05]   [Cough   ]	F1:	0.6852	Precision:	0.5441	Recall:	0.9250
[2025-10-29 10:36:05]   [NonCough]	F1:	0.3818	Precision:	0.7778	Recall:	0.2530
[2025-10-29 10:36:05]   [Stats]	Many:	92.5000	Medium:	25.3012	Few:	0.0000
[2025-10-29 10:36:05]   [Param]	LR:	0.00060396
[2025-10-29 10:36:05] Epoch 15/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:13] Stage2 - Epoch: [15 | 30]
[2025-10-29 10:36:13]   [Train]	Total Loss:	0.5720	CE Loss:	0.2740	Distill Loss:	0.2978	Source Loss:	0.2086
[2025-10-29 10:36:13]   [Train]	Acc:	0.9102
[2025-10-29 10:36:13]   [Test ]	Loss:	0.0000	Acc:	54.6012
[2025-10-29 10:36:13]   [Test ]	Micro F1:	0.5460	Macro F1:	0.4776
[2025-10-29 10:36:13]   [Cough   ]	F1:	0.6667	Precision:	0.5211	Recall:	0.9250
[2025-10-29 10:36:13]   [NonCough]	F1:	0.2885	Precision:	0.7143	Recall:	0.1807
[2025-10-29 10:36:13]   [Stats]	Many:	92.5000	Medium:	18.0723	Few:	0.0000
[2025-10-29 10:36:13]   [Param]	LR:	0.00055226
[2025-10-29 10:36:13] Epoch 16/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:20] Stage2 - Epoch: [16 | 30]
[2025-10-29 10:36:20]   [Train]	Total Loss:	0.5177	CE Loss:	0.2379	Distill Loss:	0.2910	Source Loss:	0.1925
[2025-10-29 10:36:20]   [Train]	Acc:	0.9479
[2025-10-29 10:36:20]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-29 10:36:20]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3682
[2025-10-29 10:36:20]   [Cough   ]	F1:	0.6667	Precision:	0.5000	Recall:	1.0000
[2025-10-29 10:36:20]   [NonCough]	F1:	0.0698	Precision:	1.0000	Recall:	0.0361
[2025-10-29 10:36:20]   [Stats]	Many:	100.0000	Medium:	3.6145	Few:	0.0000
[2025-10-29 10:36:20]   [Param]	LR:	0.00050000
[2025-10-29 10:36:20] Epoch 17/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:28] Stage2 - Epoch: [17 | 30]
[2025-10-29 10:36:28]   [Train]	Total Loss:	0.4865	CE Loss:	0.2042	Distill Loss:	0.2921	Source Loss:	0.1946
[2025-10-29 10:36:28]   [Train]	Acc:	0.9688
[2025-10-29 10:36:28]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-29 10:36:28]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4170
[2025-10-29 10:36:28]   [Cough   ]	F1:	0.6638	Precision:	0.5066	Recall:	0.9625
[2025-10-29 10:36:28]   [NonCough]	F1:	0.1702	Precision:	0.7273	Recall:	0.0964
[2025-10-29 10:36:28]   [Stats]	Many:	96.2500	Medium:	9.6386	Few:	0.0000
[2025-10-29 10:36:28]   [Param]	LR:	0.00044774
[2025-10-29 10:36:28] Epoch 18/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:36] Stage2 - Epoch: [18 | 30]
[2025-10-29 10:36:36]   [Train]	Total Loss:	0.4704	CE Loss:	0.1949	Distill Loss:	0.2903	Source Loss:	0.1884
[2025-10-29 10:36:36]   [Train]	Acc:	0.9609
[2025-10-29 10:36:36]   [Test ]	Loss:	0.0000	Acc:	53.3742
[2025-10-29 10:36:36]   [Test ]	Micro F1:	0.5337	Macro F1:	0.4519
[2025-10-29 10:36:36]   [Cough   ]	F1:	0.6637	Precision:	0.5137	Recall:	0.9375
[2025-10-29 10:36:36]   [NonCough]	F1:	0.2400	Precision:	0.7059	Recall:	0.1446
[2025-10-29 10:36:36]   [Stats]	Many:	93.7500	Medium:	14.4578	Few:	0.0000
[2025-10-29 10:36:36]   [Param]	LR:	0.00039604
[2025-10-29 10:36:36] Epoch 19/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:43] Stage2 - Epoch: [19 | 30]
[2025-10-29 10:36:43]   [Train]	Total Loss:	0.4598	CE Loss:	0.1856	Distill Loss:	0.3015	Source Loss:	0.1838
[2025-10-29 10:36:43]   [Train]	Acc:	0.9701
[2025-10-29 10:36:43]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-29 10:36:43]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4310
[2025-10-29 10:36:43]   [Cough   ]	F1:	0.6579	Precision:	0.5068	Recall:	0.9375
[2025-10-29 10:36:43]   [NonCough]	F1:	0.2041	Precision:	0.6667	Recall:	0.1205
[2025-10-29 10:36:43]   [Stats]	Many:	93.7500	Medium:	12.0482	Few:	0.0000
[2025-10-29 10:36:43]   [Param]	LR:	0.00034549
[2025-10-29 10:36:43] Epoch 20/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:36:53] Stage2 - Epoch: [20 | 30]
[2025-10-29 10:36:53]   [Train]	Total Loss:	0.4218	CE Loss:	0.1669	Distill Loss:	0.2901	Source Loss:	0.1678
[2025-10-29 10:36:53]   [Train]	Acc:	0.9805
[2025-10-29 10:36:53]   [Test ]	Loss:	0.0000	Acc:	49.6933
[2025-10-29 10:36:53]   [Test ]	Micro F1:	0.4969	Macro F1:	0.3524
[2025-10-29 10:36:53]   [Cough   ]	F1:	0.6583	Precision:	0.4938	Recall:	0.9875
[2025-10-29 10:36:53]   [NonCough]	F1:	0.0465	Precision:	0.6667	Recall:	0.0241
[2025-10-29 10:36:53]   [Stats]	Many:	98.7500	Medium:	2.4096	Few:	0.0000
[2025-10-29 10:36:53]   [Param]	LR:	0.00029663
[2025-10-29 10:36:53] Epoch 21/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:01] Stage2 - Epoch: [21 | 30]
[2025-10-29 10:37:01]   [Train]	Total Loss:	0.3854	CE Loss:	0.1509	Distill Loss:	0.2758	Source Loss:	0.1518
[2025-10-29 10:37:01]   [Train]	Acc:	0.9883
[2025-10-29 10:37:01]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-29 10:37:01]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-29 10:37:01]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-29 10:37:01]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-29 10:37:01]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-29 10:37:01]   [Param]	LR:	0.00025000
[2025-10-29 10:37:01] Epoch 22/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:10] Stage2 - Epoch: [22 | 30]
[2025-10-29 10:37:10]   [Train]	Total Loss:	0.4178	CE Loss:	0.1650	Distill Loss:	0.2984	Source Loss:	0.1633
[2025-10-29 10:37:10]   [Train]	Acc:	0.9844
[2025-10-29 10:37:10]   [Test ]	Loss:	0.0000	Acc:	50.3067
[2025-10-29 10:37:10]   [Test ]	Micro F1:	0.5031	Macro F1:	0.3650
[2025-10-29 10:37:10]   [Cough   ]	F1:	0.6611	Precision:	0.4969	Recall:	0.9875
[2025-10-29 10:37:10]   [NonCough]	F1:	0.0690	Precision:	0.7500	Recall:	0.0361
[2025-10-29 10:37:10]   [Stats]	Many:	98.7500	Medium:	3.6145	Few:	0.0000
[2025-10-29 10:37:10]   [Param]	LR:	0.00020611
[2025-10-29 10:37:10] Epoch 23/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:18] Stage2 - Epoch: [23 | 30]
[2025-10-29 10:37:18]   [Train]	Total Loss:	0.3861	CE Loss:	0.1533	Distill Loss:	0.2798	Source Loss:	0.1488
[2025-10-29 10:37:18]   [Train]	Acc:	0.9857
[2025-10-29 10:37:18]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-29 10:37:18]   [Test ]	Micro F1:	0.5153	Macro F1:	0.4057
[2025-10-29 10:37:18]   [Cough   ]	F1:	0.6609	Precision:	0.5033	Recall:	0.9625
[2025-10-29 10:37:18]   [NonCough]	F1:	0.1505	Precision:	0.7000	Recall:	0.0843
[2025-10-29 10:37:18]   [Stats]	Many:	96.2500	Medium:	8.4337	Few:	0.0000
[2025-10-29 10:37:18]   [Param]	LR:	0.00016543
[2025-10-29 10:37:18] Epoch 24/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:25] Stage2 - Epoch: [24 | 30]
[2025-10-29 10:37:25]   [Train]	Total Loss:	0.3682	CE Loss:	0.1497	Distill Loss:	0.2752	Source Loss:	0.1360
[2025-10-29 10:37:25]   [Train]	Acc:	0.9883
[2025-10-29 10:37:25]   [Test ]	Loss:	0.0000	Acc:	52.1472
[2025-10-29 10:37:25]   [Test ]	Micro F1:	0.5215	Macro F1:	0.4014
[2025-10-29 10:37:25]   [Cough   ]	F1:	0.6695	Precision:	0.5064	Recall:	0.9875
[2025-10-29 10:37:25]   [NonCough]	F1:	0.1333	Precision:	0.8571	Recall:	0.0723
[2025-10-29 10:37:25]   [Stats]	Many:	98.7500	Medium:	7.2289	Few:	0.0000
[2025-10-29 10:37:25]   [Param]	LR:	0.00012843
[2025-10-29 10:37:25] Epoch 25/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:35] Stage2 - Epoch: [25 | 30]
[2025-10-29 10:37:35]   [Train]	Total Loss:	0.3792	CE Loss:	0.1475	Distill Loss:	0.2715	Source Loss:	0.1502
[2025-10-29 10:37:35]   [Train]	Acc:	0.9857
[2025-10-29 10:37:35]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-29 10:37:35]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3774
[2025-10-29 10:37:35]   [Cough   ]	F1:	0.6639	Precision:	0.5000	Recall:	0.9875
[2025-10-29 10:37:35]   [NonCough]	F1:	0.0909	Precision:	0.8000	Recall:	0.0482
[2025-10-29 10:37:35]   [Stats]	Many:	98.7500	Medium:	4.8193	Few:	0.0000
[2025-10-29 10:37:35]   [Param]	LR:	0.00009549
[2025-10-29 10:37:35] Epoch 26/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:43] Stage2 - Epoch: [26 | 30]
[2025-10-29 10:37:43]   [Train]	Total Loss:	0.3514	CE Loss:	0.1399	Distill Loss:	0.2515	Source Loss:	0.1361
[2025-10-29 10:37:43]   [Train]	Acc:	0.9922
[2025-10-29 10:37:43]   [Test ]	Loss:	0.0000	Acc:	52.7607
[2025-10-29 10:37:43]   [Test ]	Micro F1:	0.5276	Macro F1:	0.4131
[2025-10-29 10:37:43]   [Cough   ]	F1:	0.6723	Precision:	0.5097	Recall:	0.9875
[2025-10-29 10:37:43]   [NonCough]	F1:	0.1538	Precision:	0.8750	Recall:	0.0843
[2025-10-29 10:37:43]   [Stats]	Many:	98.7500	Medium:	8.4337	Few:	0.0000
[2025-10-29 10:37:43]   [Param]	LR:	0.00006699
[2025-10-29 10:37:43] Epoch 27/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:51] Stage2 - Epoch: [27 | 30]
[2025-10-29 10:37:51]   [Train]	Total Loss:	0.3583	CE Loss:	0.1483	Distill Loss:	0.2553	Source Loss:	0.1334
[2025-10-29 10:37:51]   [Train]	Acc:	0.9844
[2025-10-29 10:37:51]   [Test ]	Loss:	0.0000	Acc:	50.3067
[2025-10-29 10:37:51]   [Test ]	Micro F1:	0.5031	Macro F1:	0.3650
[2025-10-29 10:37:51]   [Cough   ]	F1:	0.6611	Precision:	0.4969	Recall:	0.9875
[2025-10-29 10:37:51]   [NonCough]	F1:	0.0690	Precision:	0.7500	Recall:	0.0361
[2025-10-29 10:37:51]   [Stats]	Many:	98.7500	Medium:	3.6145	Few:	0.0000
[2025-10-29 10:37:51]   [Param]	LR:	0.00004323
[2025-10-29 10:37:51] Epoch 28/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:37:59] Stage2 - Epoch: [28 | 30]
[2025-10-29 10:37:59]   [Train]	Total Loss:	0.3564	CE Loss:	0.1385	Distill Loss:	0.2324	Source Loss:	0.1481
[2025-10-29 10:37:59]   [Train]	Acc:	0.9922
[2025-10-29 10:37:59]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-29 10:37:59]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-29 10:37:59]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-29 10:37:59]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-29 10:37:59]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-29 10:37:59]   [Param]	LR:	0.00002447
[2025-10-29 10:37:59] Epoch 29/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:38:06] Stage2 - Epoch: [29 | 30]
[2025-10-29 10:38:06]   [Train]	Total Loss:	0.3395	CE Loss:	0.1370	Distill Loss:	0.2189	Source Loss:	0.1368
[2025-10-29 10:38:06]   [Train]	Acc:	0.9909
[2025-10-29 10:38:06]   [Test ]	Loss:	0.0000	Acc:	50.9202
[2025-10-29 10:38:06]   [Test ]	Micro F1:	0.5092	Macro F1:	0.3774
[2025-10-29 10:38:06]   [Cough   ]	F1:	0.6639	Precision:	0.5000	Recall:	0.9875
[2025-10-29 10:38:06]   [NonCough]	F1:	0.0909	Precision:	0.8000	Recall:	0.0482
[2025-10-29 10:38:06]   [Stats]	Many:	98.7500	Medium:	4.8193	Few:	0.0000
[2025-10-29 10:38:06]   [Param]	LR:	0.00001093
[2025-10-29 10:38:06] Epoch 30/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 10:38:14] Stage2 - Epoch: [30 | 30]
[2025-10-29 10:38:14]   [Train]	Total Loss:	0.3407	CE Loss:	0.1442	Distill Loss:	0.2188	Source Loss:	0.1308
[2025-10-29 10:38:14]   [Train]	Acc:	0.9870
[2025-10-29 10:38:14]   [Test ]	Loss:	0.0000	Acc:	51.5337
[2025-10-29 10:38:14]   [Test ]	Micro F1:	0.5153	Macro F1:	0.3895
[2025-10-29 10:38:14]   [Cough   ]	F1:	0.6667	Precision:	0.5032	Recall:	0.9875
[2025-10-29 10:38:14]   [NonCough]	F1:	0.1124	Precision:	0.8333	Recall:	0.0602
[2025-10-29 10:38:14]   [Stats]	Many:	98.7500	Medium:	6.0241	Few:	0.0000
[2025-10-29 10:38:14]   [Param]	LR:	0.00000274
[2025-10-29 10:38:15] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_10-29/best_model_stage2_audio.pth
[2025-10-29 10:38:15] F1 score plot for stage2 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_10-29/stage2_macro_f1.png
[2025-10-29 10:38:15] Stage 2 Training Time: 00:04:29
[2025-10-29 10:38:15] Stage 2 Best Target Macro F1: 0.8307
