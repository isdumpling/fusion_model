[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:51] MODEL COMPLEXITY
[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:51] FLOPs: 863.897M
[2025-10-29 11:04:51] Parameters: 72.142M
[2025-10-29 11:04:51]   FLOPs (exact): 863896576
[2025-10-29 11:04:51]   Parameters (exact): 72141700
[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:51] ABLATION EXPERIMENT CONFIGURATION
[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:51] WeightedRandomSampler: ENABLED
[2025-10-29 11:04:51] Focal Loss: DISABLED
[2025-10-29 11:04:51] Logit Adjustment: DISABLED
[2025-10-29 11:04:51] Label Smoothing: 0.98
[2025-10-29 11:04:51] Stage 2 Use Source Data: ENABLED
[2025-10-29 11:04:51]     - Source/Target Ratio: 2.0
[2025-10-29 11:04:51] Stage 2 Sliding Window Filter: ENABLED
[2025-10-29 11:04:51]     - Confidence Threshold: 0.65
[2025-10-29 11:04:51] ============================================================
[2025-10-29 11:04:56] Stage1 - Epoch: [1 | 100]
[2025-10-29 11:04:56]   [Train]	Loss:	0.6869	Acc:	0.5735
[2025-10-29 11:04:56]   [Test ]	Loss:	0.7048	Acc:	35.7664
[2025-10-29 11:04:56]   [Test ]	Micro F1:	0.3577	Macro F1:	0.3230
[2025-10-29 11:04:56]   [Cough   ]	F1:	0.1698	Precision:	0.0933	Recall:	0.9474
[2025-10-29 11:04:56]   [NonCough]	F1:	0.4762	Precision:	0.9877	Recall:	0.3137
[2025-10-29 11:04:56]   [Stats]	Many:	94.7368	Medium:	31.3725	Few:	0.0000
[2025-10-29 11:04:56]   [Param]	LR:	0.00010000
[2025-10-29 11:05:00] Stage1 - Epoch: [2 | 100]
[2025-10-29 11:05:00]   [Train]	Loss:	0.6086	Acc:	0.7188
[2025-10-29 11:05:00]   [Test ]	Loss:	0.6824	Acc:	61.3139
[2025-10-29 11:05:00]   [Test ]	Micro F1:	0.6131	Macro F1:	0.4817
[2025-10-29 11:05:00]   [Cough   ]	F1:	0.2206	Precision:	0.1282	Recall:	0.7895
[2025-10-29 11:05:00]   [NonCough]	F1:	0.7427	Precision:	0.9745	Recall:	0.6000
[2025-10-29 11:05:00]   [Stats]	Many:	78.9474	Medium:	60.0000	Few:	0.0000
[2025-10-29 11:05:00]   [Param]	LR:	0.00009998
[2025-10-29 11:05:04] Stage1 - Epoch: [3 | 100]
[2025-10-29 11:05:04]   [Train]	Loss:	0.4414	Acc:	0.8171
[2025-10-29 11:05:04]   [Test ]	Loss:	0.6728	Acc:	65.6934
[2025-10-29 11:05:04]   [Test ]	Micro F1:	0.6569	Macro F1:	0.5209
[2025-10-29 11:05:04]   [Cough   ]	F1:	0.2656	Precision:	0.1560	Recall:	0.8947
[2025-10-29 11:05:04]   [NonCough]	F1:	0.7762	Precision:	0.9879	Recall:	0.6392
[2025-10-29 11:05:04]   [Stats]	Many:	89.4737	Medium:	63.9216	Few:	0.0000
[2025-10-29 11:05:04]   [Param]	LR:	0.00009990
[2025-10-29 11:05:09] Stage1 - Epoch: [4 | 100]
[2025-10-29 11:05:09]   [Train]	Loss:	0.3620	Acc:	0.8750
[2025-10-29 11:05:09]   [Test ]	Loss:	0.3934	Acc:	85.7664
[2025-10-29 11:05:09]   [Test ]	Micro F1:	0.8577	Macro F1:	0.6845
[2025-10-29 11:05:09]   [Cough   ]	F1:	0.4507	Precision:	0.3077	Recall:	0.8421
[2025-10-29 11:05:09]   [NonCough]	F1:	0.9182	Precision:	0.9865	Recall:	0.8588
[2025-10-29 11:05:09]   [Stats]	Many:	84.2105	Medium:	85.8824	Few:	0.0000
[2025-10-29 11:05:09]   [Param]	LR:	0.00009978
[2025-10-29 11:05:13] Stage1 - Epoch: [5 | 100]
[2025-10-29 11:05:13]   [Train]	Loss:	0.2726	Acc:	0.9072
[2025-10-29 11:05:13]   [Test ]	Loss:	0.3586	Acc:	89.0511
[2025-10-29 11:05:13]   [Test ]	Micro F1:	0.8905	Macro F1:	0.7346
[2025-10-29 11:05:13]   [Cough   ]	F1:	0.5312	Precision:	0.3778	Recall:	0.8947
[2025-10-29 11:05:13]   [NonCough]	F1:	0.9380	Precision:	0.9913	Recall:	0.8902
[2025-10-29 11:05:13]   [Stats]	Many:	89.4737	Medium:	89.0196	Few:	0.0000
[2025-10-29 11:05:13]   [Param]	LR:	0.00009961
[2025-10-29 11:05:17] Stage1 - Epoch: [6 | 100]
[2025-10-29 11:05:17]   [Train]	Loss:	0.1899	Acc:	0.9412
[2025-10-29 11:05:17]   [Test ]	Loss:	0.2759	Acc:	93.0657
[2025-10-29 11:05:17]   [Test ]	Micro F1:	0.9307	Macro F1:	0.7789
[2025-10-29 11:05:17]   [Cough   ]	F1:	0.5957	Precision:	0.5000	Recall:	0.7368
[2025-10-29 11:05:17]   [NonCough]	F1:	0.9621	Precision:	0.9797	Recall:	0.9451
[2025-10-29 11:05:17]   [Stats]	Many:	73.6842	Medium:	94.5098	Few:	0.0000
[2025-10-29 11:05:17]   [Param]	LR:	0.00009938
[2025-10-29 11:05:21] Stage1 - Epoch: [7 | 100]
[2025-10-29 11:05:21]   [Train]	Loss:	0.1610	Acc:	0.9596
[2025-10-29 11:05:21]   [Test ]	Loss:	0.2779	Acc:	90.8759
[2025-10-29 11:05:21]   [Test ]	Micro F1:	0.9088	Macro F1:	0.7552
[2025-10-29 11:05:21]   [Cough   ]	F1:	0.5614	Precision:	0.4211	Recall:	0.8421
[2025-10-29 11:05:21]   [NonCough]	F1:	0.9491	Precision:	0.9873	Recall:	0.9137
[2025-10-29 11:05:21]   [Stats]	Many:	84.2105	Medium:	91.3725	Few:	0.0000
[2025-10-29 11:05:21]   [Param]	LR:	0.00009911
[2025-10-29 11:05:25] Stage1 - Epoch: [8 | 100]
[2025-10-29 11:05:25]   [Train]	Loss:	0.1284	Acc:	0.9798
[2025-10-29 11:05:25]   [Test ]	Loss:	0.2521	Acc:	95.6204
[2025-10-29 11:05:25]   [Test ]	Micro F1:	0.9562	Macro F1:	0.8517
[2025-10-29 11:05:25]   [Cough   ]	F1:	0.7273	Precision:	0.6400	Recall:	0.8421
[2025-10-29 11:05:25]   [NonCough]	F1:	0.9762	Precision:	0.9880	Recall:	0.9647
[2025-10-29 11:05:25]   [Stats]	Many:	84.2105	Medium:	96.4706	Few:	0.0000
[2025-10-29 11:05:25]   [Param]	LR:	0.00009880
[2025-10-29 11:05:29] Stage1 - Epoch: [9 | 100]
[2025-10-29 11:05:29]   [Train]	Loss:	0.1197	Acc:	0.9807
[2025-10-29 11:05:29]   [Test ]	Loss:	0.2382	Acc:	97.0803
[2025-10-29 11:05:29]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8869
[2025-10-29 11:05:29]   [Cough   ]	F1:	0.7895	Precision:	0.7895	Recall:	0.7895
[2025-10-29 11:05:29]   [NonCough]	F1:	0.9843	Precision:	0.9843	Recall:	0.9843
[2025-10-29 11:05:29]   [Stats]	Many:	78.9474	Medium:	98.4314	Few:	0.0000
[2025-10-29 11:05:29]   [Param]	LR:	0.00009843
[2025-10-29 11:05:33] Stage1 - Epoch: [10 | 100]
[2025-10-29 11:05:33]   [Train]	Loss:	0.0921	Acc:	0.9945
[2025-10-29 11:05:33]   [Test ]	Loss:	0.2481	Acc:	98.1752
[2025-10-29 11:05:33]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:05:33]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:05:33]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:05:33]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:05:33]   [Param]	LR:	0.00009801
[2025-10-29 11:05:38] Stage1 - Epoch: [11 | 100]
[2025-10-29 11:05:38]   [Train]	Loss:	0.0878	Acc:	0.9963
[2025-10-29 11:05:38]   [Test ]	Loss:	0.2242	Acc:	98.1752
[2025-10-29 11:05:38]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 11:05:38]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 11:05:38]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 11:05:38]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 11:05:38]   [Param]	LR:	0.00009755
[2025-10-29 11:05:42] Stage1 - Epoch: [12 | 100]
[2025-10-29 11:05:42]   [Train]	Loss:	0.0817	Acc:	0.9972
[2025-10-29 11:05:42]   [Test ]	Loss:	0.2260	Acc:	97.8102
[2025-10-29 11:05:42]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9059
[2025-10-29 11:05:42]   [Cough   ]	F1:	0.8235	Precision:	0.9333	Recall:	0.7368
[2025-10-29 11:05:42]   [NonCough]	F1:	0.9883	Precision:	0.9807	Recall:	0.9961
[2025-10-29 11:05:42]   [Stats]	Many:	73.6842	Medium:	99.6078	Few:	0.0000
[2025-10-29 11:05:42]   [Param]	LR:	0.00009704
[2025-10-29 11:05:46] Stage1 - Epoch: [13 | 100]
[2025-10-29 11:05:46]   [Train]	Loss:	0.0805	Acc:	0.9963
[2025-10-29 11:05:46]   [Test ]	Loss:	0.2272	Acc:	97.8102
[2025-10-29 11:05:46]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:05:46]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:05:46]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:05:46]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:05:46]   [Param]	LR:	0.00009649
[2025-10-29 11:05:50] Stage1 - Epoch: [14 | 100]
[2025-10-29 11:05:50]   [Train]	Loss:	0.0746	Acc:	0.9982
[2025-10-29 11:05:50]   [Test ]	Loss:	0.2303	Acc:	98.1752
[2025-10-29 11:05:50]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:05:50]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:05:50]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:05:50]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:05:50]   [Param]	LR:	0.00009589
[2025-10-29 11:05:54] Stage1 - Epoch: [15 | 100]
[2025-10-29 11:05:54]   [Train]	Loss:	0.0710	Acc:	0.9982
[2025-10-29 11:05:54]   [Test ]	Loss:	0.2236	Acc:	98.1752
[2025-10-29 11:05:54]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 11:05:54]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 11:05:54]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 11:05:54]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 11:05:54]   [Param]	LR:	0.00009524
[2025-10-29 11:05:58] Stage1 - Epoch: [16 | 100]
[2025-10-29 11:05:58]   [Train]	Loss:	0.0684	Acc:	0.9982
[2025-10-29 11:05:58]   [Test ]	Loss:	0.1999	Acc:	98.1752
[2025-10-29 11:05:58]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9237
[2025-10-29 11:05:58]   [Cough   ]	F1:	0.8571	Precision:	0.9375	Recall:	0.7895
[2025-10-29 11:05:58]   [NonCough]	F1:	0.9903	Precision:	0.9845	Recall:	0.9961
[2025-10-29 11:05:58]   [Stats]	Many:	78.9474	Medium:	99.6078	Few:	0.0000
[2025-10-29 11:05:58]   [Param]	LR:	0.00009455
[2025-10-29 11:06:02] Stage1 - Epoch: [17 | 100]
[2025-10-29 11:06:02]   [Train]	Loss:	0.0671	Acc:	1.0000
[2025-10-29 11:06:02]   [Test ]	Loss:	0.2104	Acc:	98.9051
[2025-10-29 11:06:02]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 11:06:02]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 11:06:02]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 11:06:02]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:02]   [Param]	LR:	0.00009382
[2025-10-29 11:06:07] Stage1 - Epoch: [18 | 100]
[2025-10-29 11:06:07]   [Train]	Loss:	0.0636	Acc:	1.0000
[2025-10-29 11:06:07]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 11:06:07]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:06:07]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:06:07]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:06:07]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:07]   [Param]	LR:	0.00009304
[2025-10-29 11:06:11] Stage1 - Epoch: [19 | 100]
[2025-10-29 11:06:11]   [Train]	Loss:	0.0629	Acc:	1.0000
[2025-10-29 11:06:11]   [Test ]	Loss:	0.2068	Acc:	98.9051
[2025-10-29 11:06:11]   [Test ]	Micro F1:	0.9891	Macro F1:	0.9542
[2025-10-29 11:06:11]   [Cough   ]	F1:	0.9143	Precision:	1.0000	Recall:	0.8421
[2025-10-29 11:06:11]   [NonCough]	F1:	0.9942	Precision:	0.9884	Recall:	1.0000
[2025-10-29 11:06:11]   [Stats]	Many:	84.2105	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:11]   [Param]	LR:	0.00009222
[2025-10-29 11:06:15] Stage1 - Epoch: [20 | 100]
[2025-10-29 11:06:15]   [Train]	Loss:	0.0639	Acc:	1.0000
[2025-10-29 11:06:15]   [Test ]	Loss:	0.2427	Acc:	97.4453
[2025-10-29 11:06:15]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:06:15]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:06:15]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:06:15]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:15]   [Param]	LR:	0.00009135
[2025-10-29 11:06:19] Stage1 - Epoch: [21 | 100]
[2025-10-29 11:06:19]   [Train]	Loss:	0.0645	Acc:	1.0000
[2025-10-29 11:06:19]   [Test ]	Loss:	0.2306	Acc:	97.4453
[2025-10-29 11:06:19]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:06:19]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:06:19]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:06:19]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:19]   [Param]	LR:	0.00009045
[2025-10-29 11:06:23] Stage1 - Epoch: [22 | 100]
[2025-10-29 11:06:23]   [Train]	Loss:	0.0623	Acc:	1.0000
[2025-10-29 11:06:23]   [Test ]	Loss:	0.2080	Acc:	97.8102
[2025-10-29 11:06:23]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:06:23]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:06:23]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:06:23]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:23]   [Param]	LR:	0.00008951
[2025-10-29 11:06:27] Stage1 - Epoch: [23 | 100]
[2025-10-29 11:06:27]   [Train]	Loss:	0.0614	Acc:	1.0000
[2025-10-29 11:06:27]   [Test ]	Loss:	0.2254	Acc:	97.8102
[2025-10-29 11:06:27]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:06:27]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:06:27]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:06:27]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:27]   [Param]	LR:	0.00008853
[2025-10-29 11:06:32] Stage1 - Epoch: [24 | 100]
[2025-10-29 11:06:32]   [Train]	Loss:	0.0608	Acc:	1.0000
[2025-10-29 11:06:32]   [Test ]	Loss:	0.2297	Acc:	97.0803
[2025-10-29 11:06:32]   [Test ]	Micro F1:	0.9708	Macro F1:	0.8589
[2025-10-29 11:06:32]   [Cough   ]	F1:	0.7333	Precision:	1.0000	Recall:	0.5789
[2025-10-29 11:06:32]   [NonCough]	F1:	0.9846	Precision:	0.9696	Recall:	1.0000
[2025-10-29 11:06:32]   [Stats]	Many:	57.8947	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:32]   [Param]	LR:	0.00008751
[2025-10-29 11:06:36] Stage1 - Epoch: [25 | 100]
[2025-10-29 11:06:36]   [Train]	Loss:	0.0599	Acc:	1.0000
[2025-10-29 11:06:36]   [Test ]	Loss:	0.2221	Acc:	98.1752
[2025-10-29 11:06:36]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:06:36]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:06:36]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:06:36]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:36]   [Param]	LR:	0.00008645
[2025-10-29 11:06:40] Stage1 - Epoch: [26 | 100]
[2025-10-29 11:06:40]   [Train]	Loss:	0.0592	Acc:	1.0000
[2025-10-29 11:06:40]   [Test ]	Loss:	0.2228	Acc:	97.8102
[2025-10-29 11:06:40]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:06:40]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:06:40]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:06:40]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:40]   [Param]	LR:	0.00008536
[2025-10-29 11:06:44] Stage1 - Epoch: [27 | 100]
[2025-10-29 11:06:44]   [Train]	Loss:	0.0593	Acc:	1.0000
[2025-10-29 11:06:44]   [Test ]	Loss:	0.2186	Acc:	97.4453
[2025-10-29 11:06:44]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:06:44]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:06:44]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:06:44]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:44]   [Param]	LR:	0.00008423
[2025-10-29 11:06:49] Stage1 - Epoch: [28 | 100]
[2025-10-29 11:06:49]   [Train]	Loss:	0.0589	Acc:	1.0000
[2025-10-29 11:06:49]   [Test ]	Loss:	0.2145	Acc:	98.1752
[2025-10-29 11:06:49]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:06:49]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:06:49]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:06:49]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:49]   [Param]	LR:	0.00008307
[2025-10-29 11:06:53] Stage1 - Epoch: [29 | 100]
[2025-10-29 11:06:53]   [Train]	Loss:	0.0587	Acc:	1.0000
[2025-10-29 11:06:53]   [Test ]	Loss:	0.2184	Acc:	97.8102
[2025-10-29 11:06:53]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:06:53]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:06:53]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:06:53]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:53]   [Param]	LR:	0.00008187
[2025-10-29 11:06:57] Stage1 - Epoch: [30 | 100]
[2025-10-29 11:06:57]   [Train]	Loss:	0.0588	Acc:	1.0000
[2025-10-29 11:06:57]   [Test ]	Loss:	0.2139	Acc:	98.1752
[2025-10-29 11:06:57]   [Test ]	Micro F1:	0.9818	Macro F1:	0.9194
[2025-10-29 11:06:57]   [Cough   ]	F1:	0.8485	Precision:	1.0000	Recall:	0.7368
[2025-10-29 11:06:57]   [NonCough]	F1:	0.9903	Precision:	0.9808	Recall:	1.0000
[2025-10-29 11:06:57]   [Stats]	Many:	73.6842	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:06:57]   [Param]	LR:	0.00008065
[2025-10-29 11:07:02] Stage1 - Epoch: [31 | 100]
[2025-10-29 11:07:02]   [Train]	Loss:	0.0586	Acc:	1.0000
[2025-10-29 11:07:02]   [Test ]	Loss:	0.2200	Acc:	97.4453
[2025-10-29 11:07:02]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:07:02]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:07:02]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:07:02]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:02]   [Param]	LR:	0.00007939
[2025-10-29 11:07:06] Stage1 - Epoch: [32 | 100]
[2025-10-29 11:07:06]   [Train]	Loss:	0.0582	Acc:	1.0000
[2025-10-29 11:07:06]   [Test ]	Loss:	0.2228	Acc:	97.4453
[2025-10-29 11:07:06]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:07:06]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:07:06]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:07:06]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:06]   [Param]	LR:	0.00007810
[2025-10-29 11:07:10] Stage1 - Epoch: [33 | 100]
[2025-10-29 11:07:10]   [Train]	Loss:	0.0581	Acc:	1.0000
[2025-10-29 11:07:10]   [Test ]	Loss:	0.2172	Acc:	97.4453
[2025-10-29 11:07:10]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:07:10]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:07:10]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:07:10]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:10]   [Param]	LR:	0.00007679
[2025-10-29 11:07:14] Stage1 - Epoch: [34 | 100]
[2025-10-29 11:07:14]   [Train]	Loss:	0.0580	Acc:	1.0000
[2025-10-29 11:07:14]   [Test ]	Loss:	0.2127	Acc:	97.8102
[2025-10-29 11:07:14]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:07:14]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:07:14]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:07:14]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:14]   [Param]	LR:	0.00007545
[2025-10-29 11:07:18] Stage1 - Epoch: [35 | 100]
[2025-10-29 11:07:18]   [Train]	Loss:	0.0578	Acc:	1.0000
[2025-10-29 11:07:18]   [Test ]	Loss:	0.2089	Acc:	97.8102
[2025-10-29 11:07:18]   [Test ]	Micro F1:	0.9781	Macro F1:	0.9004
[2025-10-29 11:07:18]   [Cough   ]	F1:	0.8125	Precision:	1.0000	Recall:	0.6842
[2025-10-29 11:07:18]   [NonCough]	F1:	0.9884	Precision:	0.9770	Recall:	1.0000
[2025-10-29 11:07:18]   [Stats]	Many:	68.4211	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:18]   [Param]	LR:	0.00007409
[2025-10-29 11:07:23] Stage1 - Epoch: [36 | 100]
[2025-10-29 11:07:23]   [Train]	Loss:	0.0577	Acc:	1.0000
[2025-10-29 11:07:23]   [Test ]	Loss:	0.2093	Acc:	97.4453
[2025-10-29 11:07:23]   [Test ]	Micro F1:	0.9745	Macro F1:	0.8803
[2025-10-29 11:07:23]   [Cough   ]	F1:	0.7742	Precision:	1.0000	Recall:	0.6316
[2025-10-29 11:07:23]   [NonCough]	F1:	0.9865	Precision:	0.9733	Recall:	1.0000
[2025-10-29 11:07:23]   [Stats]	Many:	63.1579	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:23]   [Param]	LR:	0.00007270
[2025-10-29 11:07:23] Early stopping triggered after 36 epochs.
[2025-10-29 11:07:23] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_11-4/best_model_stage1_audio.pth
[2025-10-29 11:07:24] F1 score plot for stage1 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_11-4/stage1_macro_f1.png
[2025-10-29 11:07:24] Stage 1 Training Time: 00:02:31
[2025-10-29 11:07:24] Stage 1 Best Macro F1: 0.9542
[2025-10-29 11:07:24] Confidence threshold: 0.65
[2025-10-29 11:07:29] Total samples: 649
[2025-10-29 11:07:29] Total windows checked: 1127
[2025-10-29 11:07:29] Cough windows found: 168
[2025-10-29 11:07:29] High-confidence negative windows found: 799
[2025-10-29 11:07:29] Total kept windows: 967
[2025-10-29 11:07:29] Selection rate: 85.80%
[2025-10-29 11:07:29] Using filtered dataset with 967 cough segments
[2025-10-29 11:07:29] Starting pseudo-label precomputation for curriculum learning...
[2025-10-29 11:07:32] Confidence statistics - Min: 0.6515, Max: 0.9996, Mean: 0.9183, Median: 0.9558
[2025-10-29 11:07:32] Precomputed 967 samples with confidence scores
[2025-10-29 11:07:32] Epoch 1/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:07:40] Stage2 - Epoch: [1 | 30]
[2025-10-29 11:07:40]   [Train]	Total Loss:	0.4790	CE Loss:	0.1809	Distill Loss:	0.2748	Source Loss:	0.1058
[2025-10-29 11:07:40]   [Train]	Acc:	0.9583
[2025-10-29 11:07:40]   [Test ]	Loss:	0.0000	Acc:	58.2822
[2025-10-29 11:07:40]   [Test ]	Micro F1:	0.5828	Macro F1:	0.4851
[2025-10-29 11:07:40]   [Cough   ]	F1:	0.2609	Precision:	1.0000	Recall:	0.1500
[2025-10-29 11:07:40]   [NonCough]	F1:	0.7094	Precision:	0.5497	Recall:	1.0000
[2025-10-29 11:07:40]   [Stats]	Many:	15.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:40]   [Param]	LR:	0.00001000
[2025-10-29 11:07:40] Epoch 2/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:07:47] Stage2 - Epoch: [2 | 30]
[2025-10-29 11:07:47]   [Train]	Total Loss:	0.3287	CE Loss:	0.1314	Distill Loss:	0.1564	Source Loss:	0.0878
[2025-10-29 11:07:47]   [Train]	Acc:	0.9766
[2025-10-29 11:07:47]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-29 11:07:47]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6517
[2025-10-29 11:07:47]   [Cough   ]	F1:	0.5405	Precision:	0.9677	Recall:	0.3750
[2025-10-29 11:07:47]   [NonCough]	F1:	0.7628	Precision:	0.6212	Recall:	0.9880
[2025-10-29 11:07:47]   [Stats]	Many:	37.5000	Medium:	98.7952	Few:	0.0000
[2025-10-29 11:07:47]   [Param]	LR:	0.00000997
[2025-10-29 11:07:47] Epoch 3/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:07:55] Stage2 - Epoch: [3 | 30]
[2025-10-29 11:07:55]   [Train]	Total Loss:	0.3669	CE Loss:	0.1569	Distill Loss:	0.1734	Source Loss:	0.0886
[2025-10-29 11:07:55]   [Train]	Acc:	0.9635
[2025-10-29 11:07:55]   [Test ]	Loss:	0.0000	Acc:	63.1902
[2025-10-29 11:07:55]   [Test ]	Micro F1:	0.6319	Macro F1:	0.5673
[2025-10-29 11:07:55]   [Cough   ]	F1:	0.4000	Precision:	1.0000	Recall:	0.2500
[2025-10-29 11:07:55]   [NonCough]	F1:	0.7345	Precision:	0.5804	Recall:	1.0000
[2025-10-29 11:07:55]   [Stats]	Many:	25.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:07:55]   [Param]	LR:	0.00000989
[2025-10-29 11:07:55] Epoch 4/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:02] Stage2 - Epoch: [4 | 30]
[2025-10-29 11:08:02]   [Train]	Total Loss:	0.3869	CE Loss:	0.1504	Distill Loss:	0.1910	Source Loss:	0.1028
[2025-10-29 11:08:02]   [Train]	Acc:	0.9609
[2025-10-29 11:08:02]   [Test ]	Loss:	0.0000	Acc:	61.3497
[2025-10-29 11:08:02]   [Test ]	Micro F1:	0.6135	Macro F1:	0.5377
[2025-10-29 11:08:02]   [Cough   ]	F1:	0.3505	Precision:	1.0000	Recall:	0.2125
[2025-10-29 11:08:02]   [NonCough]	F1:	0.7249	Precision:	0.5685	Recall:	1.0000
[2025-10-29 11:08:02]   [Stats]	Many:	21.2500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:02]   [Param]	LR:	0.00000976
[2025-10-29 11:08:02] Epoch 5/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:10] Stage2 - Epoch: [5 | 30]
[2025-10-29 11:08:10]   [Train]	Total Loss:	0.2622	CE Loss:	0.1094	Distill Loss:	0.1070	Source Loss:	0.0779
[2025-10-29 11:08:10]   [Train]	Acc:	0.9805
[2025-10-29 11:08:10]   [Test ]	Loss:	0.0000	Acc:	71.7791
[2025-10-29 11:08:10]   [Test ]	Micro F1:	0.7178	Macro F1:	0.6922
[2025-10-29 11:08:10]   [Cough   ]	F1:	0.6034	Precision:	0.9722	Recall:	0.4375
[2025-10-29 11:08:10]   [NonCough]	F1:	0.7810	Precision:	0.6457	Recall:	0.9880
[2025-10-29 11:08:10]   [Stats]	Many:	43.7500	Medium:	98.7952	Few:	0.0000
[2025-10-29 11:08:10]   [Param]	LR:	0.00000957
[2025-10-29 11:08:10] Epoch 6/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:17] Stage2 - Epoch: [6 | 30]
[2025-10-29 11:08:17]   [Train]	Total Loss:	0.2096	CE Loss:	0.1091	Distill Loss:	0.0997	Source Loss:	0.0705
[2025-10-29 11:08:17]   [Train]	Acc:	0.9844
[2025-10-29 11:08:17]   [Test ]	Loss:	0.0000	Acc:	62.5767
[2025-10-29 11:08:17]   [Test ]	Micro F1:	0.6258	Macro F1:	0.5576
[2025-10-29 11:08:17]   [Cough   ]	F1:	0.3838	Precision:	1.0000	Recall:	0.2375
[2025-10-29 11:08:17]   [NonCough]	F1:	0.7313	Precision:	0.5764	Recall:	1.0000
[2025-10-29 11:08:17]   [Stats]	Many:	23.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:17]   [Param]	LR:	0.00000933
[2025-10-29 11:08:17] Epoch 7/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:25] Stage2 - Epoch: [7 | 30]
[2025-10-29 11:08:25]   [Train]	Total Loss:	0.2066	CE Loss:	0.1051	Distill Loss:	0.1064	Source Loss:	0.0695
[2025-10-29 11:08:25]   [Train]	Acc:	0.9831
[2025-10-29 11:08:25]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-29 11:08:25]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6313
[2025-10-29 11:08:25]   [Cough   ]	F1:	0.5047	Precision:	1.0000	Recall:	0.3375
[2025-10-29 11:08:25]   [NonCough]	F1:	0.7580	Precision:	0.6103	Recall:	1.0000
[2025-10-29 11:08:25]   [Stats]	Many:	33.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:25]   [Param]	LR:	0.00000905
[2025-10-29 11:08:25] Epoch 8/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:32] Stage2 - Epoch: [8 | 30]
[2025-10-29 11:08:32]   [Train]	Total Loss:	0.2024	CE Loss:	0.1036	Distill Loss:	0.1007	Source Loss:	0.0685
[2025-10-29 11:08:32]   [Train]	Acc:	0.9857
[2025-10-29 11:08:32]   [Test ]	Loss:	0.0000	Acc:	64.4172
[2025-10-29 11:08:32]   [Test ]	Micro F1:	0.6442	Macro F1:	0.5862
[2025-10-29 11:08:32]   [Cough   ]	F1:	0.4314	Precision:	1.0000	Recall:	0.2750
[2025-10-29 11:08:32]   [NonCough]	F1:	0.7411	Precision:	0.5887	Recall:	1.0000
[2025-10-29 11:08:32]   [Stats]	Many:	27.5000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:32]   [Param]	LR:	0.00000872
[2025-10-29 11:08:32] Epoch 9/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:40] Stage2 - Epoch: [9 | 30]
[2025-10-29 11:08:40]   [Train]	Total Loss:	0.1968	CE Loss:	0.1019	Distill Loss:	0.0921	Source Loss:	0.0673
[2025-10-29 11:08:40]   [Train]	Acc:	0.9844
[2025-10-29 11:08:40]   [Test ]	Loss:	0.0000	Acc:	71.1656
[2025-10-29 11:08:40]   [Test ]	Micro F1:	0.7117	Macro F1:	0.6843
[2025-10-29 11:08:40]   [Cough   ]	F1:	0.5913	Precision:	0.9714	Recall:	0.4250
[2025-10-29 11:08:40]   [NonCough]	F1:	0.7773	Precision:	0.6406	Recall:	0.9880
[2025-10-29 11:08:40]   [Stats]	Many:	42.5000	Medium:	98.7952	Few:	0.0000
[2025-10-29 11:08:40]   [Param]	LR:	0.00000835
[2025-10-29 11:08:40] Epoch 10/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:48] Stage2 - Epoch: [10 | 30]
[2025-10-29 11:08:48]   [Train]	Total Loss:	0.2120	CE Loss:	0.1071	Distill Loss:	0.1125	Source Loss:	0.0712
[2025-10-29 11:08:48]   [Train]	Acc:	0.9805
[2025-10-29 11:08:48]   [Test ]	Loss:	0.0000	Acc:	68.7117
[2025-10-29 11:08:48]   [Test ]	Micro F1:	0.6871	Macro F1:	0.6485
[2025-10-29 11:08:48]   [Cough   ]	F1:	0.5321	Precision:	1.0000	Recall:	0.3625
[2025-10-29 11:08:48]   [NonCough]	F1:	0.7650	Precision:	0.6194	Recall:	1.0000
[2025-10-29 11:08:48]   [Stats]	Many:	36.2500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:48]   [Param]	LR:	0.00000794
[2025-10-29 11:08:48] Epoch 11/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:08:56] Stage2 - Epoch: [11 | 30]
[2025-10-29 11:08:56]   [Train]	Total Loss:	0.1947	CE Loss:	0.0997	Distill Loss:	0.0958	Source Loss:	0.0663
[2025-10-29 11:08:56]   [Train]	Acc:	0.9831
[2025-10-29 11:08:56]   [Test ]	Loss:	0.0000	Acc:	66.8712
[2025-10-29 11:08:56]   [Test ]	Micro F1:	0.6687	Macro F1:	0.6226
[2025-10-29 11:08:56]   [Cough   ]	F1:	0.4906	Precision:	1.0000	Recall:	0.3250
[2025-10-29 11:08:56]   [NonCough]	F1:	0.7545	Precision:	0.6058	Recall:	1.0000
[2025-10-29 11:08:56]   [Stats]	Many:	32.5000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:08:56]   [Param]	LR:	0.00000750
[2025-10-29 11:08:56] Epoch 12/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:03] Stage2 - Epoch: [12 | 30]
[2025-10-29 11:09:03]   [Train]	Total Loss:	0.2017	CE Loss:	0.1031	Distill Loss:	0.0954	Source Loss:	0.0700
[2025-10-29 11:09:03]   [Train]	Acc:	0.9831
[2025-10-29 11:09:03]   [Test ]	Loss:	0.0000	Acc:	66.8712
[2025-10-29 11:09:03]   [Test ]	Micro F1:	0.6687	Macro F1:	0.6226
[2025-10-29 11:09:03]   [Cough   ]	F1:	0.4906	Precision:	1.0000	Recall:	0.3250
[2025-10-29 11:09:03]   [NonCough]	F1:	0.7545	Precision:	0.6058	Recall:	1.0000
[2025-10-29 11:09:03]   [Stats]	Many:	32.5000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:03]   [Param]	LR:	0.00000703
[2025-10-29 11:09:03] Epoch 13/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:11] Stage2 - Epoch: [13 | 30]
[2025-10-29 11:09:11]   [Train]	Total Loss:	0.2022	CE Loss:	0.1036	Distill Loss:	0.0997	Source Loss:	0.0687
[2025-10-29 11:09:11]   [Train]	Acc:	0.9818
[2025-10-29 11:09:11]   [Test ]	Loss:	0.0000	Acc:	71.1656
[2025-10-29 11:09:11]   [Test ]	Micro F1:	0.7117	Macro F1:	0.6843
[2025-10-29 11:09:11]   [Cough   ]	F1:	0.5913	Precision:	0.9714	Recall:	0.4250
[2025-10-29 11:09:11]   [NonCough]	F1:	0.7773	Precision:	0.6406	Recall:	0.9880
[2025-10-29 11:09:11]   [Stats]	Many:	42.5000	Medium:	98.7952	Few:	0.0000
[2025-10-29 11:09:11]   [Param]	LR:	0.00000655
[2025-10-29 11:09:11] Epoch 14/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:18] Stage2 - Epoch: [14 | 30]
[2025-10-29 11:09:18]   [Train]	Total Loss:	0.1974	CE Loss:	0.0996	Distill Loss:	0.1005	Source Loss:	0.0677
[2025-10-29 11:09:18]   [Train]	Acc:	0.9896
[2025-10-29 11:09:18]   [Test ]	Loss:	0.0000	Acc:	66.2577
[2025-10-29 11:09:18]   [Test ]	Micro F1:	0.6626	Macro F1:	0.6137
[2025-10-29 11:09:18]   [Cough   ]	F1:	0.4762	Precision:	1.0000	Recall:	0.3125
[2025-10-29 11:09:18]   [NonCough]	F1:	0.7511	Precision:	0.6014	Recall:	1.0000
[2025-10-29 11:09:18]   [Stats]	Many:	31.2500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:18]   [Param]	LR:	0.00000604
[2025-10-29 11:09:18] Epoch 15/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:26] Stage2 - Epoch: [15 | 30]
[2025-10-29 11:09:26]   [Train]	Total Loss:	0.1910	CE Loss:	0.0996	Distill Loss:	0.0863	Source Loss:	0.0655
[2025-10-29 11:09:26]   [Train]	Acc:	0.9883
[2025-10-29 11:09:26]   [Test ]	Loss:	0.0000	Acc:	69.3252
[2025-10-29 11:09:26]   [Test ]	Micro F1:	0.6933	Macro F1:	0.6570
[2025-10-29 11:09:26]   [Cough   ]	F1:	0.5455	Precision:	1.0000	Recall:	0.3750
[2025-10-29 11:09:26]   [NonCough]	F1:	0.7685	Precision:	0.6241	Recall:	1.0000
[2025-10-29 11:09:26]   [Stats]	Many:	37.5000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:26]   [Param]	LR:	0.00000552
[2025-10-29 11:09:26] Epoch 16/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:33] Stage2 - Epoch: [16 | 30]
[2025-10-29 11:09:33]   [Train]	Total Loss:	0.1723	CE Loss:	0.0875	Distill Loss:	0.0696	Source Loss:	0.0639
[2025-10-29 11:09:33]   [Train]	Acc:	0.9909
[2025-10-29 11:09:33]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:09:33]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:09:33]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:09:33]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:09:33]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:33]   [Param]	LR:	0.00000500
[2025-10-29 11:09:33] Epoch 17/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:41] Stage2 - Epoch: [17 | 30]
[2025-10-29 11:09:41]   [Train]	Total Loss:	0.1713	CE Loss:	0.0861	Distill Loss:	0.0704	Source Loss:	0.0641
[2025-10-29 11:09:41]   [Train]	Acc:	0.9935
[2025-10-29 11:09:41]   [Test ]	Loss:	0.0000	Acc:	72.3926
[2025-10-29 11:09:41]   [Test ]	Micro F1:	0.7239	Macro F1:	0.6977
[2025-10-29 11:09:41]   [Cough   ]	F1:	0.6087	Precision:	1.0000	Recall:	0.4375
[2025-10-29 11:09:41]   [NonCough]	F1:	0.7867	Precision:	0.6484	Recall:	1.0000
[2025-10-29 11:09:41]   [Stats]	Many:	43.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:41]   [Param]	LR:	0.00000448
[2025-10-29 11:09:41] Epoch 18/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:48] Stage2 - Epoch: [18 | 30]
[2025-10-29 11:09:48]   [Train]	Total Loss:	0.1793	CE Loss:	0.0919	Distill Loss:	0.0781	Source Loss:	0.0640
[2025-10-29 11:09:48]   [Train]	Acc:	0.9909
[2025-10-29 11:09:48]   [Test ]	Loss:	0.0000	Acc:	70.5521
[2025-10-29 11:09:48]   [Test ]	Micro F1:	0.7055	Macro F1:	0.6736
[2025-10-29 11:09:48]   [Cough   ]	F1:	0.5714	Precision:	1.0000	Recall:	0.4000
[2025-10-29 11:09:48]   [NonCough]	F1:	0.7757	Precision:	0.6336	Recall:	1.0000
[2025-10-29 11:09:48]   [Stats]	Many:	40.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:48]   [Param]	LR:	0.00000396
[2025-10-29 11:09:48] Epoch 19/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:09:56] Stage2 - Epoch: [19 | 30]
[2025-10-29 11:09:56]   [Train]	Total Loss:	0.1841	CE Loss:	0.0953	Distill Loss:	0.0831	Source Loss:	0.0638
[2025-10-29 11:09:56]   [Train]	Acc:	0.9883
[2025-10-29 11:09:56]   [Test ]	Loss:	0.0000	Acc:	66.2577
[2025-10-29 11:09:56]   [Test ]	Micro F1:	0.6626	Macro F1:	0.6137
[2025-10-29 11:09:56]   [Cough   ]	F1:	0.4762	Precision:	1.0000	Recall:	0.3125
[2025-10-29 11:09:56]   [NonCough]	F1:	0.7511	Precision:	0.6014	Recall:	1.0000
[2025-10-29 11:09:56]   [Stats]	Many:	31.2500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:09:56]   [Param]	LR:	0.00000345
[2025-10-29 11:09:56] Epoch 20/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:03] Stage2 - Epoch: [20 | 30]
[2025-10-29 11:10:03]   [Train]	Total Loss:	0.1725	CE Loss:	0.0867	Distill Loss:	0.0717	Source Loss:	0.0643
[2025-10-29 11:10:03]   [Train]	Acc:	0.9948
[2025-10-29 11:10:03]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:03]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:03]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:03]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:03]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:03]   [Param]	LR:	0.00000297
[2025-10-29 11:10:03] Epoch 21/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:11] Stage2 - Epoch: [21 | 30]
[2025-10-29 11:10:11]   [Train]	Total Loss:	0.1755	CE Loss:	0.0921	Distill Loss:	0.0697	Source Loss:	0.0625
[2025-10-29 11:10:11]   [Train]	Acc:	0.9922
[2025-10-29 11:10:11]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:11]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:11]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:11]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:11]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:11]   [Param]	LR:	0.00000250
[2025-10-29 11:10:11] Epoch 22/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:18] Stage2 - Epoch: [22 | 30]
[2025-10-29 11:10:18]   [Train]	Total Loss:	0.1783	CE Loss:	0.0910	Distill Loss:	0.0771	Source Loss:	0.0641
[2025-10-29 11:10:18]   [Train]	Acc:	0.9896
[2025-10-29 11:10:18]   [Test ]	Loss:	0.0000	Acc:	69.9387
[2025-10-29 11:10:18]   [Test ]	Micro F1:	0.6994	Macro F1:	0.6653
[2025-10-29 11:10:18]   [Cough   ]	F1:	0.5586	Precision:	1.0000	Recall:	0.3875
[2025-10-29 11:10:18]   [NonCough]	F1:	0.7721	Precision:	0.6288	Recall:	1.0000
[2025-10-29 11:10:18]   [Stats]	Many:	38.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:18]   [Param]	LR:	0.00000206
[2025-10-29 11:10:18] Epoch 23/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:26] Stage2 - Epoch: [23 | 30]
[2025-10-29 11:10:26]   [Train]	Total Loss:	0.1753	CE Loss:	0.0910	Distill Loss:	0.0705	Source Loss:	0.0632
[2025-10-29 11:10:26]   [Train]	Acc:	0.9896
[2025-10-29 11:10:26]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:26]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:26]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:26]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:26]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:26]   [Param]	LR:	0.00000165
[2025-10-29 11:10:26] Epoch 24/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:33] Stage2 - Epoch: [24 | 30]
[2025-10-29 11:10:33]   [Train]	Total Loss:	0.1648	CE Loss:	0.0822	Distill Loss:	0.0632	Source Loss:	0.0636
[2025-10-29 11:10:33]   [Train]	Acc:	0.9948
[2025-10-29 11:10:33]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:33]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:33]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:33]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:33]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:33]   [Param]	LR:	0.00000128
[2025-10-29 11:10:33] Epoch 25/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:41] Stage2 - Epoch: [25 | 30]
[2025-10-29 11:10:41]   [Train]	Total Loss:	0.1677	CE Loss:	0.0853	Distill Loss:	0.0654	Source Loss:	0.0629
[2025-10-29 11:10:41]   [Train]	Acc:	0.9935
[2025-10-29 11:10:41]   [Test ]	Loss:	0.0000	Acc:	67.4847
[2025-10-29 11:10:41]   [Test ]	Micro F1:	0.6748	Macro F1:	0.6313
[2025-10-29 11:10:41]   [Cough   ]	F1:	0.5047	Precision:	1.0000	Recall:	0.3375
[2025-10-29 11:10:41]   [NonCough]	F1:	0.7580	Precision:	0.6103	Recall:	1.0000
[2025-10-29 11:10:41]   [Stats]	Many:	33.7500	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:41]   [Param]	LR:	0.00000095
[2025-10-29 11:10:41] Epoch 26/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:49] Stage2 - Epoch: [26 | 30]
[2025-10-29 11:10:49]   [Train]	Total Loss:	0.1720	CE Loss:	0.0871	Distill Loss:	0.0730	Source Loss:	0.0630
[2025-10-29 11:10:49]   [Train]	Acc:	0.9883
[2025-10-29 11:10:49]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:49]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:49]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:49]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:49]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:49]   [Param]	LR:	0.00000067
[2025-10-29 11:10:49] Epoch 27/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:10:56] Stage2 - Epoch: [27 | 30]
[2025-10-29 11:10:56]   [Train]	Total Loss:	0.1733	CE Loss:	0.0904	Distill Loss:	0.0676	Source Loss:	0.0626
[2025-10-29 11:10:56]   [Train]	Acc:	0.9896
[2025-10-29 11:10:56]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:10:56]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:10:56]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:10:56]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:10:56]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:10:56]   [Param]	LR:	0.00000043
[2025-10-29 11:10:56] Epoch 28/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:11:04] Stage2 - Epoch: [28 | 30]
[2025-10-29 11:11:04]   [Train]	Total Loss:	0.1704	CE Loss:	0.0864	Distill Loss:	0.0683	Source Loss:	0.0636
[2025-10-29 11:11:04]   [Train]	Acc:	0.9948
[2025-10-29 11:11:04]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:11:04]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:11:04]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:11:04]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:11:04]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:11:04]   [Param]	LR:	0.00000024
[2025-10-29 11:11:04] Epoch 29/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:11:12] Stage2 - Epoch: [29 | 30]
[2025-10-29 11:11:12]   [Train]	Total Loss:	0.1691	CE Loss:	0.0873	Distill Loss:	0.0662	Source Loss:	0.0620
[2025-10-29 11:11:12]   [Train]	Acc:	0.9909
[2025-10-29 11:11:12]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:11:12]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:11:12]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:11:12]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:11:12]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:11:12]   [Param]	LR:	0.00000011
[2025-10-29 11:11:12] Epoch 30/30: Using 779/967 target samples (threshold=0.8500)
[2025-10-29 11:11:20] Stage2 - Epoch: [30 | 30]
[2025-10-29 11:11:20]   [Train]	Total Loss:	0.1678	CE Loss:	0.0856	Distill Loss:	0.0670	Source Loss:	0.0621
[2025-10-29 11:11:20]   [Train]	Acc:	0.9909
[2025-10-29 11:11:20]   [Test ]	Loss:	0.0000	Acc:	68.0982
[2025-10-29 11:11:20]   [Test ]	Micro F1:	0.6810	Macro F1:	0.6400
[2025-10-29 11:11:20]   [Cough   ]	F1:	0.5185	Precision:	1.0000	Recall:	0.3500
[2025-10-29 11:11:20]   [NonCough]	F1:	0.7615	Precision:	0.6148	Recall:	1.0000
[2025-10-29 11:11:20]   [Stats]	Many:	35.0000	Medium:	100.0000	Few:	0.0000
[2025-10-29 11:11:20]   [Param]	LR:	0.00000003
[2025-10-29 11:11:22] Model saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_11-4/best_model_stage2_audio.pth
[2025-10-29 11:11:22] F1 score plot for stage2 saved to output/cold_zone_to_hot_zone_fine_S2Src2.0_10-29_11-4/stage2_macro_f1.png
[2025-10-29 11:11:22] Stage 2 Training Time: 00:03:48
[2025-10-29 11:11:22] Stage 2 Best Target Macro F1: 0.6977
